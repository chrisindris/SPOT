./spot_train_eval.sh 0 sweep_eh-1-s_10-g_0.2-lb_0.9-l2_0.9.txt ./configs/anet.yaml model.embedding_head=1 training.step=10 training.gamma=0.2 training.loss_balance=0.9 loss.lambda_2=0.9 dataset.training.output_path=./output/ dataset.testing.output_path=./output/ training.checkpoint_path=./output/
{'dataset': {'name': 'anet', 'num_classes': 200, 'training': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}, 'testing': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}}, 'model': {'embedding_head': 1, 'feat_dim': 400, 'temporal_scale': 100}, 'pretraining': {'warmup_epoch': 30, 'consecutive_warmup_epochs': 3, 'unlabeled_pretrain': False}, 'training': {'batch_size': 25, 'learning_rate': 0.0004, 'weight_decay': 0.005, 'alternate': True, 'max_epoch': 40, 'consecutive_train_epochs': 3, 'checkpoint_path': './output/', 'random_seed': 1, 'step': 10, 'gamma': 0.2, 'scheduler': False, 'feature_path': '/data/i5O/ActivityNet1.3/train/', 'num_gpu': 1, 'loss_balance': 0.9, 'loss_balance_full': 0.5, 'regular_eval': False}, 'loss': {'lambda_1': 0.5, 'lambda_2': 0.9}, 'testing': {'feature_path': '/data/i5O/ActivityNet1.3/test/', 'cls_thresh': 0.01, 'mask_thresh': [0, 0.2, 0.4, 0.6, 0.8], 'class_thresh': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'top_k_snip': 10, 'top_k': 500, 'nms_thresh': 0.6}}

Total Number of Learnable Paramters (in M) :  2.83706
No of Gpus using to Train :  1 
 Saving all Checkpoints in path : ./output/
train_loader
Loading train Video Information ...
  0% 0/9649 [00:00<?, ?it/s]  6% 622/9649 [00:00<00:01, 6210.81it/s] 13% 1252/9649 [00:00<00:01, 6259.42it/s] 19% 1880/9649 [00:00<00:01, 6265.97it/s] 26% 2511/9649 [00:00<00:01, 6281.55it/s] 33% 3140/9649 [00:00<00:01, 6088.54it/s] 39% 3806/9649 [00:00<00:00, 6277.14it/s] 46% 4480/9649 [00:00<00:00, 6424.49it/s] 53% 5134/9649 [00:00<00:00, 6458.46it/s] 60% 5781/9649 [00:00<00:00, 6456.97it/s] 67% 6428/9649 [00:01<00:00, 6404.86it/s] 73% 7069/9649 [00:01<00:00, 6249.99it/s] 80% 7698/9649 [00:01<00:00, 6259.50it/s] 86% 8325/9649 [00:01<00:00, 6230.79it/s] 93% 8949/9649 [00:01<00:00, 6216.69it/s] 99% 9571/9649 [00:01<00:00, 6168.69it/s]100% 9649/9649 [00:01<00:00, 6265.98it/s]
train_loader_pretrain
Loading train Video Information ...
  0% 0/9649 [00:00<?, ?it/s] 30% 2903/9649 [00:00<00:00, 29020.34it/s] 61% 5840/9649 [00:00<00:00, 29223.31it/s] 91% 8763/9649 [00:00<00:00, 29042.45it/s]100% 9649/9649 [00:00<00:00, 29012.37it/s]
train_loader_unlabel
Loading unlabel Video Information ...
  0% 0/8683 [00:00<?, ?it/s]  7% 618/8683 [00:00<00:01, 6175.41it/s] 14% 1236/8683 [00:00<00:01, 5956.50it/s] 21% 1833/8683 [00:00<00:01, 5815.38it/s] 28% 2415/8683 [00:00<00:01, 5681.23it/s] 34% 2984/8683 [00:00<00:01, 5460.45it/s] 41% 3532/8683 [00:00<00:00, 5265.93it/s] 47% 4060/8683 [00:00<00:00, 5140.24it/s] 53% 4575/8683 [00:00<00:00, 4992.57it/s] 58% 5075/8683 [00:00<00:00, 4851.59it/s] 64% 5561/8683 [00:01<00:00, 4708.88it/s] 69% 6033/8683 [00:01<00:00, 4555.09it/s] 75% 6490/8683 [00:01<00:00, 4438.02it/s] 80% 6935/8683 [00:01<00:00, 4350.81it/s] 85% 7371/8683 [00:01<00:00, 4189.36it/s] 90% 7791/8683 [00:01<00:00, 4088.36it/s] 94% 8201/8683 [00:01<00:00, 4007.34it/s] 99% 8602/8683 [00:01<00:00, 3913.78it/s]100% 8683/8683 [00:01<00:00, 4640.88it/s]
training: len(train_loader_unlabel) 295
test_loader
Loading validation Video Information ...
  0% 0/4728 [00:00<?, ?it/s]  9% 431/4728 [00:00<00:00, 4306.13it/s] 18% 862/4728 [00:00<00:00, 4240.00it/s] 28% 1306/4728 [00:00<00:00, 4326.99it/s] 37% 1753/4728 [00:00<00:00, 4379.57it/s] 46% 2192/4728 [00:00<00:00, 4382.50it/s] 56% 2631/4728 [00:00<00:00, 4373.39it/s] 65% 3069/4728 [00:00<00:00, 4284.50it/s] 74% 3498/4728 [00:00<00:00, 4205.66it/s] 83% 3919/4728 [00:00<00:00, 4128.05it/s] 92% 4333/4728 [00:01<00:00, 4036.55it/s]100% 4728/4728 [00:01<00:00, 4157.70it/s]training: len(train_loader) 31
training: len(train_loader_pretrain) 31
training: len(test_loader) 154
0

n_iter  0 : loss (0.251516) + tot_loss (0.944717) + tot_loss_crop (0.907943) + loss_clip_order (0.692506) = final_loss = 2.796683
n_iter  1 : loss (0.240168) + tot_loss (0.944975) + tot_loss_crop (0.894988) + loss_clip_order (0.697859) = final_loss = 2.777990
n_iter  2 : loss (0.230398) + tot_loss (0.923077) + tot_loss_crop (0.883829) + loss_clip_order (0.697347) = final_loss = 2.734650
n_iter  3 : loss (0.223330) + tot_loss (0.909091) + tot_loss_crop (0.876070) + loss_clip_order (0.694492) = final_loss = 2.702983
n_iter  4 : loss (0.219778) + tot_loss (0.899420) + tot_loss_crop (0.868574) + loss_clip_order (0.693866) = final_loss = 2.681638
n_iter  5 : loss (0.212646) + tot_loss (0.898166) + tot_loss_crop (0.870378) + loss_clip_order (0.695119) = final_loss = 2.676308
n_iter  6 : loss (0.209596) + tot_loss (0.891535) + tot_loss_crop (0.868376) + loss_clip_order (0.692412) = final_loss = 2.661918
n_iter  7 : loss (0.208262) + tot_loss (0.868612) + tot_loss_crop (0.863038) + loss_clip_order (0.694322) = final_loss = 2.634233
n_iter  8 : loss (0.206440) + tot_loss (0.879261) + tot_loss_crop (0.856473) + loss_clip_order (0.694538) = final_loss = 2.636712
n_iter  9 : loss (0.196381) + tot_loss (0.866972) + tot_loss_crop (0.859547) + loss_clip_order (0.694542) = final_loss = 2.617442
n_iter 10 : loss (0.192351) + tot_loss (0.877073) + tot_loss_crop (0.858059) + loss_clip_order (0.694921) = final_loss = 2.622404
n_iter 11 : loss (0.189773) + tot_loss (0.862690) + tot_loss_crop (0.854542) + loss_clip_order (0.692727) = final_loss = 2.599732
n_iter 12 : loss (0.188804) + tot_loss (0.870511) + tot_loss_crop (0.848608) + loss_clip_order (0.695791) = final_loss = 2.603714
n_iter 13 : loss (0.184304) + tot_loss (0.870803) + tot_loss_crop (0.852125) + loss_clip_order (0.696274) = final_loss = 2.603507
n_iter 14 : loss (0.171993) + tot_loss (0.870010) + tot_loss_crop (0.853542) + loss_clip_order (0.693737) = final_loss = 2.589282
n_iter 15 : loss (0.179033) + tot_loss (0.869000) + tot_loss_crop (0.847489) + loss_clip_order (0.695010) = final_loss = 2.590533
n_iter 16 : loss (0.173335) + tot_loss (0.863445) + tot_loss_crop (0.847296) + loss_clip_order (0.694174) = final_loss = 2.578251
n_iter 17 : loss (0.172316) + tot_loss (0.860186) + tot_loss_crop (0.848950) + loss_clip_order (0.695503) = final_loss = 2.576956
n_iter 18 : loss (0.170411) + tot_loss (0.858792) + tot_loss_crop (0.846344) + loss_clip_order (0.693901) = final_loss = 2.569448
n_iter 19 : loss (0.170526) + tot_loss (0.841938) + tot_loss_crop (0.844401) + loss_clip_order (0.694619) = final_loss = 2.551485
n_iter 20 : loss (0.164702) + tot_loss (0.851020) + tot_loss_crop (0.846768) + loss_clip_order (0.696514) = final_loss = 2.559004
n_iter 21 : loss (0.159851) + tot_loss (0.869221) + tot_loss_crop (0.849921) + loss_clip_order (0.695967) = final_loss = 2.574960
n_iter 22 : loss (0.170408) + tot_loss (0.846959) + tot_loss_crop (0.838298) + loss_clip_order (0.693754) = final_loss = 2.549420
n_iter 23 : loss (0.170778) + tot_loss (0.847686) + tot_loss_crop (0.843512) + loss_clip_order (0.695705) = final_loss = 2.557681
n_iter 24 : loss (0.168300) + tot_loss (0.835293) + tot_loss_crop (0.840233) + loss_clip_order (0.695996) = final_loss = 2.539823
n_iter 25 : loss (0.172329) + tot_loss (0.837278) + tot_loss_crop (0.834277) + loss_clip_order (0.696769) = final_loss = 2.540653
n_iter 26 : loss (0.162847) + tot_loss (0.844527) + tot_loss_crop (0.842844) + loss_clip_order (0.696898) = final_loss = 2.547114
n_iter 27 : loss (0.158413) + tot_loss (0.847834) + tot_loss_crop (0.843221) + loss_clip_order (0.692486) = final_loss = 2.541955
n_iter 28 : loss (0.163233) + tot_loss (0.820823) + tot_loss_crop (0.838498) + loss_clip_order (0.694937) = final_loss = 2.517491
n_iter 29 : loss (0.165894) + tot_loss (0.846967) + tot_loss_crop (0.836629) + loss_clip_order (0.693413) = final_loss = 2.542903
n_iter 30 : loss (0.162540) + tot_loss (0.842678) + tot_loss_crop (0.837021) + loss_clip_order (0.693626) = final_loss = 2.535865
[Pretraining Epoch 000] Total-Loss 0.84 =  F-Loss 0.84 + Clip-Loss 0.69 (train)
/root/models/venv_SPOT/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
n_iter  0 : loss (0.168233) + tot_loss (0.832463) + tot_loss_crop (0.834745) + loss_clip_order (0.692781) = final_loss = 2.528222
n_iter  1 : loss (0.171901) + tot_loss (0.852256) + tot_loss_crop (0.830803) + loss_clip_order (0.693870) = final_loss = 2.548831
n_iter  2 : loss (0.166134) + tot_loss (0.838158) + tot_loss_crop (0.832995) + loss_clip_order (0.695471) = final_loss = 2.532757
n_iter  3 : loss (0.170385) + tot_loss (0.828762) + tot_loss_crop (0.827428) + loss_clip_order (0.693435) = final_loss = 2.520010
n_iter  4 : loss (0.171223) + tot_loss (0.821481) + tot_loss_crop (0.830208) + loss_clip_order (0.693916) = final_loss = 2.516828
n_iter  5 : loss (0.170344) + tot_loss (0.822699) + tot_loss_crop (0.826256) + loss_clip_order (0.695513) = final_loss = 2.514812
n_iter  6 : loss (0.162128) + tot_loss (0.821697) + tot_loss_crop (0.829868) + loss_clip_order (0.693072) = final_loss = 2.506766
n_iter  7 : loss (0.160316) + tot_loss (0.802545) + tot_loss_crop (0.829077) + loss_clip_order (0.694240) = final_loss = 2.486178
n_iter  8 : loss (0.164167) + tot_loss (0.815243) + tot_loss_crop (0.829827) + loss_clip_order (0.694065) = final_loss = 2.503302
n_iter  9 : loss (0.168311) + tot_loss (0.807345) + tot_loss_crop (0.826653) + loss_clip_order (0.692927) = final_loss = 2.495236
n_iter 10 : loss (0.165052) + tot_loss (0.820984) + tot_loss_crop (0.825874) + loss_clip_order (0.691779) = final_loss = 2.503689
n_iter 11 : loss (0.171735) + tot_loss (0.806640) + tot_loss_crop (0.819028) + loss_clip_order (0.693709) = final_loss = 2.491112
n_iter 12 : loss (0.160096) + tot_loss (0.816181) + tot_loss_crop (0.822909) + loss_clip_order (0.693322) = final_loss = 2.492508
n_iter 13 : loss (0.169279) + tot_loss (0.816177) + tot_loss_crop (0.818010) + loss_clip_order (0.690847) = final_loss = 2.494313
n_iter 14 : loss (0.173586) + tot_loss (0.815796) + tot_loss_crop (0.816315) + loss_clip_order (0.694292) = final_loss = 2.499989
n_iter 15 : loss (0.163622) + tot_loss (0.813893) + tot_loss_crop (0.819197) + loss_clip_order (0.692357) = final_loss = 2.489068
n_iter 16 : loss (0.171242) + tot_loss (0.808634) + tot_loss_crop (0.818208) + loss_clip_order (0.693921) = final_loss = 2.492005
n_iter 17 : loss (0.164149) + tot_loss (0.806038) + tot_loss_crop (0.821025) + loss_clip_order (0.693178) = final_loss = 2.484391
n_iter 18 : loss (0.168559) + tot_loss (0.806375) + tot_loss_crop (0.815636) + loss_clip_order (0.692593) = final_loss = 2.483164
n_iter 19 : loss (0.174219) + tot_loss (0.792734) + tot_loss_crop (0.807971) + loss_clip_order (0.692677) = final_loss = 2.467601
n_iter 20 : loss (0.167579) + tot_loss (0.801990) + tot_loss_crop (0.814770) + loss_clip_order (0.693329) = final_loss = 2.477668
n_iter 21 : loss (0.169767) + tot_loss (0.820769) + tot_loss_crop (0.809428) + loss_clip_order (0.692616) = final_loss = 2.492579
n_iter 22 : loss (0.162244) + tot_loss (0.800281) + tot_loss_crop (0.814246) + loss_clip_order (0.690781) = final_loss = 2.467552
n_iter 23 : loss (0.155854) + tot_loss (0.801139) + tot_loss_crop (0.817569) + loss_clip_order (0.694230) = final_loss = 2.468791
n_iter 24 : loss (0.163622) + tot_loss (0.790515) + tot_loss_crop (0.811080) + loss_clip_order (0.691008) = final_loss = 2.456224
n_iter 25 : loss (0.162601) + tot_loss (0.792784) + tot_loss_crop (0.809363) + loss_clip_order (0.692842) = final_loss = 2.457589
n_iter 26 : loss (0.161754) + tot_loss (0.800041) + tot_loss_crop (0.812283) + loss_clip_order (0.692986) = final_loss = 2.467064
n_iter 27 : loss (0.163210) + tot_loss (0.802775) + tot_loss_crop (0.806979) + loss_clip_order (0.691335) = final_loss = 2.464298
n_iter 28 : loss (0.165766) + tot_loss (0.777564) + tot_loss_crop (0.803299) + loss_clip_order (0.693064) = final_loss = 2.439693
n_iter 29 : loss (0.157056) + tot_loss (0.801951) + tot_loss_crop (0.810439) + loss_clip_order (0.693217) = final_loss = 2.462664
n_iter 30 : loss (0.164671) + tot_loss (0.797187) + tot_loss_crop (0.805092) + loss_clip_order (0.690688) = final_loss = 2.457639
[Pretraining Epoch 001] Total-Loss 0.80 =  F-Loss 0.80 + Clip-Loss 0.69 (train)
n_iter  0 : loss (0.168993) + tot_loss (0.787765) + tot_loss_crop (0.800054) + loss_clip_order (0.692226) = final_loss = 2.449037
n_iter  1 : loss (0.156278) + tot_loss (0.807357) + tot_loss_crop (0.807067) + loss_clip_order (0.693104) = final_loss = 2.463806
n_iter  2 : loss (0.159333) + tot_loss (0.794322) + tot_loss_crop (0.801841) + loss_clip_order (0.690330) = final_loss = 2.445826
n_iter  3 : loss (0.156664) + tot_loss (0.785839) + tot_loss_crop (0.804172) + loss_clip_order (0.692142) = final_loss = 2.438817
n_iter  4 : loss (0.165708) + tot_loss (0.779969) + tot_loss_crop (0.797988) + loss_clip_order (0.691759) = final_loss = 2.435424
n_iter  5 : loss (0.174950) + tot_loss (0.781475) + tot_loss_crop (0.789810) + loss_clip_order (0.692182) = final_loss = 2.438418
n_iter  6 : loss (0.161439) + tot_loss (0.780220) + tot_loss_crop (0.798080) + loss_clip_order (0.689677) = final_loss = 2.429416
n_iter  7 : loss (0.166582) + tot_loss (0.761855) + tot_loss_crop (0.793336) + loss_clip_order (0.690281) = final_loss = 2.412054
n_iter  8 : loss (0.167913) + tot_loss (0.772120) + tot_loss_crop (0.793571) + loss_clip_order (0.695367) = final_loss = 2.428971
n_iter  9 : loss (0.168611) + tot_loss (0.764596) + tot_loss_crop (0.792256) + loss_clip_order (0.687923) = final_loss = 2.413386
n_iter 10 : loss (0.168855) + tot_loss (0.777548) + tot_loss_crop (0.791023) + loss_clip_order (0.690429) = final_loss = 2.427855
n_iter 11 : loss (0.162950) + tot_loss (0.763452) + tot_loss_crop (0.790242) + loss_clip_order (0.688318) = final_loss = 2.404963
n_iter 12 : loss (0.168306) + tot_loss (0.774529) + tot_loss_crop (0.786120) + loss_clip_order (0.691289) = final_loss = 2.420243
n_iter 13 : loss (0.157820) + tot_loss (0.774464) + tot_loss_crop (0.793147) + loss_clip_order (0.685302) = final_loss = 2.410734
n_iter 14 : loss (0.162611) + tot_loss (0.775880) + tot_loss_crop (0.789333) + loss_clip_order (0.688044) = final_loss = 2.415869
n_iter 15 : loss (0.170150) + tot_loss (0.773431) + tot_loss_crop (0.781990) + loss_clip_order (0.683713) = final_loss = 2.409284
n_iter 16 : loss (0.164647) + tot_loss (0.768730) + tot_loss_crop (0.784328) + loss_clip_order (0.686970) = final_loss = 2.404675
n_iter 17 : loss (0.167059) + tot_loss (0.766455) + tot_loss_crop (0.784785) + loss_clip_order (0.686882) = final_loss = 2.405180
n_iter 18 : loss (0.167062) + tot_loss (0.765925) + tot_loss_crop (0.782824) + loss_clip_order (0.687688) = final_loss = 2.403499
n_iter 19 : loss (0.175141) + tot_loss (0.753517) + tot_loss_crop (0.773862) + loss_clip_order (0.688531) = final_loss = 2.391050
n_iter 20 : loss (0.165770) + tot_loss (0.761650) + tot_loss_crop (0.780015) + loss_clip_order (0.682196) = final_loss = 2.389631
n_iter 21 : loss (0.153543) + tot_loss (0.779794) + tot_loss_crop (0.786856) + loss_clip_order (0.678664) = final_loss = 2.398857
n_iter 22 : loss (0.173105) + tot_loss (0.760469) + tot_loss_crop (0.772958) + loss_clip_order (0.677096) = final_loss = 2.383628
n_iter 23 : loss (0.156426) + tot_loss (0.760931) + tot_loss_crop (0.782004) + loss_clip_order (0.680572) = final_loss = 2.379933
n_iter 24 : loss (0.164450) + tot_loss (0.751156) + tot_loss_crop (0.778320) + loss_clip_order (0.672634) = final_loss = 2.366560
n_iter 25 : loss (0.168917) + tot_loss (0.753083) + tot_loss_crop (0.770942) + loss_clip_order (0.672935) = final_loss = 2.365877
n_iter 26 : loss (0.164828) + tot_loss (0.759373) + tot_loss_crop (0.772253) + loss_clip_order (0.665414) = final_loss = 2.361869
n_iter 27 : loss (0.162392) + tot_loss (0.762641) + tot_loss_crop (0.777330) + loss_clip_order (0.665090) = final_loss = 2.367454
n_iter 28 : loss (0.173891) + tot_loss (0.739666) + tot_loss_crop (0.766931) + loss_clip_order (0.654738) = final_loss = 2.335226
n_iter 29 : loss (0.158278) + tot_loss (0.763365) + tot_loss_crop (0.776098) + loss_clip_order (0.643338) = final_loss = 2.341079
n_iter 30 : loss (0.155988) + tot_loss (0.758739) + tot_loss_crop (0.773080) + loss_clip_order (0.628380) = final_loss = 2.316187
[Pretraining Epoch 002] Total-Loss 0.76 =  F-Loss 0.76 + Clip-Loss 0.63 (train)
training epoch 0
use Semi !!!
[Iteration 000] Total-Loss 6.20 = T-Loss 5.50 + B-Loss 0.71 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 5.22 = T-Loss 4.53 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 5.15 = T-Loss 4.47 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 5.16 = T-Loss 4.49 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 000] Total-Loss 5.16 = T-Loss 4.49 + B-Loss 0.67 (train)[0m
[Epoch 000] Total-Loss 5.06 = T-Loss 4.41 + B-Loss 0.64  (val)
training epoch 1
use Semi !!!
[Iteration 000] Total-Loss 4.69 = T-Loss 4.02 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.80 = T-Loss 4.15 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.80 = T-Loss 4.14 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.84 = T-Loss 4.18 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 001] Total-Loss 4.84 = T-Loss 4.18 + B-Loss 0.65 (train)[0m
[Epoch 001] Total-Loss 4.89 = T-Loss 4.25 + B-Loss 0.65  (val)
training epoch 2
use Semi !!!
[Iteration 000] Total-Loss 4.27 = T-Loss 3.60 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.51 = T-Loss 3.85 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.43 = T-Loss 3.78 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.34 = T-Loss 3.69 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 002] Total-Loss 4.34 = T-Loss 3.69 + B-Loss 0.65 (train)[0m
[Epoch 002] Total-Loss 4.09 = T-Loss 3.43 + B-Loss 0.66  (val)
3
n_iter  0 : loss (0.243082) + tot_loss (0.714612) + tot_loss_crop (0.736085) + loss_clip_order (0.616743) = final_loss = 2.310522
n_iter  1 : loss (0.242372) + tot_loss (0.734506) + tot_loss_crop (0.737953) + loss_clip_order (0.619402) = final_loss = 2.334233
n_iter  2 : loss (0.240314) + tot_loss (0.722147) + tot_loss_crop (0.738751) + loss_clip_order (0.589215) = final_loss = 2.290427
n_iter  3 : loss (0.237661) + tot_loss (0.714151) + tot_loss_crop (0.738172) + loss_clip_order (0.583954) = final_loss = 2.273938
n_iter  4 : loss (0.234222) + tot_loss (0.708698) + tot_loss_crop (0.741033) + loss_clip_order (0.543404) = final_loss = 2.227357
n_iter  5 : loss (0.233021) + tot_loss (0.710932) + tot_loss_crop (0.737643) + loss_clip_order (0.539609) = final_loss = 2.221204
n_iter  6 : loss (0.227893) + tot_loss (0.710755) + tot_loss_crop (0.736161) + loss_clip_order (0.515016) = final_loss = 2.189826
n_iter  7 : loss (0.223096) + tot_loss (0.695267) + tot_loss_crop (0.733307) + loss_clip_order (0.506064) = final_loss = 2.157734
n_iter  8 : loss (0.219022) + tot_loss (0.705720) + tot_loss_crop (0.732680) + loss_clip_order (0.509664) = final_loss = 2.167086
n_iter  9 : loss (0.213077) + tot_loss (0.699997) + tot_loss_crop (0.731098) + loss_clip_order (0.502144) = final_loss = 2.146316
n_iter 10 : loss (0.203514) + tot_loss (0.712305) + tot_loss_crop (0.735080) + loss_clip_order (0.491169) = final_loss = 2.142068
n_iter 11 : loss (0.199562) + tot_loss (0.699226) + tot_loss_crop (0.727737) + loss_clip_order (0.482725) = final_loss = 2.109250
n_iter 12 : loss (0.188500) + tot_loss (0.710606) + tot_loss_crop (0.730639) + loss_clip_order (0.455799) = final_loss = 2.085543
n_iter 13 : loss (0.179334) + tot_loss (0.709919) + tot_loss_crop (0.734822) + loss_clip_order (0.414527) = final_loss = 2.038602
n_iter 14 : loss (0.179755) + tot_loss (0.713112) + tot_loss_crop (0.727958) + loss_clip_order (0.412757) = final_loss = 2.033582
n_iter 15 : loss (0.165030) + tot_loss (0.711085) + tot_loss_crop (0.730227) + loss_clip_order (0.410962) = final_loss = 2.017304
n_iter 16 : loss (0.161569) + tot_loss (0.710117) + tot_loss_crop (0.728622) + loss_clip_order (0.401767) = final_loss = 2.002076
n_iter 17 : loss (0.161758) + tot_loss (0.710206) + tot_loss_crop (0.728933) + loss_clip_order (0.406776) = final_loss = 2.007673
n_iter 18 : loss (0.167243) + tot_loss (0.711048) + tot_loss_crop (0.725101) + loss_clip_order (0.380769) = final_loss = 1.984161
n_iter 19 : loss (0.162281) + tot_loss (0.700058) + tot_loss_crop (0.724916) + loss_clip_order (0.399421) = final_loss = 1.986676
n_iter 20 : loss (0.183046) + tot_loss (0.707900) + tot_loss_crop (0.715631) + loss_clip_order (0.389582) = final_loss = 1.996159
n_iter 21 : loss (0.151981) + tot_loss (0.726525) + tot_loss_crop (0.728187) + loss_clip_order (0.392803) = final_loss = 1.999497
n_iter 22 : loss (0.177151) + tot_loss (0.706099) + tot_loss_crop (0.718283) + loss_clip_order (0.391619) = final_loss = 1.993153
n_iter 23 : loss (0.160523) + tot_loss (0.706815) + tot_loss_crop (0.723687) + loss_clip_order (0.381178) = final_loss = 1.972203
n_iter 24 : loss (0.165588) + tot_loss (0.695992) + tot_loss_crop (0.719122) + loss_clip_order (0.368490) = final_loss = 1.949191
n_iter 25 : loss (0.170622) + tot_loss (0.698831) + tot_loss_crop (0.713511) + loss_clip_order (0.366642) = final_loss = 1.949606
n_iter 26 : loss (0.162389) + tot_loss (0.703004) + tot_loss_crop (0.719552) + loss_clip_order (0.381826) = final_loss = 1.966771
n_iter 27 : loss (0.177173) + tot_loss (0.706180) + tot_loss_crop (0.710838) + loss_clip_order (0.357692) = final_loss = 1.951883
n_iter 28 : loss (0.162176) + tot_loss (0.684280) + tot_loss_crop (0.715344) + loss_clip_order (0.347163) = final_loss = 1.908963
n_iter 29 : loss (0.175915) + tot_loss (0.707141) + tot_loss_crop (0.712474) + loss_clip_order (0.360900) = final_loss = 1.956430
n_iter 30 : loss (0.172379) + tot_loss (0.702004) + tot_loss_crop (0.710183) + loss_clip_order (0.356171) = final_loss = 1.940737
[Pretraining Epoch 003] Total-Loss 0.70 =  F-Loss 0.70 + Clip-Loss 0.36 (train)
n_iter  0 : loss (0.167201) + tot_loss (0.693869) + tot_loss_crop (0.711891) + loss_clip_order (0.362203) = final_loss = 1.935163
n_iter  1 : loss (0.170784) + tot_loss (0.712316) + tot_loss_crop (0.713954) + loss_clip_order (0.362720) = final_loss = 1.959774
n_iter  2 : loss (0.164967) + tot_loss (0.699767) + tot_loss_crop (0.711402) + loss_clip_order (0.352516) = final_loss = 1.928652
n_iter  3 : loss (0.166619) + tot_loss (0.691470) + tot_loss_crop (0.711220) + loss_clip_order (0.349403) = final_loss = 1.918713
n_iter  4 : loss (0.155172) + tot_loss (0.686949) + tot_loss_crop (0.713786) + loss_clip_order (0.345721) = final_loss = 1.901629
n_iter  5 : loss (0.151690) + tot_loss (0.689939) + tot_loss_crop (0.715654) + loss_clip_order (0.340930) = final_loss = 1.898212
n_iter  6 : loss (0.151309) + tot_loss (0.689115) + tot_loss_crop (0.710335) + loss_clip_order (0.352226) = final_loss = 1.902985
n_iter  7 : loss (0.160849) + tot_loss (0.674113) + tot_loss_crop (0.705730) + loss_clip_order (0.347638) = final_loss = 1.888330
n_iter  8 : loss (0.160856) + tot_loss (0.684347) + tot_loss_crop (0.705971) + loss_clip_order (0.352031) = final_loss = 1.903204
n_iter  9 : loss (0.154257) + tot_loss (0.678853) + tot_loss_crop (0.708292) + loss_clip_order (0.347950) = final_loss = 1.889351
n_iter 10 : loss (0.164780) + tot_loss (0.690259) + tot_loss_crop (0.699551) + loss_clip_order (0.348868) = final_loss = 1.903458
n_iter 11 : loss (0.173530) + tot_loss (0.677139) + tot_loss_crop (0.695454) + loss_clip_order (0.348872) = final_loss = 1.894995
n_iter 12 : loss (0.167262) + tot_loss (0.687407) + tot_loss_crop (0.695352) + loss_clip_order (0.347242) = final_loss = 1.897263
n_iter 13 : loss (0.161133) + tot_loss (0.686502) + tot_loss_crop (0.698995) + loss_clip_order (0.337267) = final_loss = 1.883897
n_iter 14 : loss (0.147422) + tot_loss (0.688034) + tot_loss_crop (0.706383) + loss_clip_order (0.342551) = final_loss = 1.884389
n_iter 15 : loss (0.168392) + tot_loss (0.684854) + tot_loss_crop (0.698206) + loss_clip_order (0.347166) = final_loss = 1.898618
n_iter 16 : loss (0.170768) + tot_loss (0.682023) + tot_loss_crop (0.693442) + loss_clip_order (0.339687) = final_loss = 1.885920
n_iter 17 : loss (0.158472) + tot_loss (0.680283) + tot_loss_crop (0.699032) + loss_clip_order (0.351227) = final_loss = 1.889014
n_iter 18 : loss (0.163221) + tot_loss (0.679924) + tot_loss_crop (0.693860) + loss_clip_order (0.338710) = final_loss = 1.875715
n_iter 19 : loss (0.167434) + tot_loss (0.668864) + tot_loss_crop (0.688157) + loss_clip_order (0.350874) = final_loss = 1.875329
n_iter 20 : loss (0.167581) + tot_loss (0.676515) + tot_loss_crop (0.687409) + loss_clip_order (0.347282) = final_loss = 1.878787
n_iter 21 : loss (0.160710) + tot_loss (0.694867) + tot_loss_crop (0.692280) + loss_clip_order (0.334928) = final_loss = 1.882786
n_iter 22 : loss (0.169100) + tot_loss (0.675497) + tot_loss_crop (0.685380) + loss_clip_order (0.339365) = final_loss = 1.869342
n_iter 23 : loss (0.152088) + tot_loss (0.677099) + tot_loss_crop (0.695833) + loss_clip_order (0.331031) = final_loss = 1.856051
n_iter 24 : loss (0.151500) + tot_loss (0.667123) + tot_loss_crop (0.691727) + loss_clip_order (0.332249) = final_loss = 1.842599
n_iter 25 : loss (0.169012) + tot_loss (0.670454) + tot_loss_crop (0.683963) + loss_clip_order (0.334488) = final_loss = 1.857918
n_iter 26 : loss (0.160021) + tot_loss (0.674618) + tot_loss_crop (0.688133) + loss_clip_order (0.343024) = final_loss = 1.865796
n_iter 27 : loss (0.158943) + tot_loss (0.677936) + tot_loss_crop (0.687687) + loss_clip_order (0.339064) = final_loss = 1.863629
n_iter 28 : loss (0.164454) + tot_loss (0.656687) + tot_loss_crop (0.682764) + loss_clip_order (0.327814) = final_loss = 1.831719
n_iter 29 : loss (0.157986) + tot_loss (0.679488) + tot_loss_crop (0.688599) + loss_clip_order (0.337609) = final_loss = 1.863681
n_iter 30 : loss (0.159670) + tot_loss (0.675184) + tot_loss_crop (0.685825) + loss_clip_order (0.333744) = final_loss = 1.854424
[Pretraining Epoch 004] Total-Loss 0.68 =  F-Loss 0.68 + Clip-Loss 0.33 (train)
n_iter  0 : loss (0.165249) + tot_loss (0.667628) + tot_loss_crop (0.682117) + loss_clip_order (0.331672) = final_loss = 1.846665
n_iter  1 : loss (0.168490) + tot_loss (0.686342) + tot_loss_crop (0.681237) + loss_clip_order (0.329403) = final_loss = 1.865472
n_iter  2 : loss (0.163559) + tot_loss (0.674103) + tot_loss_crop (0.679968) + loss_clip_order (0.328294) = final_loss = 1.845924
n_iter  3 : loss (0.162377) + tot_loss (0.666061) + tot_loss_crop (0.680100) + loss_clip_order (0.327734) = final_loss = 1.836271
n_iter  4 : loss (0.171676) + tot_loss (0.661166) + tot_loss_crop (0.671207) + loss_clip_order (0.328765) = final_loss = 1.832814
n_iter  5 : loss (0.159648) + tot_loss (0.663345) + tot_loss_crop (0.678782) + loss_clip_order (0.321966) = final_loss = 1.823742
n_iter  6 : loss (0.157233) + tot_loss (0.661635) + tot_loss_crop (0.675775) + loss_clip_order (0.332370) = final_loss = 1.827013
n_iter  7 : loss (0.168449) + tot_loss (0.646342) + tot_loss_crop (0.675089) + loss_clip_order (0.332542) = final_loss = 1.822422
n_iter  8 : loss (0.160091) + tot_loss (0.655818) + tot_loss_crop (0.671477) + loss_clip_order (0.329447) = final_loss = 1.816833
n_iter  9 : loss (0.171995) + tot_loss (0.650359) + tot_loss_crop (0.669597) + loss_clip_order (0.332416) = final_loss = 1.824367
n_iter 10 : loss (0.166263) + tot_loss (0.661571) + tot_loss_crop (0.669955) + loss_clip_order (0.326822) = final_loss = 1.824611
n_iter 11 : loss (0.165166) + tot_loss (0.648648) + tot_loss_crop (0.669183) + loss_clip_order (0.330352) = final_loss = 1.813350
n_iter 12 : loss (0.153803) + tot_loss (0.658820) + tot_loss_crop (0.672556) + loss_clip_order (0.323866) = final_loss = 1.809045
n_iter 13 : loss (0.164132) + tot_loss (0.658615) + tot_loss_crop (0.665695) + loss_clip_order (0.323491) = final_loss = 1.811933
n_iter 14 : loss (0.166087) + tot_loss (0.660710) + tot_loss_crop (0.666618) + loss_clip_order (0.330942) = final_loss = 1.824356
n_iter 15 : loss (0.159930) + tot_loss (0.657644) + tot_loss_crop (0.669872) + loss_clip_order (0.330628) = final_loss = 1.818074
n_iter 16 : loss (0.159833) + tot_loss (0.654857) + tot_loss_crop (0.667984) + loss_clip_order (0.318529) = final_loss = 1.801204
n_iter 17 : loss (0.170048) + tot_loss (0.653242) + tot_loss_crop (0.662736) + loss_clip_order (0.326857) = final_loss = 1.812882
n_iter 18 : loss (0.153723) + tot_loss (0.652511) + tot_loss_crop (0.668388) + loss_clip_order (0.326235) = final_loss = 1.800856
n_iter 19 : loss (0.157460) + tot_loss (0.641170) + tot_loss_crop (0.666794) + loss_clip_order (0.328812) = final_loss = 1.794236
n_iter 20 : loss (0.156144) + tot_loss (0.648671) + tot_loss_crop (0.662786) + loss_clip_order (0.321958) = final_loss = 1.789559
n_iter 21 : loss (0.161208) + tot_loss (0.666748) + tot_loss_crop (0.661178) + loss_clip_order (0.325217) = final_loss = 1.814351
n_iter 22 : loss (0.163551) + tot_loss (0.647899) + tot_loss_crop (0.660600) + loss_clip_order (0.329407) = final_loss = 1.801457
n_iter 23 : loss (0.160002) + tot_loss (0.649454) + tot_loss_crop (0.661705) + loss_clip_order (0.322456) = final_loss = 1.793616
n_iter 24 : loss (0.162583) + tot_loss (0.639851) + tot_loss_crop (0.657841) + loss_clip_order (0.323296) = final_loss = 1.783571
n_iter 25 : loss (0.158681) + tot_loss (0.642849) + tot_loss_crop (0.659478) + loss_clip_order (0.318445) = final_loss = 1.779453
n_iter 26 : loss (0.163474) + tot_loss (0.646961) + tot_loss_crop (0.657739) + loss_clip_order (0.328542) = final_loss = 1.796717
n_iter 27 : loss (0.166974) + tot_loss (0.650146) + tot_loss_crop (0.653836) + loss_clip_order (0.324251) = final_loss = 1.795208
n_iter 28 : loss (0.163707) + tot_loss (0.629091) + tot_loss_crop (0.652955) + loss_clip_order (0.318040) = final_loss = 1.763793
n_iter 29 : loss (0.155553) + tot_loss (0.651183) + tot_loss_crop (0.658607) + loss_clip_order (0.323444) = final_loss = 1.788787
n_iter 30 : loss (0.155863) + tot_loss (0.646810) + tot_loss_crop (0.656008) + loss_clip_order (0.317676) = final_loss = 1.776357
[Pretraining Epoch 005] Total-Loss 0.65 =  F-Loss 0.65 + Clip-Loss 0.32 (train)
training epoch 3
use Semi !!!
[Iteration 000] Total-Loss 5.78 = T-Loss 5.08 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.72 = T-Loss 4.03 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.31 = T-Loss 3.63 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.00 = T-Loss 3.32 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 003] Total-Loss 4.00 = T-Loss 3.32 + B-Loss 0.68 (train)[0m
[Epoch 003] Total-Loss 3.80 = T-Loss 3.13 + B-Loss 0.67  (val)
training epoch 4
use Semi !!!
[Iteration 000] Total-Loss 2.94 = T-Loss 2.27 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.12 = T-Loss 2.46 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.01 = T-Loss 2.35 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 2.91 = T-Loss 2.25 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 004] Total-Loss 2.91 = T-Loss 2.25 + B-Loss 0.66 (train)[0m
[Epoch 004] Total-Loss 3.17 = T-Loss 2.51 + B-Loss 0.66  (val)
training epoch 5
use Semi !!!
[Iteration 000] Total-Loss 2.32 = T-Loss 1.65 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.49 = T-Loss 1.84 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.44 = T-Loss 1.78 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 2.37 = T-Loss 1.72 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 005] Total-Loss 2.37 = T-Loss 1.72 + B-Loss 0.66 (train)[0m
[Epoch 005] Total-Loss 2.98 = T-Loss 2.32 + B-Loss 0.66  (val)
6
n_iter  0 : loss (0.239021) + tot_loss (0.625690) + tot_loss_crop (0.639092) + loss_clip_order (0.528373) = final_loss = 2.032175
n_iter  1 : loss (0.237588) + tot_loss (0.644016) + tot_loss_crop (0.644172) + loss_clip_order (0.490683) = final_loss = 2.016458
n_iter  2 : loss (0.235176) + tot_loss (0.632026) + tot_loss_crop (0.643585) + loss_clip_order (0.437907) = final_loss = 1.948694
n_iter  3 : loss (0.232193) + tot_loss (0.624631) + tot_loss_crop (0.643712) + loss_clip_order (0.552307) = final_loss = 2.052843
n_iter  4 : loss (0.223958) + tot_loss (0.619924) + tot_loss_crop (0.640134) + loss_clip_order (0.449575) = final_loss = 1.933592
n_iter  5 : loss (0.216565) + tot_loss (0.624279) + tot_loss_crop (0.640777) + loss_clip_order (0.491702) = final_loss = 1.973323
n_iter  6 : loss (0.210773) + tot_loss (0.624269) + tot_loss_crop (0.630954) + loss_clip_order (0.505219) = final_loss = 1.971215
n_iter  7 : loss (0.201546) + tot_loss (0.609564) + tot_loss_crop (0.636582) + loss_clip_order (0.425392) = final_loss = 1.873084
n_iter  8 : loss (0.194630) + tot_loss (0.618054) + tot_loss_crop (0.637194) + loss_clip_order (0.350396) = final_loss = 1.800273
n_iter  9 : loss (0.189655) + tot_loss (0.612178) + tot_loss_crop (0.637216) + loss_clip_order (0.340953) = final_loss = 1.780001
n_iter 10 : loss (0.189003) + tot_loss (0.623505) + tot_loss_crop (0.630751) + loss_clip_order (0.354278) = final_loss = 1.797537
n_iter 11 : loss (0.184380) + tot_loss (0.610679) + tot_loss_crop (0.628686) + loss_clip_order (0.349788) = final_loss = 1.773534
n_iter 12 : loss (0.169439) + tot_loss (0.621937) + tot_loss_crop (0.629919) + loss_clip_order (0.342670) = final_loss = 1.763965
n_iter 13 : loss (0.164682) + tot_loss (0.623060) + tot_loss_crop (0.633685) + loss_clip_order (0.314663) = final_loss = 1.736090
n_iter 14 : loss (0.161993) + tot_loss (0.628267) + tot_loss_crop (0.630269) + loss_clip_order (0.326247) = final_loss = 1.746776
n_iter 15 : loss (0.170932) + tot_loss (0.628272) + tot_loss_crop (0.626084) + loss_clip_order (0.321037) = final_loss = 1.746326
n_iter 16 : loss (0.177674) + tot_loss (0.629028) + tot_loss_crop (0.625314) + loss_clip_order (0.314345) = final_loss = 1.746360
n_iter 17 : loss (0.167128) + tot_loss (0.630047) + tot_loss_crop (0.627448) + loss_clip_order (0.321201) = final_loss = 1.745823
n_iter 18 : loss (0.169757) + tot_loss (0.631108) + tot_loss_crop (0.629402) + loss_clip_order (0.317631) = final_loss = 1.747898
n_iter 19 : loss (0.165611) + tot_loss (0.619712) + tot_loss_crop (0.626216) + loss_clip_order (0.320893) = final_loss = 1.732432
n_iter 20 : loss (0.176002) + tot_loss (0.627925) + tot_loss_crop (0.621365) + loss_clip_order (0.322135) = final_loss = 1.747427
n_iter 21 : loss (0.156005) + tot_loss (0.647171) + tot_loss_crop (0.628797) + loss_clip_order (0.318393) = final_loss = 1.750365
n_iter 22 : loss (0.165143) + tot_loss (0.625999) + tot_loss_crop (0.623601) + loss_clip_order (0.327267) = final_loss = 1.742010
n_iter 23 : loss (0.150977) + tot_loss (0.628117) + tot_loss_crop (0.627560) + loss_clip_order (0.312839) = final_loss = 1.719492
n_iter 24 : loss (0.163700) + tot_loss (0.615721) + tot_loss_crop (0.620572) + loss_clip_order (0.313703) = final_loss = 1.713696
n_iter 25 : loss (0.159334) + tot_loss (0.618897) + tot_loss_crop (0.621187) + loss_clip_order (0.311685) = final_loss = 1.711103
n_iter 26 : loss (0.158650) + tot_loss (0.620931) + tot_loss_crop (0.620728) + loss_clip_order (0.318602) = final_loss = 1.718911
n_iter 27 : loss (0.153290) + tot_loss (0.622632) + tot_loss_crop (0.622741) + loss_clip_order (0.305508) = final_loss = 1.704172
n_iter 28 : loss (0.162730) + tot_loss (0.600791) + tot_loss_crop (0.615345) + loss_clip_order (0.309706) = final_loss = 1.688572
n_iter 29 : loss (0.162631) + tot_loss (0.621048) + tot_loss_crop (0.617299) + loss_clip_order (0.311976) = final_loss = 1.712954
n_iter 30 : loss (0.161781) + tot_loss (0.615441) + tot_loss_crop (0.617329) + loss_clip_order (0.308187) = final_loss = 1.702738
[Pretraining Epoch 006] Total-Loss 0.62 =  F-Loss 0.62 + Clip-Loss 0.31 (train)
n_iter  0 : loss (0.168761) + tot_loss (0.607336) + tot_loss_crop (0.612094) + loss_clip_order (0.309211) = final_loss = 1.697402
n_iter  1 : loss (0.158004) + tot_loss (0.624719) + tot_loss_crop (0.614718) + loss_clip_order (0.326484) = final_loss = 1.723925
n_iter  2 : loss (0.165550) + tot_loss (0.612889) + tot_loss_crop (0.608936) + loss_clip_order (0.311956) = final_loss = 1.699332
n_iter  3 : loss (0.168244) + tot_loss (0.604774) + tot_loss_crop (0.607147) + loss_clip_order (0.304195) = final_loss = 1.684361
n_iter  4 : loss (0.155990) + tot_loss (0.599868) + tot_loss_crop (0.610466) + loss_clip_order (0.307532) = final_loss = 1.673856
n_iter  5 : loss (0.161847) + tot_loss (0.602834) + tot_loss_crop (0.608697) + loss_clip_order (0.303071) = final_loss = 1.676448
n_iter  6 : loss (0.160415) + tot_loss (0.600948) + tot_loss_crop (0.609392) + loss_clip_order (0.312410) = final_loss = 1.683165
n_iter  7 : loss (0.165663) + tot_loss (0.586399) + tot_loss_crop (0.602375) + loss_clip_order (0.307454) = final_loss = 1.661891
n_iter  8 : loss (0.174109) + tot_loss (0.595451) + tot_loss_crop (0.600394) + loss_clip_order (0.315593) = final_loss = 1.685547
n_iter  9 : loss (0.152940) + tot_loss (0.590282) + tot_loss_crop (0.606556) + loss_clip_order (0.316062) = final_loss = 1.665840
n_iter 10 : loss (0.164351) + tot_loss (0.600920) + tot_loss_crop (0.601856) + loss_clip_order (0.315666) = final_loss = 1.682793
n_iter 11 : loss (0.177595) + tot_loss (0.588434) + tot_loss_crop (0.594851) + loss_clip_order (0.313112) = final_loss = 1.673992
n_iter 12 : loss (0.168554) + tot_loss (0.598197) + tot_loss_crop (0.596084) + loss_clip_order (0.306269) = final_loss = 1.669103
n_iter 13 : loss (0.152451) + tot_loss (0.597075) + tot_loss_crop (0.605629) + loss_clip_order (0.302713) = final_loss = 1.657868
n_iter 14 : loss (0.158131) + tot_loss (0.599147) + tot_loss_crop (0.596928) + loss_clip_order (0.310949) = final_loss = 1.665155
n_iter 15 : loss (0.172028) + tot_loss (0.596025) + tot_loss_crop (0.594448) + loss_clip_order (0.311613) = final_loss = 1.674114
n_iter 16 : loss (0.159295) + tot_loss (0.593490) + tot_loss_crop (0.595813) + loss_clip_order (0.301085) = final_loss = 1.649683
n_iter 17 : loss (0.164629) + tot_loss (0.592157) + tot_loss_crop (0.594957) + loss_clip_order (0.326171) = final_loss = 1.677914
n_iter 18 : loss (0.151355) + tot_loss (0.591895) + tot_loss_crop (0.597359) + loss_clip_order (0.304431) = final_loss = 1.645040
n_iter 19 : loss (0.159566) + tot_loss (0.581331) + tot_loss_crop (0.591900) + loss_clip_order (0.304573) = final_loss = 1.637371
n_iter 20 : loss (0.170797) + tot_loss (0.588776) + tot_loss_crop (0.586954) + loss_clip_order (0.308941) = final_loss = 1.655468
n_iter 21 : loss (0.162497) + tot_loss (0.606648) + tot_loss_crop (0.588974) + loss_clip_order (0.302788) = final_loss = 1.660907
n_iter 22 : loss (0.165152) + tot_loss (0.588607) + tot_loss_crop (0.588341) + loss_clip_order (0.307335) = final_loss = 1.649435
n_iter 23 : loss (0.165129) + tot_loss (0.590272) + tot_loss_crop (0.585396) + loss_clip_order (0.300317) = final_loss = 1.641113
n_iter 24 : loss (0.165041) + tot_loss (0.580653) + tot_loss_crop (0.582987) + loss_clip_order (0.302867) = final_loss = 1.631548
n_iter 25 : loss (0.165045) + tot_loss (0.584422) + tot_loss_crop (0.584248) + loss_clip_order (0.292719) = final_loss = 1.626434
n_iter 26 : loss (0.163023) + tot_loss (0.588117) + tot_loss_crop (0.582400) + loss_clip_order (0.304426) = final_loss = 1.637966
n_iter 27 : loss (0.167270) + tot_loss (0.591245) + tot_loss_crop (0.579702) + loss_clip_order (0.298092) = final_loss = 1.636309
n_iter 28 : loss (0.172306) + tot_loss (0.570858) + tot_loss_crop (0.576259) + loss_clip_order (0.304623) = final_loss = 1.624046
n_iter 29 : loss (0.171096) + tot_loss (0.591614) + tot_loss_crop (0.579317) + loss_clip_order (0.304427) = final_loss = 1.646454
n_iter 30 : loss (0.161054) + tot_loss (0.587185) + tot_loss_crop (0.578044) + loss_clip_order (0.296414) = final_loss = 1.622697
[Pretraining Epoch 007] Total-Loss 0.59 =  F-Loss 0.59 + Clip-Loss 0.30 (train)
n_iter  0 : loss (0.160563) + tot_loss (0.579483) + tot_loss_crop (0.581085) + loss_clip_order (0.300326) = final_loss = 1.621457
n_iter  1 : loss (0.171212) + tot_loss (0.597572) + tot_loss_crop (0.576998) + loss_clip_order (0.302973) = final_loss = 1.648756
n_iter  2 : loss (0.171448) + tot_loss (0.586330) + tot_loss_crop (0.573094) + loss_clip_order (0.302862) = final_loss = 1.633734
n_iter  3 : loss (0.164866) + tot_loss (0.578262) + tot_loss_crop (0.572997) + loss_clip_order (0.295838) = final_loss = 1.611963
n_iter  4 : loss (0.157622) + tot_loss (0.573757) + tot_loss_crop (0.575063) + loss_clip_order (0.295557) = final_loss = 1.601999
n_iter  5 : loss (0.170555) + tot_loss (0.576913) + tot_loss_crop (0.569065) + loss_clip_order (0.298809) = final_loss = 1.615342
n_iter  6 : loss (0.167582) + tot_loss (0.575251) + tot_loss_crop (0.567426) + loss_clip_order (0.306285) = final_loss = 1.616545
n_iter  7 : loss (0.153698) + tot_loss (0.560969) + tot_loss_crop (0.570500) + loss_clip_order (0.297747) = final_loss = 1.582914
n_iter  8 : loss (0.167491) + tot_loss (0.570047) + tot_loss_crop (0.567208) + loss_clip_order (0.294371) = final_loss = 1.599117
n_iter  9 : loss (0.152346) + tot_loss (0.564913) + tot_loss_crop (0.571985) + loss_clip_order (0.295071) = final_loss = 1.584314
n_iter 10 : loss (0.167971) + tot_loss (0.575239) + tot_loss_crop (0.565145) + loss_clip_order (0.300389) = final_loss = 1.608744
n_iter 11 : loss (0.166364) + tot_loss (0.563205) + tot_loss_crop (0.559680) + loss_clip_order (0.297619) = final_loss = 1.586868
n_iter 12 : loss (0.169565) + tot_loss (0.573083) + tot_loss_crop (0.559488) + loss_clip_order (0.293151) = final_loss = 1.595287
n_iter 13 : loss (0.167053) + tot_loss (0.572267) + tot_loss_crop (0.560040) + loss_clip_order (0.288941) = final_loss = 1.588300
n_iter 14 : loss (0.162543) + tot_loss (0.574094) + tot_loss_crop (0.560907) + loss_clip_order (0.293917) = final_loss = 1.591461
n_iter 15 : loss (0.161347) + tot_loss (0.571174) + tot_loss_crop (0.559624) + loss_clip_order (0.293184) = final_loss = 1.585328
n_iter 16 : loss (0.168813) + tot_loss (0.568762) + tot_loss_crop (0.553159) + loss_clip_order (0.292266) = final_loss = 1.583000
n_iter 17 : loss (0.161704) + tot_loss (0.567024) + tot_loss_crop (0.555195) + loss_clip_order (0.295073) = final_loss = 1.578995
n_iter 18 : loss (0.168246) + tot_loss (0.566495) + tot_loss_crop (0.553840) + loss_clip_order (0.298733) = final_loss = 1.587314
n_iter 19 : loss (0.157070) + tot_loss (0.555059) + tot_loss_crop (0.551297) + loss_clip_order (0.294628) = final_loss = 1.558053
n_iter 20 : loss (0.182640) + tot_loss (0.562036) + tot_loss_crop (0.545669) + loss_clip_order (0.300013) = final_loss = 1.590358
n_iter 21 : loss (0.166965) + tot_loss (0.578757) + tot_loss_crop (0.550843) + loss_clip_order (0.295297) = final_loss = 1.591862
n_iter 22 : loss (0.168417) + tot_loss (0.560706) + tot_loss_crop (0.546265) + loss_clip_order (0.300189) = final_loss = 1.575576
n_iter 23 : loss (0.158893) + tot_loss (0.561724) + tot_loss_crop (0.547664) + loss_clip_order (0.292703) = final_loss = 1.560982
n_iter 24 : loss (0.157702) + tot_loss (0.552577) + tot_loss_crop (0.549789) + loss_clip_order (0.293562) = final_loss = 1.553630
n_iter 25 : loss (0.160996) + tot_loss (0.556226) + tot_loss_crop (0.545271) + loss_clip_order (0.287410) = final_loss = 1.549903
n_iter 26 : loss (0.154815) + tot_loss (0.559863) + tot_loss_crop (0.547317) + loss_clip_order (0.297433) = final_loss = 1.559428
n_iter 27 : loss (0.160994) + tot_loss (0.563255) + tot_loss_crop (0.542733) + loss_clip_order (0.290138) = final_loss = 1.557120
n_iter 28 : loss (0.169363) + tot_loss (0.543646) + tot_loss_crop (0.535535) + loss_clip_order (0.292546) = final_loss = 1.541089
n_iter 29 : loss (0.160705) + tot_loss (0.563711) + tot_loss_crop (0.542025) + loss_clip_order (0.296610) = final_loss = 1.563052
n_iter 30 : loss (0.172340) + tot_loss (0.559803) + tot_loss_crop (0.534007) + loss_clip_order (0.294819) = final_loss = 1.560970
[Pretraining Epoch 008] Total-Loss 0.56 =  F-Loss 0.56 + Clip-Loss 0.29 (train)
training epoch 6
use Semi !!!
[Iteration 000] Total-Loss 3.51 = T-Loss 2.82 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.85 = T-Loss 2.17 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.64 = T-Loss 1.97 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 2.50 = T-Loss 1.82 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 006] Total-Loss 2.50 = T-Loss 1.82 + B-Loss 0.67 (train)[0m
[Epoch 006] Total-Loss 3.05 = T-Loss 2.38 + B-Loss 0.67  (val)
training epoch 7
use Semi !!!
[Iteration 000] Total-Loss 2.09 = T-Loss 1.42 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.15 = T-Loss 1.48 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.10 = T-Loss 1.43 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 2.04 = T-Loss 1.38 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 007] Total-Loss 2.04 = T-Loss 1.38 + B-Loss 0.66 (train)[0m
[Epoch 007] Total-Loss 2.73 = T-Loss 2.07 + B-Loss 0.66  (val)
training epoch 8
use Semi !!!
[Iteration 000] Total-Loss 1.85 = T-Loss 1.18 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.95 = T-Loss 1.29 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.92 = T-Loss 1.26 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.88 = T-Loss 1.22 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 008] Total-Loss 1.88 = T-Loss 1.22 + B-Loss 0.66 (train)[0m
[Epoch 008] Total-Loss 2.78 = T-Loss 2.11 + B-Loss 0.66  (val)
9
n_iter  0 : loss (0.228174) + tot_loss (0.544615) + tot_loss_crop (0.532421) + loss_clip_order (0.506024) = final_loss = 1.811235
n_iter  1 : loss (0.228440) + tot_loss (0.563379) + tot_loss_crop (0.531021) + loss_clip_order (0.490175) = final_loss = 1.813014
n_iter  2 : loss (0.226064) + tot_loss (0.552717) + tot_loss_crop (0.527117) + loss_clip_order (0.437606) = final_loss = 1.743504
n_iter  3 : loss (0.221845) + tot_loss (0.545623) + tot_loss_crop (0.532461) + loss_clip_order (0.494534) = final_loss = 1.794463
n_iter  4 : loss (0.218300) + tot_loss (0.540303) + tot_loss_crop (0.527427) + loss_clip_order (0.415987) = final_loss = 1.702017
n_iter  5 : loss (0.213563) + tot_loss (0.542889) + tot_loss_crop (0.524758) + loss_clip_order (0.441422) = final_loss = 1.722632
n_iter  6 : loss (0.208951) + tot_loss (0.542080) + tot_loss_crop (0.524788) + loss_clip_order (0.427471) = final_loss = 1.703290
n_iter  7 : loss (0.202585) + tot_loss (0.528231) + tot_loss_crop (0.525558) + loss_clip_order (0.361998) = final_loss = 1.618371
n_iter  8 : loss (0.199006) + tot_loss (0.536954) + tot_loss_crop (0.524879) + loss_clip_order (0.338987) = final_loss = 1.599827
n_iter  9 : loss (0.188535) + tot_loss (0.531676) + tot_loss_crop (0.530623) + loss_clip_order (0.353232) = final_loss = 1.604065
n_iter 10 : loss (0.181530) + tot_loss (0.542294) + tot_loss_crop (0.524148) + loss_clip_order (0.299754) = final_loss = 1.547726
n_iter 11 : loss (0.181165) + tot_loss (0.530802) + tot_loss_crop (0.518475) + loss_clip_order (0.289018) = final_loss = 1.519460
n_iter 12 : loss (0.171990) + tot_loss (0.541439) + tot_loss_crop (0.517371) + loss_clip_order (0.291621) = final_loss = 1.522421
n_iter 13 : loss (0.165697) + tot_loss (0.542039) + tot_loss_crop (0.519438) + loss_clip_order (0.287109) = final_loss = 1.514283
n_iter 14 : loss (0.161773) + tot_loss (0.545313) + tot_loss_crop (0.519000) + loss_clip_order (0.296477) = final_loss = 1.522563
n_iter 15 : loss (0.164892) + tot_loss (0.544194) + tot_loss_crop (0.518493) + loss_clip_order (0.295940) = final_loss = 1.523520
n_iter 16 : loss (0.160144) + tot_loss (0.543409) + tot_loss_crop (0.517105) + loss_clip_order (0.283975) = final_loss = 1.504633
n_iter 17 : loss (0.161071) + tot_loss (0.542121) + tot_loss_crop (0.517231) + loss_clip_order (0.301058) = final_loss = 1.521480
n_iter 18 : loss (0.160789) + tot_loss (0.542921) + tot_loss_crop (0.515131) + loss_clip_order (0.288247) = final_loss = 1.507088
n_iter 19 : loss (0.171469) + tot_loss (0.531162) + tot_loss_crop (0.511360) + loss_clip_order (0.282425) = final_loss = 1.496417
n_iter 20 : loss (0.156204) + tot_loss (0.539363) + tot_loss_crop (0.513019) + loss_clip_order (0.297862) = final_loss = 1.506449
n_iter 21 : loss (0.163298) + tot_loss (0.557223) + tot_loss_crop (0.514203) + loss_clip_order (0.289586) = final_loss = 1.524310
n_iter 22 : loss (0.175889) + tot_loss (0.538064) + tot_loss_crop (0.508908) + loss_clip_order (0.288227) = final_loss = 1.511088
n_iter 23 : loss (0.178187) + tot_loss (0.540485) + tot_loss_crop (0.507254) + loss_clip_order (0.284152) = final_loss = 1.510078
n_iter 24 : loss (0.167978) + tot_loss (0.529271) + tot_loss_crop (0.504734) + loss_clip_order (0.284473) = final_loss = 1.486455
n_iter 25 : loss (0.154310) + tot_loss (0.533406) + tot_loss_crop (0.505108) + loss_clip_order (0.283550) = final_loss = 1.476375
n_iter 26 : loss (0.155676) + tot_loss (0.535479) + tot_loss_crop (0.504463) + loss_clip_order (0.291558) = final_loss = 1.487176
n_iter 27 : loss (0.166629) + tot_loss (0.537217) + tot_loss_crop (0.500556) + loss_clip_order (0.292519) = final_loss = 1.496922
n_iter 28 : loss (0.173033) + tot_loss (0.516881) + tot_loss_crop (0.495525) + loss_clip_order (0.284003) = final_loss = 1.469442
n_iter 29 : loss (0.156701) + tot_loss (0.534194) + tot_loss_crop (0.500927) + loss_clip_order (0.286115) = final_loss = 1.477937
n_iter 30 : loss (0.155099) + tot_loss (0.529926) + tot_loss_crop (0.497653) + loss_clip_order (0.286096) = final_loss = 1.468774
[Pretraining Epoch 009] Total-Loss 0.53 =  F-Loss 0.53 + Clip-Loss 0.29 (train)
n_iter  0 : loss (0.160079) + tot_loss (0.520424) + tot_loss_crop (0.496993) + loss_clip_order (0.280428) = final_loss = 1.457925
n_iter  1 : loss (0.161210) + tot_loss (0.536564) + tot_loss_crop (0.496672) + loss_clip_order (0.290324) = final_loss = 1.484771
n_iter  2 : loss (0.156610) + tot_loss (0.524952) + tot_loss_crop (0.492532) + loss_clip_order (0.282448) = final_loss = 1.456541
n_iter  3 : loss (0.165428) + tot_loss (0.516100) + tot_loss_crop (0.489719) + loss_clip_order (0.277666) = final_loss = 1.448913
n_iter  4 : loss (0.168692) + tot_loss (0.511362) + tot_loss_crop (0.486866) + loss_clip_order (0.279373) = final_loss = 1.446293
n_iter  5 : loss (0.157386) + tot_loss (0.514135) + tot_loss_crop (0.489250) + loss_clip_order (0.277412) = final_loss = 1.438184
n_iter  6 : loss (0.163065) + tot_loss (0.511079) + tot_loss_crop (0.486599) + loss_clip_order (0.293493) = final_loss = 1.454236
n_iter  7 : loss (0.167842) + tot_loss (0.497039) + tot_loss_crop (0.481712) + loss_clip_order (0.284917) = final_loss = 1.431511
n_iter  8 : loss (0.168364) + tot_loss (0.505256) + tot_loss_crop (0.481573) + loss_clip_order (0.283284) = final_loss = 1.438477
n_iter  9 : loss (0.155862) + tot_loss (0.499825) + tot_loss_crop (0.481333) + loss_clip_order (0.283677) = final_loss = 1.420697
n_iter 10 : loss (0.171931) + tot_loss (0.509218) + tot_loss_crop (0.480914) + loss_clip_order (0.288601) = final_loss = 1.450665
n_iter 11 : loss (0.158648) + tot_loss (0.498483) + tot_loss_crop (0.475970) + loss_clip_order (0.281705) = final_loss = 1.414806
n_iter 12 : loss (0.162149) + tot_loss (0.507438) + tot_loss_crop (0.476226) + loss_clip_order (0.281095) = final_loss = 1.426908
n_iter 13 : loss (0.164836) + tot_loss (0.505925) + tot_loss_crop (0.476129) + loss_clip_order (0.282242) = final_loss = 1.429132
n_iter 14 : loss (0.149980) + tot_loss (0.507188) + tot_loss_crop (0.477681) + loss_clip_order (0.279029) = final_loss = 1.413878
n_iter 15 : loss (0.151486) + tot_loss (0.503965) + tot_loss_crop (0.479233) + loss_clip_order (0.277968) = final_loss = 1.412652
n_iter 16 : loss (0.155201) + tot_loss (0.501568) + tot_loss_crop (0.475315) + loss_clip_order (0.279634) = final_loss = 1.411717
n_iter 17 : loss (0.162633) + tot_loss (0.499176) + tot_loss_crop (0.470691) + loss_clip_order (0.289065) = final_loss = 1.421565
n_iter 18 : loss (0.156160) + tot_loss (0.498933) + tot_loss_crop (0.471809) + loss_clip_order (0.285839) = final_loss = 1.412741
n_iter 19 : loss (0.154541) + tot_loss (0.487214) + tot_loss_crop (0.468485) + loss_clip_order (0.285935) = final_loss = 1.396175
n_iter 20 : loss (0.154576) + tot_loss (0.494460) + tot_loss_crop (0.467077) + loss_clip_order (0.280616) = final_loss = 1.396729
n_iter 21 : loss (0.166303) + tot_loss (0.509297) + tot_loss_crop (0.465941) + loss_clip_order (0.282079) = final_loss = 1.423620
n_iter 22 : loss (0.162571) + tot_loss (0.492044) + tot_loss_crop (0.464455) + loss_clip_order (0.289268) = final_loss = 1.408337
n_iter 23 : loss (0.170133) + tot_loss (0.493005) + tot_loss_crop (0.461466) + loss_clip_order (0.282257) = final_loss = 1.406861
n_iter 24 : loss (0.178439) + tot_loss (0.483315) + tot_loss_crop (0.456905) + loss_clip_order (0.288039) = final_loss = 1.406697
n_iter 25 : loss (0.163707) + tot_loss (0.487793) + tot_loss_crop (0.460056) + loss_clip_order (0.276151) = final_loss = 1.387706
n_iter 26 : loss (0.155324) + tot_loss (0.490504) + tot_loss_crop (0.463843) + loss_clip_order (0.285980) = final_loss = 1.395651
n_iter 27 : loss (0.160158) + tot_loss (0.493640) + tot_loss_crop (0.458751) + loss_clip_order (0.275147) = final_loss = 1.387695
n_iter 28 : loss (0.153239) + tot_loss (0.474516) + tot_loss_crop (0.459386) + loss_clip_order (0.271178) = final_loss = 1.358319
n_iter 29 : loss (0.165037) + tot_loss (0.492339) + tot_loss_crop (0.459239) + loss_clip_order (0.282908) = final_loss = 1.399522
n_iter 30 : loss (0.152833) + tot_loss (0.489542) + tot_loss_crop (0.457048) + loss_clip_order (0.276303) = final_loss = 1.375726
[Pretraining Epoch 010] Total-Loss 0.49 =  F-Loss 0.49 + Clip-Loss 0.28 (train)
n_iter  0 : loss (0.163627) + tot_loss (0.481238) + tot_loss_crop (0.453657) + loss_clip_order (0.276975) = final_loss = 1.375496
n_iter  1 : loss (0.172979) + tot_loss (0.498304) + tot_loss_crop (0.454361) + loss_clip_order (0.285021) = final_loss = 1.410665
n_iter  2 : loss (0.159792) + tot_loss (0.487829) + tot_loss_crop (0.452052) + loss_clip_order (0.277083) = final_loss = 1.376756
n_iter  3 : loss (0.162531) + tot_loss (0.479216) + tot_loss_crop (0.449886) + loss_clip_order (0.278741) = final_loss = 1.370374
n_iter  4 : loss (0.160234) + tot_loss (0.475432) + tot_loss_crop (0.448745) + loss_clip_order (0.268864) = final_loss = 1.353275
n_iter  5 : loss (0.159688) + tot_loss (0.478775) + tot_loss_crop (0.448757) + loss_clip_order (0.273353) = final_loss = 1.360574
n_iter  6 : loss (0.171399) + tot_loss (0.475568) + tot_loss_crop (0.446846) + loss_clip_order (0.275384) = final_loss = 1.369197
n_iter  7 : loss (0.170062) + tot_loss (0.461653) + tot_loss_crop (0.441700) + loss_clip_order (0.276734) = final_loss = 1.350149
n_iter  8 : loss (0.161285) + tot_loss (0.469714) + tot_loss_crop (0.445316) + loss_clip_order (0.273190) = final_loss = 1.349505
n_iter  9 : loss (0.169575) + tot_loss (0.464550) + tot_loss_crop (0.441110) + loss_clip_order (0.275721) = final_loss = 1.350956
n_iter 10 : loss (0.156422) + tot_loss (0.473926) + tot_loss_crop (0.442708) + loss_clip_order (0.277702) = final_loss = 1.350758
n_iter 11 : loss (0.167400) + tot_loss (0.463556) + tot_loss_crop (0.439269) + loss_clip_order (0.271537) = final_loss = 1.341762
n_iter 12 : loss (0.160003) + tot_loss (0.473012) + tot_loss_crop (0.440564) + loss_clip_order (0.268002) = final_loss = 1.341581
n_iter 13 : loss (0.169819) + tot_loss (0.471631) + tot_loss_crop (0.437639) + loss_clip_order (0.267880) = final_loss = 1.346969
n_iter 14 : loss (0.158101) + tot_loss (0.472335) + tot_loss_crop (0.440240) + loss_clip_order (0.277947) = final_loss = 1.348624
n_iter 15 : loss (0.167970) + tot_loss (0.469778) + tot_loss_crop (0.436307) + loss_clip_order (0.274406) = final_loss = 1.348460
n_iter 16 : loss (0.165951) + tot_loss (0.468066) + tot_loss_crop (0.436260) + loss_clip_order (0.265400) = final_loss = 1.335678
n_iter 17 : loss (0.156972) + tot_loss (0.465212) + tot_loss_crop (0.436214) + loss_clip_order (0.277682) = final_loss = 1.336080
n_iter 18 : loss (0.157734) + tot_loss (0.464855) + tot_loss_crop (0.432569) + loss_clip_order (0.269154) = final_loss = 1.324312
n_iter 19 : loss (0.175293) + tot_loss (0.453086) + tot_loss_crop (0.429293) + loss_clip_order (0.284458) = final_loss = 1.342129
n_iter 20 : loss (0.164277) + tot_loss (0.460441) + tot_loss_crop (0.430341) + loss_clip_order (0.271192) = final_loss = 1.326250
n_iter 21 : loss (0.160665) + tot_loss (0.474811) + tot_loss_crop (0.432623) + loss_clip_order (0.274263) = final_loss = 1.342362
n_iter 22 : loss (0.157933) + tot_loss (0.457781) + tot_loss_crop (0.428461) + loss_clip_order (0.275819) = final_loss = 1.319995
n_iter 23 : loss (0.153970) + tot_loss (0.458718) + tot_loss_crop (0.428529) + loss_clip_order (0.267649) = final_loss = 1.308866
n_iter 24 : loss (0.147653) + tot_loss (0.449119) + tot_loss_crop (0.428087) + loss_clip_order (0.272491) = final_loss = 1.297350
n_iter 25 : loss (0.157646) + tot_loss (0.453931) + tot_loss_crop (0.427473) + loss_clip_order (0.265902) = final_loss = 1.304951
n_iter 26 : loss (0.159804) + tot_loss (0.456422) + tot_loss_crop (0.424443) + loss_clip_order (0.271154) = final_loss = 1.311823
n_iter 27 : loss (0.163938) + tot_loss (0.459551) + tot_loss_crop (0.424445) + loss_clip_order (0.272730) = final_loss = 1.320664
n_iter 28 : loss (0.157314) + tot_loss (0.441165) + tot_loss_crop (0.420786) + loss_clip_order (0.272852) = final_loss = 1.292117
n_iter 29 : loss (0.160923) + tot_loss (0.457881) + tot_loss_crop (0.425287) + loss_clip_order (0.267659) = final_loss = 1.311751
n_iter 30 : loss (0.161339) + tot_loss (0.455152) + tot_loss_crop (0.419344) + loss_clip_order (0.273490) = final_loss = 1.309325
[Pretraining Epoch 011] Total-Loss 0.46 =  F-Loss 0.46 + Clip-Loss 0.27 (train)
training epoch 9
use Semi !!!
[Iteration 000] Total-Loss 2.82 = T-Loss 2.13 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.33 = T-Loss 1.64 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.17 = T-Loss 1.49 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 2.07 = T-Loss 1.39 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 009] Total-Loss 2.07 = T-Loss 1.39 + B-Loss 0.68 (train)[0m
[Epoch 009] Total-Loss 2.84 = T-Loss 2.17 + B-Loss 0.67  (val)
training epoch 10
use Semi !!!
[Iteration 000] Total-Loss 1.90 = T-Loss 1.23 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.89 = T-Loss 1.22 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.88 = T-Loss 1.22 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.86 = T-Loss 1.20 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 010] Total-Loss 1.86 = T-Loss 1.20 + B-Loss 0.67 (train)[0m
[Epoch 010] Total-Loss 2.93 = T-Loss 2.26 + B-Loss 0.67  (val)
training epoch 11
use Semi !!!
[Iteration 000] Total-Loss 1.77 = T-Loss 1.10 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.83 = T-Loss 1.17 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.79 = T-Loss 1.13 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.73 = T-Loss 1.07 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 011] Total-Loss 1.73 = T-Loss 1.07 + B-Loss 0.66 (train)[0m
[Epoch 011] Total-Loss 2.69 = T-Loss 2.03 + B-Loss 0.66  (val)
12
n_iter  0 : loss (0.206844) + tot_loss (0.442807) + tot_loss_crop (0.408340) + loss_clip_order (0.494781) = final_loss = 1.552771
n_iter  1 : loss (0.207587) + tot_loss (0.461254) + tot_loss_crop (0.413156) + loss_clip_order (0.454776) = final_loss = 1.536772
n_iter  2 : loss (0.201015) + tot_loss (0.452877) + tot_loss_crop (0.410182) + loss_clip_order (0.433378) = final_loss = 1.497452
n_iter  3 : loss (0.201131) + tot_loss (0.443986) + tot_loss_crop (0.409767) + loss_clip_order (0.417888) = final_loss = 1.472772
n_iter  4 : loss (0.194129) + tot_loss (0.439585) + tot_loss_crop (0.407610) + loss_clip_order (0.399201) = final_loss = 1.440525
n_iter  5 : loss (0.193122) + tot_loss (0.442952) + tot_loss_crop (0.407572) + loss_clip_order (0.395903) = final_loss = 1.439550
n_iter  6 : loss (0.186527) + tot_loss (0.441865) + tot_loss_crop (0.408887) + loss_clip_order (0.410502) = final_loss = 1.447780
n_iter  7 : loss (0.181900) + tot_loss (0.427744) + tot_loss_crop (0.404418) + loss_clip_order (0.371342) = final_loss = 1.385405
n_iter  8 : loss (0.182262) + tot_loss (0.436050) + tot_loss_crop (0.404446) + loss_clip_order (0.371433) = final_loss = 1.394191
n_iter  9 : loss (0.171304) + tot_loss (0.431259) + tot_loss_crop (0.406185) + loss_clip_order (0.301937) = final_loss = 1.310686
n_iter 10 : loss (0.166963) + tot_loss (0.441189) + tot_loss_crop (0.410886) + loss_clip_order (0.272590) = final_loss = 1.291628
n_iter 11 : loss (0.164938) + tot_loss (0.431450) + tot_loss_crop (0.409142) + loss_clip_order (0.272592) = final_loss = 1.278122
n_iter 12 : loss (0.162475) + tot_loss (0.441524) + tot_loss_crop (0.410059) + loss_clip_order (0.279116) = final_loss = 1.293173
n_iter 13 : loss (0.168791) + tot_loss (0.440085) + tot_loss_crop (0.411157) + loss_clip_order (0.270391) = final_loss = 1.290425
n_iter 14 : loss (0.152737) + tot_loss (0.442380) + tot_loss_crop (0.409197) + loss_clip_order (0.287468) = final_loss = 1.291782
n_iter 15 : loss (0.162146) + tot_loss (0.440799) + tot_loss_crop (0.410451) + loss_clip_order (0.276702) = final_loss = 1.290098
n_iter 16 : loss (0.167863) + tot_loss (0.440048) + tot_loss_crop (0.409319) + loss_clip_order (0.263969) = final_loss = 1.281197
n_iter 17 : loss (0.176433) + tot_loss (0.438637) + tot_loss_crop (0.409458) + loss_clip_order (0.278979) = final_loss = 1.303506
n_iter 18 : loss (0.172194) + tot_loss (0.439877) + tot_loss_crop (0.408994) + loss_clip_order (0.264588) = final_loss = 1.285653
n_iter 19 : loss (0.172186) + tot_loss (0.429148) + tot_loss_crop (0.404538) + loss_clip_order (0.263105) = final_loss = 1.268977
n_iter 20 : loss (0.165458) + tot_loss (0.438548) + tot_loss_crop (0.406244) + loss_clip_order (0.269812) = final_loss = 1.280062
n_iter 21 : loss (0.163913) + tot_loss (0.453909) + tot_loss_crop (0.408013) + loss_clip_order (0.275603) = final_loss = 1.301437
n_iter 22 : loss (0.162830) + tot_loss (0.436624) + tot_loss_crop (0.404656) + loss_clip_order (0.269756) = final_loss = 1.273867
n_iter 23 : loss (0.161856) + tot_loss (0.438260) + tot_loss_crop (0.403397) + loss_clip_order (0.270263) = final_loss = 1.273776
n_iter 24 : loss (0.150204) + tot_loss (0.427503) + tot_loss_crop (0.400140) + loss_clip_order (0.273655) = final_loss = 1.251502
n_iter 25 : loss (0.161807) + tot_loss (0.431778) + tot_loss_crop (0.401475) + loss_clip_order (0.262173) = final_loss = 1.257233
n_iter 26 : loss (0.178181) + tot_loss (0.434143) + tot_loss_crop (0.400681) + loss_clip_order (0.273202) = final_loss = 1.286208
n_iter 27 : loss (0.164764) + tot_loss (0.435607) + tot_loss_crop (0.398942) + loss_clip_order (0.259752) = final_loss = 1.259066
n_iter 28 : loss (0.177757) + tot_loss (0.416035) + tot_loss_crop (0.394769) + loss_clip_order (0.264214) = final_loss = 1.252775
n_iter 29 : loss (0.158660) + tot_loss (0.432020) + tot_loss_crop (0.398243) + loss_clip_order (0.260330) = final_loss = 1.249253
n_iter 30 : loss (0.162309) + tot_loss (0.428204) + tot_loss_crop (0.393548) + loss_clip_order (0.256561) = final_loss = 1.240622
[Pretraining Epoch 012] Total-Loss 0.43 =  F-Loss 0.43 + Clip-Loss 0.26 (train)
n_iter  0 : loss (0.159569) + tot_loss (0.418671) + tot_loss_crop (0.393094) + loss_clip_order (0.260682) = final_loss = 1.232016
n_iter  1 : loss (0.160278) + tot_loss (0.435204) + tot_loss_crop (0.393798) + loss_clip_order (0.267590) = final_loss = 1.256870
n_iter  2 : loss (0.159426) + tot_loss (0.424158) + tot_loss_crop (0.391403) + loss_clip_order (0.259900) = final_loss = 1.234886
n_iter  3 : loss (0.161276) + tot_loss (0.416043) + tot_loss_crop (0.389706) + loss_clip_order (0.261450) = final_loss = 1.228475
n_iter  4 : loss (0.164871) + tot_loss (0.411847) + tot_loss_crop (0.388122) + loss_clip_order (0.257669) = final_loss = 1.222509
n_iter  5 : loss (0.172711) + tot_loss (0.415543) + tot_loss_crop (0.388556) + loss_clip_order (0.255788) = final_loss = 1.232598
n_iter  6 : loss (0.155241) + tot_loss (0.412198) + tot_loss_crop (0.386408) + loss_clip_order (0.263278) = final_loss = 1.217125
n_iter  7 : loss (0.163825) + tot_loss (0.398982) + tot_loss_crop (0.381526) + loss_clip_order (0.258910) = final_loss = 1.203243
n_iter  8 : loss (0.166171) + tot_loss (0.406657) + tot_loss_crop (0.380805) + loss_clip_order (0.268314) = final_loss = 1.221947
n_iter  9 : loss (0.166969) + tot_loss (0.401659) + tot_loss_crop (0.379954) + loss_clip_order (0.268233) = final_loss = 1.216814
n_iter 10 : loss (0.167826) + tot_loss (0.410494) + tot_loss_crop (0.378486) + loss_clip_order (0.266464) = final_loss = 1.223270
n_iter 11 : loss (0.160252) + tot_loss (0.401040) + tot_loss_crop (0.377713) + loss_clip_order (0.260770) = final_loss = 1.199776
n_iter 12 : loss (0.155919) + tot_loss (0.409672) + tot_loss_crop (0.376161) + loss_clip_order (0.266552) = final_loss = 1.208304
n_iter 13 : loss (0.153950) + tot_loss (0.408120) + tot_loss_crop (0.377475) + loss_clip_order (0.260900) = final_loss = 1.200445
n_iter 14 : loss (0.160023) + tot_loss (0.408915) + tot_loss_crop (0.375934) + loss_clip_order (0.266498) = final_loss = 1.211369
n_iter 15 : loss (0.157624) + tot_loss (0.405769) + tot_loss_crop (0.376635) + loss_clip_order (0.259429) = final_loss = 1.199457
n_iter 16 : loss (0.163536) + tot_loss (0.404863) + tot_loss_crop (0.371828) + loss_clip_order (0.256928) = final_loss = 1.197155
n_iter 17 : loss (0.160800) + tot_loss (0.401688) + tot_loss_crop (0.373672) + loss_clip_order (0.274004) = final_loss = 1.210164
n_iter 18 : loss (0.153269) + tot_loss (0.402146) + tot_loss_crop (0.373335) + loss_clip_order (0.256950) = final_loss = 1.185700
n_iter 19 : loss (0.173875) + tot_loss (0.390624) + tot_loss_crop (0.367283) + loss_clip_order (0.279589) = final_loss = 1.211372
n_iter 20 : loss (0.160617) + tot_loss (0.398557) + tot_loss_crop (0.368159) + loss_clip_order (0.263679) = final_loss = 1.191013
n_iter 21 : loss (0.160576) + tot_loss (0.412381) + tot_loss_crop (0.369254) + loss_clip_order (0.263106) = final_loss = 1.205317
n_iter 22 : loss (0.162046) + tot_loss (0.395875) + tot_loss_crop (0.366763) + loss_clip_order (0.266184) = final_loss = 1.190868
n_iter 23 : loss (0.163571) + tot_loss (0.397276) + tot_loss_crop (0.368876) + loss_clip_order (0.257588) = final_loss = 1.187311
n_iter 24 : loss (0.162602) + tot_loss (0.387358) + tot_loss_crop (0.363887) + loss_clip_order (0.261227) = final_loss = 1.175074
n_iter 25 : loss (0.159888) + tot_loss (0.392274) + tot_loss_crop (0.365349) + loss_clip_order (0.254376) = final_loss = 1.171887
n_iter 26 : loss (0.162298) + tot_loss (0.394574) + tot_loss_crop (0.367646) + loss_clip_order (0.257815) = final_loss = 1.182333
n_iter 27 : loss (0.162507) + tot_loss (0.397570) + tot_loss_crop (0.363644) + loss_clip_order (0.258092) = final_loss = 1.181813
n_iter 28 : loss (0.168723) + tot_loss (0.380375) + tot_loss_crop (0.360532) + loss_clip_order (0.257080) = final_loss = 1.166709
n_iter 29 : loss (0.157733) + tot_loss (0.395904) + tot_loss_crop (0.363022) + loss_clip_order (0.261337) = final_loss = 1.177995
n_iter 30 : loss (0.160541) + tot_loss (0.394039) + tot_loss_crop (0.362824) + loss_clip_order (0.252127) = final_loss = 1.169532
[Pretraining Epoch 013] Total-Loss 0.39 =  F-Loss 0.39 + Clip-Loss 0.25 (train)
n_iter  0 : loss (0.159147) + tot_loss (0.385479) + tot_loss_crop (0.359881) + loss_clip_order (0.254523) = final_loss = 1.159029
n_iter  1 : loss (0.152391) + tot_loss (0.401581) + tot_loss_crop (0.360957) + loss_clip_order (0.258586) = final_loss = 1.173516
n_iter  2 : loss (0.173022) + tot_loss (0.392877) + tot_loss_crop (0.357059) + loss_clip_order (0.264113) = final_loss = 1.187072
n_iter  3 : loss (0.161826) + tot_loss (0.384484) + tot_loss_crop (0.357368) + loss_clip_order (0.255559) = final_loss = 1.159237
n_iter  4 : loss (0.160729) + tot_loss (0.381148) + tot_loss_crop (0.354874) + loss_clip_order (0.256679) = final_loss = 1.153430
n_iter  5 : loss (0.160793) + tot_loss (0.385159) + tot_loss_crop (0.356929) + loss_clip_order (0.253457) = final_loss = 1.156338
n_iter  6 : loss (0.150216) + tot_loss (0.381914) + tot_loss_crop (0.352897) + loss_clip_order (0.256338) = final_loss = 1.141366
n_iter  7 : loss (0.158432) + tot_loss (0.368024) + tot_loss_crop (0.353520) + loss_clip_order (0.252871) = final_loss = 1.132847
n_iter  8 : loss (0.165599) + tot_loss (0.376237) + tot_loss_crop (0.353338) + loss_clip_order (0.262866) = final_loss = 1.158040
n_iter  9 : loss (0.158746) + tot_loss (0.372124) + tot_loss_crop (0.351782) + loss_clip_order (0.257105) = final_loss = 1.139756
n_iter 10 : loss (0.163656) + tot_loss (0.380578) + tot_loss_crop (0.350034) + loss_clip_order (0.258908) = final_loss = 1.153177
n_iter 11 : loss (0.161305) + tot_loss (0.371701) + tot_loss_crop (0.347211) + loss_clip_order (0.248863) = final_loss = 1.129079
n_iter 12 : loss (0.159670) + tot_loss (0.380539) + tot_loss_crop (0.348434) + loss_clip_order (0.248270) = final_loss = 1.136914
n_iter 13 : loss (0.158768) + tot_loss (0.379350) + tot_loss_crop (0.347981) + loss_clip_order (0.256333) = final_loss = 1.142433
n_iter 14 : loss (0.161928) + tot_loss (0.379748) + tot_loss_crop (0.348457) + loss_clip_order (0.256959) = final_loss = 1.147092
n_iter 15 : loss (0.153704) + tot_loss (0.376371) + tot_loss_crop (0.346133) + loss_clip_order (0.254450) = final_loss = 1.130657
n_iter 16 : loss (0.162909) + tot_loss (0.375766) + tot_loss_crop (0.346345) + loss_clip_order (0.257578) = final_loss = 1.142598
n_iter 17 : loss (0.164726) + tot_loss (0.373206) + tot_loss_crop (0.343141) + loss_clip_order (0.274207) = final_loss = 1.155280
n_iter 18 : loss (0.161041) + tot_loss (0.372860) + tot_loss_crop (0.342797) + loss_clip_order (0.250013) = final_loss = 1.126711
n_iter 19 : loss (0.168864) + tot_loss (0.361425) + tot_loss_crop (0.338019) + loss_clip_order (0.262658) = final_loss = 1.130966
n_iter 20 : loss (0.151232) + tot_loss (0.369717) + tot_loss_crop (0.341076) + loss_clip_order (0.247352) = final_loss = 1.109377
n_iter 21 : loss (0.162291) + tot_loss (0.383382) + tot_loss_crop (0.342111) + loss_clip_order (0.253007) = final_loss = 1.140791
n_iter 22 : loss (0.157453) + tot_loss (0.367271) + tot_loss_crop (0.338731) + loss_clip_order (0.257322) = final_loss = 1.120776
n_iter 23 : loss (0.158247) + tot_loss (0.368828) + tot_loss_crop (0.339362) + loss_clip_order (0.249402) = final_loss = 1.115840
n_iter 24 : loss (0.156611) + tot_loss (0.358208) + tot_loss_crop (0.335872) + loss_clip_order (0.253354) = final_loss = 1.104044
n_iter 25 : loss (0.156740) + tot_loss (0.363932) + tot_loss_crop (0.338639) + loss_clip_order (0.248271) = final_loss = 1.107582
n_iter 26 : loss (0.162938) + tot_loss (0.366220) + tot_loss_crop (0.337750) + loss_clip_order (0.252243) = final_loss = 1.119150
n_iter 27 : loss (0.157065) + tot_loss (0.369132) + tot_loss_crop (0.338826) + loss_clip_order (0.247806) = final_loss = 1.112830
n_iter 28 : loss (0.154171) + tot_loss (0.351244) + tot_loss_crop (0.334104) + loss_clip_order (0.247192) = final_loss = 1.086711
n_iter 29 : loss (0.154421) + tot_loss (0.366999) + tot_loss_crop (0.336024) + loss_clip_order (0.251226) = final_loss = 1.108670
n_iter 30 : loss (0.155117) + tot_loss (0.365742) + tot_loss_crop (0.334024) + loss_clip_order (0.251520) = final_loss = 1.106403
[Pretraining Epoch 014] Total-Loss 0.37 =  F-Loss 0.37 + Clip-Loss 0.25 (train)
training epoch 12
use Semi !!!
[Iteration 000] Total-Loss 2.77 = T-Loss 2.08 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.17 = T-Loss 1.48 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.02 = T-Loss 1.33 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.93 = T-Loss 1.25 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 012] Total-Loss 1.93 = T-Loss 1.25 + B-Loss 0.69 (train)[0m
[Epoch 012] Total-Loss 2.73 = T-Loss 2.05 + B-Loss 0.68  (val)
training epoch 13
use Semi !!!
[Iteration 000] Total-Loss 1.71 = T-Loss 1.03 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.74 = T-Loss 1.07 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.72 = T-Loss 1.05 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.71 = T-Loss 1.04 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 013] Total-Loss 1.71 = T-Loss 1.04 + B-Loss 0.67 (train)[0m
[Epoch 013] Total-Loss 2.83 = T-Loss 2.17 + B-Loss 0.67  (val)
training epoch 14
use Semi !!!
[Iteration 000] Total-Loss 1.63 = T-Loss 0.96 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.71 = T-Loss 1.05 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.68 = T-Loss 1.02 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.64 = T-Loss 0.98 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 014] Total-Loss 1.64 = T-Loss 0.98 + B-Loss 0.66 (train)[0m
[Epoch 014] Total-Loss 2.72 = T-Loss 2.06 + B-Loss 0.66  (val)
15
n_iter  0 : loss (0.200210) + tot_loss (0.377822) + tot_loss_crop (0.342297) + loss_clip_order (0.492815) = final_loss = 1.413145
n_iter  1 : loss (0.204216) + tot_loss (0.394970) + tot_loss_crop (0.336519) + loss_clip_order (0.522691) = final_loss = 1.458396
n_iter  2 : loss (0.201305) + tot_loss (0.387164) + tot_loss_crop (0.336249) + loss_clip_order (0.581484) = final_loss = 1.506202
n_iter  3 : loss (0.199540) + tot_loss (0.382157) + tot_loss_crop (0.334206) + loss_clip_order (0.629734) = final_loss = 1.545638
n_iter  4 : loss (0.196424) + tot_loss (0.379682) + tot_loss_crop (0.336541) + loss_clip_order (0.632873) = final_loss = 1.545520
n_iter  5 : loss (0.186207) + tot_loss (0.383893) + tot_loss_crop (0.334638) + loss_clip_order (0.626238) = final_loss = 1.530976
n_iter  6 : loss (0.185088) + tot_loss (0.380915) + tot_loss_crop (0.333807) + loss_clip_order (0.622522) = final_loss = 1.522332
n_iter  7 : loss (0.172521) + tot_loss (0.365795) + tot_loss_crop (0.327743) + loss_clip_order (0.537261) = final_loss = 1.403320
n_iter  8 : loss (0.180065) + tot_loss (0.370417) + tot_loss_crop (0.329716) + loss_clip_order (0.462402) = final_loss = 1.342600
n_iter  9 : loss (0.166374) + tot_loss (0.363199) + tot_loss_crop (0.330467) + loss_clip_order (0.313809) = final_loss = 1.173849
n_iter 10 : loss (0.165889) + tot_loss (0.372313) + tot_loss_crop (0.335609) + loss_clip_order (0.254337) = final_loss = 1.128148
n_iter 11 : loss (0.171102) + tot_loss (0.363375) + tot_loss_crop (0.339579) + loss_clip_order (0.266316) = final_loss = 1.140373
n_iter 12 : loss (0.170075) + tot_loss (0.374101) + tot_loss_crop (0.340383) + loss_clip_order (0.378042) = final_loss = 1.262602
n_iter 13 : loss (0.169463) + tot_loss (0.369197) + tot_loss_crop (0.341647) + loss_clip_order (0.280419) = final_loss = 1.160726
n_iter 14 : loss (0.156956) + tot_loss (0.369351) + tot_loss_crop (0.337619) + loss_clip_order (0.260020) = final_loss = 1.123945
n_iter 15 : loss (0.167988) + tot_loss (0.367058) + tot_loss_crop (0.338195) + loss_clip_order (0.250549) = final_loss = 1.123790
n_iter 16 : loss (0.168265) + tot_loss (0.365766) + tot_loss_crop (0.336619) + loss_clip_order (0.240093) = final_loss = 1.110743
n_iter 17 : loss (0.163391) + tot_loss (0.364284) + tot_loss_crop (0.337236) + loss_clip_order (0.247355) = final_loss = 1.112265
n_iter 18 : loss (0.181290) + tot_loss (0.366042) + tot_loss_crop (0.335373) + loss_clip_order (0.253358) = final_loss = 1.136064
n_iter 19 : loss (0.174491) + tot_loss (0.355966) + tot_loss_crop (0.334491) + loss_clip_order (0.252492) = final_loss = 1.117439
n_iter 20 : loss (0.148222) + tot_loss (0.365266) + tot_loss_crop (0.333278) + loss_clip_order (0.258547) = final_loss = 1.105313
n_iter 21 : loss (0.157578) + tot_loss (0.379348) + tot_loss_crop (0.336851) + loss_clip_order (0.249255) = final_loss = 1.123032
n_iter 22 : loss (0.156151) + tot_loss (0.363042) + tot_loss_crop (0.331870) + loss_clip_order (0.252747) = final_loss = 1.103810
n_iter 23 : loss (0.181257) + tot_loss (0.364748) + tot_loss_crop (0.334175) + loss_clip_order (0.269885) = final_loss = 1.150066
n_iter 24 : loss (0.161304) + tot_loss (0.353644) + tot_loss_crop (0.329666) + loss_clip_order (0.254996) = final_loss = 1.099610
n_iter 25 : loss (0.175098) + tot_loss (0.358609) + tot_loss_crop (0.332075) + loss_clip_order (0.251988) = final_loss = 1.117770
n_iter 26 : loss (0.163870) + tot_loss (0.359668) + tot_loss_crop (0.331463) + loss_clip_order (0.248206) = final_loss = 1.103208
n_iter 27 : loss (0.154379) + tot_loss (0.360449) + tot_loss_crop (0.329845) + loss_clip_order (0.244825) = final_loss = 1.089497
n_iter 28 : loss (0.156095) + tot_loss (0.342180) + tot_loss_crop (0.323799) + loss_clip_order (0.250390) = final_loss = 1.072464
n_iter 29 : loss (0.159305) + tot_loss (0.356001) + tot_loss_crop (0.326777) + loss_clip_order (0.247212) = final_loss = 1.089295
n_iter 30 : loss (0.161180) + tot_loss (0.352600) + tot_loss_crop (0.324391) + loss_clip_order (0.243814) = final_loss = 1.081986
[Pretraining Epoch 015] Total-Loss 0.35 =  F-Loss 0.35 + Clip-Loss 0.24 (train)
n_iter  0 : loss (0.155381) + tot_loss (0.343036) + tot_loss_crop (0.323400) + loss_clip_order (0.239995) = final_loss = 1.061812
n_iter  1 : loss (0.166191) + tot_loss (0.358314) + tot_loss_crop (0.324886) + loss_clip_order (0.246050) = final_loss = 1.095442
n_iter  2 : loss (0.169799) + tot_loss (0.348327) + tot_loss_crop (0.320940) + loss_clip_order (0.241569) = final_loss = 1.080635
n_iter  3 : loss (0.158891) + tot_loss (0.339657) + tot_loss_crop (0.318786) + loss_clip_order (0.236067) = final_loss = 1.053402
n_iter  4 : loss (0.166148) + tot_loss (0.335449) + tot_loss_crop (0.318096) + loss_clip_order (0.239990) = final_loss = 1.059683
n_iter  5 : loss (0.169958) + tot_loss (0.339095) + tot_loss_crop (0.318534) + loss_clip_order (0.239336) = final_loss = 1.066923
n_iter  6 : loss (0.159936) + tot_loss (0.335404) + tot_loss_crop (0.316953) + loss_clip_order (0.240808) = final_loss = 1.053101
n_iter  7 : loss (0.165973) + tot_loss (0.321743) + tot_loss_crop (0.312314) + loss_clip_order (0.245261) = final_loss = 1.045292
n_iter  8 : loss (0.164251) + tot_loss (0.329159) + tot_loss_crop (0.312464) + loss_clip_order (0.246865) = final_loss = 1.052739
n_iter  9 : loss (0.160840) + tot_loss (0.325025) + tot_loss_crop (0.312791) + loss_clip_order (0.237675) = final_loss = 1.036332
n_iter 10 : loss (0.166915) + tot_loss (0.333251) + tot_loss_crop (0.312116) + loss_clip_order (0.243543) = final_loss = 1.055826
n_iter 11 : loss (0.162495) + tot_loss (0.324448) + tot_loss_crop (0.306440) + loss_clip_order (0.244633) = final_loss = 1.038016
n_iter 12 : loss (0.154865) + tot_loss (0.333140) + tot_loss_crop (0.307740) + loss_clip_order (0.236082) = final_loss = 1.031827
n_iter 13 : loss (0.160809) + tot_loss (0.331587) + tot_loss_crop (0.308674) + loss_clip_order (0.236516) = final_loss = 1.037586
n_iter 14 : loss (0.154138) + tot_loss (0.332093) + tot_loss_crop (0.306194) + loss_clip_order (0.246118) = final_loss = 1.038542
n_iter 15 : loss (0.168411) + tot_loss (0.328388) + tot_loss_crop (0.306063) + loss_clip_order (0.244206) = final_loss = 1.047069
n_iter 16 : loss (0.150463) + tot_loss (0.327719) + tot_loss_crop (0.303412) + loss_clip_order (0.238684) = final_loss = 1.020278
n_iter 17 : loss (0.158204) + tot_loss (0.325106) + tot_loss_crop (0.302425) + loss_clip_order (0.245784) = final_loss = 1.031519
n_iter 18 : loss (0.162667) + tot_loss (0.325003) + tot_loss_crop (0.302089) + loss_clip_order (0.242595) = final_loss = 1.032354
n_iter 19 : loss (0.177381) + tot_loss (0.313421) + tot_loss_crop (0.296456) + loss_clip_order (0.251816) = final_loss = 1.039073
n_iter 20 : loss (0.165583) + tot_loss (0.321364) + tot_loss_crop (0.297477) + loss_clip_order (0.245385) = final_loss = 1.029808
n_iter 21 : loss (0.171317) + tot_loss (0.334349) + tot_loss_crop (0.299623) + loss_clip_order (0.242941) = final_loss = 1.048231
n_iter 22 : loss (0.161194) + tot_loss (0.318396) + tot_loss_crop (0.296269) + loss_clip_order (0.252239) = final_loss = 1.028097
n_iter 23 : loss (0.148043) + tot_loss (0.320456) + tot_loss_crop (0.296548) + loss_clip_order (0.233245) = final_loss = 0.998292
n_iter 24 : loss (0.166373) + tot_loss (0.310155) + tot_loss_crop (0.291851) + loss_clip_order (0.248432) = final_loss = 1.016812
n_iter 25 : loss (0.167783) + tot_loss (0.316405) + tot_loss_crop (0.292772) + loss_clip_order (0.255483) = final_loss = 1.032443
n_iter 26 : loss (0.164052) + tot_loss (0.317789) + tot_loss_crop (0.293508) + loss_clip_order (0.239646) = final_loss = 1.014995
n_iter 27 : loss (0.154057) + tot_loss (0.321146) + tot_loss_crop (0.292658) + loss_clip_order (0.245719) = final_loss = 1.013579
n_iter 28 : loss (0.161438) + tot_loss (0.303865) + tot_loss_crop (0.288986) + loss_clip_order (0.238606) = final_loss = 0.992895
n_iter 29 : loss (0.154220) + tot_loss (0.318659) + tot_loss_crop (0.294169) + loss_clip_order (0.242167) = final_loss = 1.009216
n_iter 30 : loss (0.157203) + tot_loss (0.317282) + tot_loss_crop (0.288940) + loss_clip_order (0.243525) = final_loss = 1.006951
[Pretraining Epoch 016] Total-Loss 0.32 =  F-Loss 0.32 + Clip-Loss 0.24 (train)
n_iter  0 : loss (0.163387) + tot_loss (0.308846) + tot_loss_crop (0.288951) + loss_clip_order (0.244919) = final_loss = 1.006103
n_iter  1 : loss (0.169077) + tot_loss (0.325117) + tot_loss_crop (0.290846) + loss_clip_order (0.246725) = final_loss = 1.031765
n_iter  2 : loss (0.157630) + tot_loss (0.316238) + tot_loss_crop (0.284838) + loss_clip_order (0.249967) = final_loss = 1.008673
n_iter  3 : loss (0.158507) + tot_loss (0.308621) + tot_loss_crop (0.283831) + loss_clip_order (0.238789) = final_loss = 0.989749
n_iter  4 : loss (0.161791) + tot_loss (0.306190) + tot_loss_crop (0.284599) + loss_clip_order (0.243542) = final_loss = 0.996122
n_iter  5 : loss (0.168134) + tot_loss (0.310417) + tot_loss_crop (0.284284) + loss_clip_order (0.242769) = final_loss = 1.005604
n_iter  6 : loss (0.152178) + tot_loss (0.306570) + tot_loss_crop (0.283529) + loss_clip_order (0.236277) = final_loss = 0.978554
n_iter  7 : loss (0.170977) + tot_loss (0.293658) + tot_loss_crop (0.280708) + loss_clip_order (0.245293) = final_loss = 0.990635
n_iter  8 : loss (0.155001) + tot_loss (0.301386) + tot_loss_crop (0.284086) + loss_clip_order (0.238674) = final_loss = 0.979147
n_iter  9 : loss (0.146377) + tot_loss (0.297776) + tot_loss_crop (0.281781) + loss_clip_order (0.239975) = final_loss = 0.965909
n_iter 10 : loss (0.172203) + tot_loss (0.305768) + tot_loss_crop (0.281580) + loss_clip_order (0.240713) = final_loss = 1.000265
n_iter 11 : loss (0.152404) + tot_loss (0.298155) + tot_loss_crop (0.277773) + loss_clip_order (0.240045) = final_loss = 0.968377
n_iter 12 : loss (0.150297) + tot_loss (0.307136) + tot_loss_crop (0.280003) + loss_clip_order (0.233867) = final_loss = 0.971303
n_iter 13 : loss (0.159102) + tot_loss (0.305520) + tot_loss_crop (0.279444) + loss_clip_order (0.249138) = final_loss = 0.993205
n_iter 14 : loss (0.172915) + tot_loss (0.306257) + tot_loss_crop (0.278931) + loss_clip_order (0.248092) = final_loss = 1.006194
n_iter 15 : loss (0.163822) + tot_loss (0.302968) + tot_loss_crop (0.280115) + loss_clip_order (0.239508) = final_loss = 0.986414
n_iter 16 : loss (0.162639) + tot_loss (0.302358) + tot_loss_crop (0.278770) + loss_clip_order (0.233119) = final_loss = 0.976886
n_iter 17 : loss (0.164440) + tot_loss (0.299766) + tot_loss_crop (0.278206) + loss_clip_order (0.247577) = final_loss = 0.989988
n_iter 18 : loss (0.163405) + tot_loss (0.299594) + tot_loss_crop (0.277331) + loss_clip_order (0.241085) = final_loss = 0.981415
n_iter 19 : loss (0.159936) + tot_loss (0.288495) + tot_loss_crop (0.272871) + loss_clip_order (0.240092) = final_loss = 0.961395
n_iter 20 : loss (0.167620) + tot_loss (0.296595) + tot_loss_crop (0.276823) + loss_clip_order (0.241330) = final_loss = 0.982368
n_iter 21 : loss (0.166866) + tot_loss (0.310160) + tot_loss_crop (0.278868) + loss_clip_order (0.233937) = final_loss = 0.989831
n_iter 22 : loss (0.162241) + tot_loss (0.294335) + tot_loss_crop (0.271270) + loss_clip_order (0.249342) = final_loss = 0.977188
n_iter 23 : loss (0.152524) + tot_loss (0.296344) + tot_loss_crop (0.274715) + loss_clip_order (0.235837) = final_loss = 0.959419
n_iter 24 : loss (0.167194) + tot_loss (0.286010) + tot_loss_crop (0.267851) + loss_clip_order (0.240590) = final_loss = 0.961645
n_iter 25 : loss (0.157999) + tot_loss (0.292086) + tot_loss_crop (0.273762) + loss_clip_order (0.234223) = final_loss = 0.958070
n_iter 26 : loss (0.166233) + tot_loss (0.294004) + tot_loss_crop (0.270894) + loss_clip_order (0.237123) = final_loss = 0.968254
n_iter 27 : loss (0.160768) + tot_loss (0.296720) + tot_loss_crop (0.268752) + loss_clip_order (0.237468) = final_loss = 0.963708
n_iter 28 : loss (0.152115) + tot_loss (0.280303) + tot_loss_crop (0.266026) + loss_clip_order (0.232935) = final_loss = 0.931379
n_iter 29 : loss (0.162503) + tot_loss (0.294516) + tot_loss_crop (0.270959) + loss_clip_order (0.238327) = final_loss = 0.966305
n_iter 30 : loss (0.155060) + tot_loss (0.293598) + tot_loss_crop (0.268850) + loss_clip_order (0.234825) = final_loss = 0.952332
[Pretraining Epoch 017] Total-Loss 0.29 =  F-Loss 0.29 + Clip-Loss 0.23 (train)
training epoch 15
use Semi !!!
[Iteration 000] Total-Loss 2.66 = T-Loss 1.96 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.15 = T-Loss 1.46 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.00 = T-Loss 1.31 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.89 = T-Loss 1.21 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 015] Total-Loss 1.89 = T-Loss 1.21 + B-Loss 0.69 (train)[0m
[Epoch 015] Total-Loss 2.71 = T-Loss 2.04 + B-Loss 0.68  (val)
training epoch 16
use Semi !!!
[Iteration 000] Total-Loss 1.60 = T-Loss 0.92 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.64 = T-Loss 0.97 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.61 = T-Loss 0.95 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.60 = T-Loss 0.94 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 016] Total-Loss 1.60 = T-Loss 0.94 + B-Loss 0.67 (train)[0m
[Epoch 016] Total-Loss 2.69 = T-Loss 2.02 + B-Loss 0.66  (val)
training epoch 17
use Semi !!!
[Iteration 000] Total-Loss 1.63 = T-Loss 0.97 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.60 = T-Loss 0.94 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.57 = T-Loss 0.91 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.56 = T-Loss 0.90 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 017] Total-Loss 1.56 = T-Loss 0.90 + B-Loss 0.66 (train)[0m
[Epoch 017] Total-Loss 2.64 = T-Loss 1.98 + B-Loss 0.66  (val)
18
n_iter  0 : loss (0.199529) + tot_loss (0.301917) + tot_loss_crop (0.262585) + loss_clip_order (0.458285) = final_loss = 1.222316
n_iter  1 : loss (0.203568) + tot_loss (0.318439) + tot_loss_crop (0.260322) + loss_clip_order (0.430227) = final_loss = 1.212556
n_iter  2 : loss (0.198765) + tot_loss (0.312200) + tot_loss_crop (0.259646) + loss_clip_order (0.502019) = final_loss = 1.272630
n_iter  3 : loss (0.200170) + tot_loss (0.307752) + tot_loss_crop (0.262777) + loss_clip_order (0.529368) = final_loss = 1.300067
n_iter  4 : loss (0.193771) + tot_loss (0.306607) + tot_loss_crop (0.264525) + loss_clip_order (0.511325) = final_loss = 1.276229
n_iter  5 : loss (0.189827) + tot_loss (0.313142) + tot_loss_crop (0.266924) + loss_clip_order (0.455125) = final_loss = 1.225017
n_iter  6 : loss (0.187989) + tot_loss (0.311146) + tot_loss_crop (0.269620) + loss_clip_order (0.406071) = final_loss = 1.174826
n_iter  7 : loss (0.186785) + tot_loss (0.297349) + tot_loss_crop (0.268300) + loss_clip_order (0.349803) = final_loss = 1.102236
n_iter  8 : loss (0.171161) + tot_loss (0.303965) + tot_loss_crop (0.273351) + loss_clip_order (0.258638) = final_loss = 1.007115
n_iter  9 : loss (0.177794) + tot_loss (0.298314) + tot_loss_crop (0.276468) + loss_clip_order (0.234281) = final_loss = 0.986858
n_iter 10 : loss (0.168397) + tot_loss (0.307707) + tot_loss_crop (0.279297) + loss_clip_order (0.232614) = final_loss = 0.988016
n_iter 11 : loss (0.173174) + tot_loss (0.297599) + tot_loss_crop (0.278114) + loss_clip_order (0.227813) = final_loss = 0.976700
n_iter 12 : loss (0.163778) + tot_loss (0.308249) + tot_loss_crop (0.278050) + loss_clip_order (0.260917) = final_loss = 1.010994
n_iter 13 : loss (0.171642) + tot_loss (0.304076) + tot_loss_crop (0.281574) + loss_clip_order (0.256208) = final_loss = 1.013500
n_iter 14 : loss (0.169670) + tot_loss (0.305187) + tot_loss_crop (0.281641) + loss_clip_order (0.296921) = final_loss = 1.053419
n_iter 15 : loss (0.171230) + tot_loss (0.301879) + tot_loss_crop (0.279744) + loss_clip_order (0.283930) = final_loss = 1.036783
n_iter 16 : loss (0.160056) + tot_loss (0.298923) + tot_loss_crop (0.278267) + loss_clip_order (0.240647) = final_loss = 0.977893
n_iter 17 : loss (0.167776) + tot_loss (0.296505) + tot_loss_crop (0.278847) + loss_clip_order (0.265235) = final_loss = 1.008363
n_iter 18 : loss (0.151518) + tot_loss (0.296387) + tot_loss_crop (0.275130) + loss_clip_order (0.232285) = final_loss = 0.955320
n_iter 19 : loss (0.175842) + tot_loss (0.286400) + tot_loss_crop (0.274523) + loss_clip_order (0.221993) = final_loss = 0.958758
n_iter 20 : loss (0.173863) + tot_loss (0.295627) + tot_loss_crop (0.276863) + loss_clip_order (0.234384) = final_loss = 0.980737
n_iter 21 : loss (0.167329) + tot_loss (0.308073) + tot_loss_crop (0.279264) + loss_clip_order (0.228877) = final_loss = 0.983543
n_iter 22 : loss (0.160416) + tot_loss (0.292994) + tot_loss_crop (0.272797) + loss_clip_order (0.242450) = final_loss = 0.968657
n_iter 23 : loss (0.154269) + tot_loss (0.295263) + tot_loss_crop (0.274822) + loss_clip_order (0.229601) = final_loss = 0.953955
n_iter 24 : loss (0.161946) + tot_loss (0.285895) + tot_loss_crop (0.271486) + loss_clip_order (0.241789) = final_loss = 0.961116
n_iter 25 : loss (0.161431) + tot_loss (0.291257) + tot_loss_crop (0.272425) + loss_clip_order (0.237040) = final_loss = 0.962152
n_iter 26 : loss (0.161748) + tot_loss (0.293649) + tot_loss_crop (0.272301) + loss_clip_order (0.238232) = final_loss = 0.965929
n_iter 27 : loss (0.161012) + tot_loss (0.294544) + tot_loss_crop (0.269681) + loss_clip_order (0.245473) = final_loss = 0.970710
n_iter 28 : loss (0.158004) + tot_loss (0.277506) + tot_loss_crop (0.266512) + loss_clip_order (0.242797) = final_loss = 0.944819
n_iter 29 : loss (0.159461) + tot_loss (0.291224) + tot_loss_crop (0.270988) + loss_clip_order (0.228779) = final_loss = 0.950452
n_iter 30 : loss (0.155297) + tot_loss (0.288614) + tot_loss_crop (0.266390) + loss_clip_order (0.231932) = final_loss = 0.942233
[Pretraining Epoch 018] Total-Loss 0.29 =  F-Loss 0.29 + Clip-Loss 0.23 (train)
n_iter  0 : loss (0.171134) + tot_loss (0.279214) + tot_loss_crop (0.263773) + loss_clip_order (0.240329) = final_loss = 0.954450
n_iter  1 : loss (0.169019) + tot_loss (0.294087) + tot_loss_crop (0.269314) + loss_clip_order (0.230810) = final_loss = 0.963229
n_iter  2 : loss (0.160047) + tot_loss (0.284092) + tot_loss_crop (0.261907) + loss_clip_order (0.239006) = final_loss = 0.945052
n_iter  3 : loss (0.152184) + tot_loss (0.275314) + tot_loss_crop (0.260084) + loss_clip_order (0.223493) = final_loss = 0.911075
n_iter  4 : loss (0.162892) + tot_loss (0.271767) + tot_loss_crop (0.260245) + loss_clip_order (0.227849) = final_loss = 0.922754
n_iter  5 : loss (0.149744) + tot_loss (0.275567) + tot_loss_crop (0.257742) + loss_clip_order (0.226259) = final_loss = 0.909312
n_iter  6 : loss (0.163433) + tot_loss (0.271052) + tot_loss_crop (0.260081) + loss_clip_order (0.227563) = final_loss = 0.922129
n_iter  7 : loss (0.154985) + tot_loss (0.257395) + tot_loss_crop (0.255962) + loss_clip_order (0.220808) = final_loss = 0.889150
n_iter  8 : loss (0.157484) + tot_loss (0.264729) + tot_loss_crop (0.254592) + loss_clip_order (0.231249) = final_loss = 0.908053
n_iter  9 : loss (0.163043) + tot_loss (0.260837) + tot_loss_crop (0.255876) + loss_clip_order (0.227143) = final_loss = 0.906899
n_iter 10 : loss (0.173349) + tot_loss (0.268427) + tot_loss_crop (0.257156) + loss_clip_order (0.230946) = final_loss = 0.929878
n_iter 11 : loss (0.168784) + tot_loss (0.260116) + tot_loss_crop (0.253067) + loss_clip_order (0.220628) = final_loss = 0.902595
n_iter 12 : loss (0.168553) + tot_loss (0.268908) + tot_loss_crop (0.253067) + loss_clip_order (0.221000) = final_loss = 0.911528
n_iter 13 : loss (0.163890) + tot_loss (0.267331) + tot_loss_crop (0.253863) + loss_clip_order (0.216912) = final_loss = 0.901996
n_iter 14 : loss (0.156980) + tot_loss (0.267532) + tot_loss_crop (0.250015) + loss_clip_order (0.230518) = final_loss = 0.905045
n_iter 15 : loss (0.157756) + tot_loss (0.264420) + tot_loss_crop (0.251070) + loss_clip_order (0.226884) = final_loss = 0.900130
n_iter 16 : loss (0.159776) + tot_loss (0.263865) + tot_loss_crop (0.250358) + loss_clip_order (0.219725) = final_loss = 0.893724
n_iter 17 : loss (0.163731) + tot_loss (0.262045) + tot_loss_crop (0.248151) + loss_clip_order (0.235187) = final_loss = 0.909114
n_iter 18 : loss (0.154815) + tot_loss (0.261674) + tot_loss_crop (0.246776) + loss_clip_order (0.232558) = final_loss = 0.895823
n_iter 19 : loss (0.175165) + tot_loss (0.250537) + tot_loss_crop (0.245157) + loss_clip_order (0.222460) = final_loss = 0.893319
n_iter 20 : loss (0.168858) + tot_loss (0.258919) + tot_loss_crop (0.245356) + loss_clip_order (0.227186) = final_loss = 0.900319
n_iter 21 : loss (0.174721) + tot_loss (0.271600) + tot_loss_crop (0.246825) + loss_clip_order (0.230003) = final_loss = 0.923150
n_iter 22 : loss (0.172254) + tot_loss (0.256432) + tot_loss_crop (0.240113) + loss_clip_order (0.237147) = final_loss = 0.905946
n_iter 23 : loss (0.167555) + tot_loss (0.258564) + tot_loss_crop (0.242840) + loss_clip_order (0.228467) = final_loss = 0.897426
n_iter 24 : loss (0.159100) + tot_loss (0.248672) + tot_loss_crop (0.237045) + loss_clip_order (0.229786) = final_loss = 0.874603
n_iter 25 : loss (0.159664) + tot_loss (0.254421) + tot_loss_crop (0.239183) + loss_clip_order (0.229473) = final_loss = 0.882740
n_iter 26 : loss (0.162941) + tot_loss (0.255969) + tot_loss_crop (0.239888) + loss_clip_order (0.229985) = final_loss = 0.888784
n_iter 27 : loss (0.162415) + tot_loss (0.258904) + tot_loss_crop (0.239024) + loss_clip_order (0.223359) = final_loss = 0.883702
n_iter 28 : loss (0.163224) + tot_loss (0.243136) + tot_loss_crop (0.232425) + loss_clip_order (0.232671) = final_loss = 0.871456
n_iter 29 : loss (0.148217) + tot_loss (0.256666) + tot_loss_crop (0.236271) + loss_clip_order (0.221445) = final_loss = 0.862599
n_iter 30 : loss (0.156565) + tot_loss (0.255840) + tot_loss_crop (0.237648) + loss_clip_order (0.217623) = final_loss = 0.867676
[Pretraining Epoch 019] Total-Loss 0.26 =  F-Loss 0.26 + Clip-Loss 0.22 (train)
n_iter  0 : loss (0.172630) + tot_loss (0.246744) + tot_loss_crop (0.235277) + loss_clip_order (0.231352) = final_loss = 0.886003
n_iter  1 : loss (0.159243) + tot_loss (0.263016) + tot_loss_crop (0.236847) + loss_clip_order (0.233132) = final_loss = 0.892238
n_iter  2 : loss (0.159417) + tot_loss (0.254562) + tot_loss_crop (0.234102) + loss_clip_order (0.225569) = final_loss = 0.873650
n_iter  3 : loss (0.159450) + tot_loss (0.247393) + tot_loss_crop (0.230557) + loss_clip_order (0.225148) = final_loss = 0.862548
n_iter  4 : loss (0.148608) + tot_loss (0.244877) + tot_loss_crop (0.230666) + loss_clip_order (0.223068) = final_loss = 0.847218
n_iter  5 : loss (0.154146) + tot_loss (0.249486) + tot_loss_crop (0.230470) + loss_clip_order (0.219057) = final_loss = 0.853159
n_iter  6 : loss (0.164837) + tot_loss (0.245989) + tot_loss_crop (0.228683) + loss_clip_order (0.224845) = final_loss = 0.864355
n_iter  7 : loss (0.158563) + tot_loss (0.233076) + tot_loss_crop (0.222840) + loss_clip_order (0.238127) = final_loss = 0.852606
n_iter  8 : loss (0.159960) + tot_loss (0.241071) + tot_loss_crop (0.226234) + loss_clip_order (0.231725) = final_loss = 0.858989
n_iter  9 : loss (0.159614) + tot_loss (0.237605) + tot_loss_crop (0.223327) + loss_clip_order (0.226079) = final_loss = 0.846624
n_iter 10 : loss (0.166032) + tot_loss (0.245211) + tot_loss_crop (0.223136) + loss_clip_order (0.238028) = final_loss = 0.872406
n_iter 11 : loss (0.174792) + tot_loss (0.238002) + tot_loss_crop (0.221836) + loss_clip_order (0.237540) = final_loss = 0.872170
n_iter 12 : loss (0.162135) + tot_loss (0.246598) + tot_loss_crop (0.224572) + loss_clip_order (0.223278) = final_loss = 0.856583
n_iter 13 : loss (0.157637) + tot_loss (0.245084) + tot_loss_crop (0.226025) + loss_clip_order (0.219850) = final_loss = 0.848596
n_iter 14 : loss (0.171675) + tot_loss (0.245628) + tot_loss_crop (0.224314) + loss_clip_order (0.232018) = final_loss = 0.873635
n_iter 15 : loss (0.164715) + tot_loss (0.242154) + tot_loss_crop (0.225351) + loss_clip_order (0.225804) = final_loss = 0.858025
n_iter 16 : loss (0.155685) + tot_loss (0.242593) + tot_loss_crop (0.220153) + loss_clip_order (0.229935) = final_loss = 0.848366
n_iter 17 : loss (0.150726) + tot_loss (0.240360) + tot_loss_crop (0.222257) + loss_clip_order (0.237400) = final_loss = 0.850742
n_iter 18 : loss (0.161297) + tot_loss (0.240584) + tot_loss_crop (0.222987) + loss_clip_order (0.221528) = final_loss = 0.846396
n_iter 19 : loss (0.173108) + tot_loss (0.229862) + tot_loss_crop (0.215195) + loss_clip_order (0.238338) = final_loss = 0.856503
n_iter 20 : loss (0.165751) + tot_loss (0.237913) + tot_loss_crop (0.217375) + loss_clip_order (0.229213) = final_loss = 0.850252
n_iter 21 : loss (0.167924) + tot_loss (0.251001) + tot_loss_crop (0.223281) + loss_clip_order (0.230976) = final_loss = 0.873182
n_iter 22 : loss (0.161948) + tot_loss (0.235074) + tot_loss_crop (0.215708) + loss_clip_order (0.230268) = final_loss = 0.842998
n_iter 23 : loss (0.162298) + tot_loss (0.237755) + tot_loss_crop (0.218791) + loss_clip_order (0.226274) = final_loss = 0.845117
n_iter 24 : loss (0.172284) + tot_loss (0.227536) + tot_loss_crop (0.213243) + loss_clip_order (0.226166) = final_loss = 0.839229
n_iter 25 : loss (0.157243) + tot_loss (0.233432) + tot_loss_crop (0.218289) + loss_clip_order (0.218712) = final_loss = 0.827676
n_iter 26 : loss (0.165500) + tot_loss (0.235147) + tot_loss_crop (0.219256) + loss_clip_order (0.221193) = final_loss = 0.841097
n_iter 27 : loss (0.164561) + tot_loss (0.238449) + tot_loss_crop (0.217470) + loss_clip_order (0.225948) = final_loss = 0.846428
n_iter 28 : loss (0.163655) + tot_loss (0.222270) + tot_loss_crop (0.210488) + loss_clip_order (0.229847) = final_loss = 0.826260
n_iter 29 : loss (0.158016) + tot_loss (0.235760) + tot_loss_crop (0.219167) + loss_clip_order (0.228864) = final_loss = 0.841807
n_iter 30 : loss (0.159708) + tot_loss (0.235329) + tot_loss_crop (0.215542) + loss_clip_order (0.221750) = final_loss = 0.832329
[Pretraining Epoch 020] Total-Loss 0.24 =  F-Loss 0.24 + Clip-Loss 0.22 (train)
training epoch 18
use Semi !!!
[Iteration 000] Total-Loss 4.43 = T-Loss 3.74 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.93 = T-Loss 2.23 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.57 = T-Loss 1.87 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 2.37 = T-Loss 1.67 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 018] Total-Loss 2.37 = T-Loss 1.67 + B-Loss 0.70 (train)[0m
[Epoch 018] Total-Loss 2.86 = T-Loss 2.17 + B-Loss 0.69  (val)
training epoch 19
use Semi !!!
[Iteration 000] Total-Loss 1.73 = T-Loss 1.04 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.78 = T-Loss 1.09 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.71 = T-Loss 1.03 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.66 = T-Loss 0.99 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 019] Total-Loss 1.66 = T-Loss 0.99 + B-Loss 0.68 (train)[0m
[Epoch 019] Total-Loss 2.70 = T-Loss 2.04 + B-Loss 0.67  (val)
training epoch 20
use Semi !!!
[Iteration 000] Total-Loss 1.53 = T-Loss 0.86 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.59 = T-Loss 0.93 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.57 = T-Loss 0.91 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.54 = T-Loss 0.88 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 020] Total-Loss 1.54 = T-Loss 0.88 + B-Loss 0.66 (train)[0m
[Epoch 020] Total-Loss 2.72 = T-Loss 2.06 + B-Loss 0.66  (val)
21
n_iter  0 : loss (0.230464) + tot_loss (0.336296) + tot_loss_crop (0.273854) + loss_clip_order (1.335338) = final_loss = 2.175953
n_iter  1 : loss (0.232590) + tot_loss (0.333872) + tot_loss_crop (0.257505) + loss_clip_order (0.302334) = final_loss = 1.126300
n_iter  2 : loss (0.230207) + tot_loss (0.323808) + tot_loss_crop (0.262256) + loss_clip_order (0.460575) = final_loss = 1.276847
n_iter  3 : loss (0.223509) + tot_loss (0.319617) + tot_loss_crop (0.268716) + loss_clip_order (0.539054) = final_loss = 1.350896
n_iter  4 : loss (0.213123) + tot_loss (0.320020) + tot_loss_crop (0.270060) + loss_clip_order (0.593774) = final_loss = 1.396976
n_iter  5 : loss (0.198379) + tot_loss (0.323693) + tot_loss_crop (0.270366) + loss_clip_order (0.548725) = final_loss = 1.341163
n_iter  6 : loss (0.189114) + tot_loss (0.314602) + tot_loss_crop (0.263125) + loss_clip_order (0.534670) = final_loss = 1.301511
n_iter  7 : loss (0.173641) + tot_loss (0.292435) + tot_loss_crop (0.254339) + loss_clip_order (0.475840) = final_loss = 1.196256
n_iter  8 : loss (0.174196) + tot_loss (0.287410) + tot_loss_crop (0.250330) + loss_clip_order (0.433793) = final_loss = 1.145729
n_iter  9 : loss (0.158577) + tot_loss (0.269701) + tot_loss_crop (0.241457) + loss_clip_order (0.324902) = final_loss = 0.994636
n_iter 10 : loss (0.154243) + tot_loss (0.263496) + tot_loss_crop (0.237242) + loss_clip_order (0.251046) = final_loss = 0.906027
n_iter 11 : loss (0.172217) + tot_loss (0.243433) + tot_loss_crop (0.230595) + loss_clip_order (0.226236) = final_loss = 0.872480
n_iter 12 : loss (0.166164) + tot_loss (0.244668) + tot_loss_crop (0.230941) + loss_clip_order (0.211085) = final_loss = 0.852857
n_iter 13 : loss (0.177043) + tot_loss (0.239573) + tot_loss_crop (0.233371) + loss_clip_order (0.304252) = final_loss = 0.954240
n_iter 14 : loss (0.164033) + tot_loss (0.237810) + tot_loss_crop (0.228058) + loss_clip_order (0.219202) = final_loss = 0.849104
n_iter 15 : loss (0.162274) + tot_loss (0.237726) + tot_loss_crop (0.228017) + loss_clip_order (0.218559) = final_loss = 0.846576
n_iter 16 : loss (0.160313) + tot_loss (0.242170) + tot_loss_crop (0.229484) + loss_clip_order (0.222707) = final_loss = 0.854675
n_iter 17 : loss (0.157712) + tot_loss (0.245581) + tot_loss_crop (0.230184) + loss_clip_order (0.227692) = final_loss = 0.861168
n_iter 18 : loss (0.161964) + tot_loss (0.250113) + tot_loss_crop (0.234832) + loss_clip_order (0.223744) = final_loss = 0.870653
n_iter 19 : loss (0.172357) + tot_loss (0.242086) + tot_loss_crop (0.234700) + loss_clip_order (0.223917) = final_loss = 0.873059
n_iter 20 : loss (0.161644) + tot_loss (0.254230) + tot_loss_crop (0.234597) + loss_clip_order (0.215912) = final_loss = 0.866383
n_iter 21 : loss (0.154375) + tot_loss (0.268153) + tot_loss_crop (0.237640) + loss_clip_order (0.220888) = final_loss = 0.881056
n_iter 22 : loss (0.147547) + tot_loss (0.251565) + tot_loss_crop (0.234654) + loss_clip_order (0.219708) = final_loss = 0.853474
n_iter 23 : loss (0.167910) + tot_loss (0.253623) + tot_loss_crop (0.239420) + loss_clip_order (0.217517) = final_loss = 0.878470
n_iter 24 : loss (0.169571) + tot_loss (0.240513) + tot_loss_crop (0.236773) + loss_clip_order (0.212836) = final_loss = 0.859692
n_iter 25 : loss (0.166321) + tot_loss (0.245862) + tot_loss_crop (0.235259) + loss_clip_order (0.215986) = final_loss = 0.863429
n_iter 26 : loss (0.165085) + tot_loss (0.245562) + tot_loss_crop (0.235042) + loss_clip_order (0.221425) = final_loss = 0.867114
n_iter 27 : loss (0.169272) + tot_loss (0.244244) + tot_loss_crop (0.232725) + loss_clip_order (0.215045) = final_loss = 0.861286
n_iter 28 : loss (0.160949) + tot_loss (0.226528) + tot_loss_crop (0.226618) + loss_clip_order (0.207887) = final_loss = 0.821983
n_iter 29 : loss (0.162368) + tot_loss (0.237782) + tot_loss_crop (0.228425) + loss_clip_order (0.220381) = final_loss = 0.848957
n_iter 30 : loss (0.172900) + tot_loss (0.234756) + tot_loss_crop (0.228203) + loss_clip_order (0.207473) = final_loss = 0.843332
[Pretraining Epoch 021] Total-Loss 0.23 =  F-Loss 0.23 + Clip-Loss 0.21 (train)
n_iter  0 : loss (0.168162) + tot_loss (0.224679) + tot_loss_crop (0.224327) + loss_clip_order (0.215162) = final_loss = 0.832331
n_iter  1 : loss (0.166846) + tot_loss (0.238754) + tot_loss_crop (0.225801) + loss_clip_order (0.224866) = final_loss = 0.856267
n_iter  2 : loss (0.163724) + tot_loss (0.230095) + tot_loss_crop (0.220543) + loss_clip_order (0.210013) = final_loss = 0.824375
n_iter  3 : loss (0.167412) + tot_loss (0.221399) + tot_loss_crop (0.220460) + loss_clip_order (0.210267) = final_loss = 0.819539
n_iter  4 : loss (0.169455) + tot_loss (0.218656) + tot_loss_crop (0.220527) + loss_clip_order (0.230137) = final_loss = 0.838776
n_iter  5 : loss (0.155230) + tot_loss (0.223501) + tot_loss_crop (0.219610) + loss_clip_order (0.245334) = final_loss = 0.843676
n_iter  6 : loss (0.168173) + tot_loss (0.218862) + tot_loss_crop (0.219275) + loss_clip_order (0.232599) = final_loss = 0.838909
n_iter  7 : loss (0.166410) + tot_loss (0.206153) + tot_loss_crop (0.215626) + loss_clip_order (0.209261) = final_loss = 0.797451
n_iter  8 : loss (0.156684) + tot_loss (0.215546) + tot_loss_crop (0.216385) + loss_clip_order (0.220909) = final_loss = 0.809525
n_iter  9 : loss (0.164825) + tot_loss (0.213003) + tot_loss_crop (0.214709) + loss_clip_order (0.214547) = final_loss = 0.807085
n_iter 10 : loss (0.162795) + tot_loss (0.221489) + tot_loss_crop (0.215997) + loss_clip_order (0.217375) = final_loss = 0.817656
n_iter 11 : loss (0.164801) + tot_loss (0.214733) + tot_loss_crop (0.214531) + loss_clip_order (0.208300) = final_loss = 0.802365
n_iter 12 : loss (0.163296) + tot_loss (0.223777) + tot_loss_crop (0.212472) + loss_clip_order (0.208212) = final_loss = 0.807758
n_iter 13 : loss (0.150863) + tot_loss (0.223431) + tot_loss_crop (0.212866) + loss_clip_order (0.208488) = final_loss = 0.795648
n_iter 14 : loss (0.154995) + tot_loss (0.223837) + tot_loss_crop (0.213361) + loss_clip_order (0.212212) = final_loss = 0.804405
n_iter 15 : loss (0.163429) + tot_loss (0.219960) + tot_loss_crop (0.214331) + loss_clip_order (0.211634) = final_loss = 0.809355
n_iter 16 : loss (0.166947) + tot_loss (0.220668) + tot_loss_crop (0.211308) + loss_clip_order (0.214835) = final_loss = 0.813759
n_iter 17 : loss (0.160937) + tot_loss (0.217943) + tot_loss_crop (0.209627) + loss_clip_order (0.217369) = final_loss = 0.805876
n_iter 18 : loss (0.161882) + tot_loss (0.217562) + tot_loss_crop (0.210297) + loss_clip_order (0.208325) = final_loss = 0.798066
n_iter 19 : loss (0.155630) + tot_loss (0.204669) + tot_loss_crop (0.201709) + loss_clip_order (0.212184) = final_loss = 0.774192
n_iter 20 : loss (0.158253) + tot_loss (0.213495) + tot_loss_crop (0.205652) + loss_clip_order (0.213688) = final_loss = 0.791088
n_iter 21 : loss (0.163367) + tot_loss (0.225948) + tot_loss_crop (0.208276) + loss_clip_order (0.216210) = final_loss = 0.813801
n_iter 22 : loss (0.163591) + tot_loss (0.209176) + tot_loss_crop (0.201763) + loss_clip_order (0.216529) = final_loss = 0.791059
n_iter 23 : loss (0.169841) + tot_loss (0.212110) + tot_loss_crop (0.209357) + loss_clip_order (0.208403) = final_loss = 0.799710
n_iter 24 : loss (0.155771) + tot_loss (0.199960) + tot_loss_crop (0.199185) + loss_clip_order (0.211683) = final_loss = 0.766598
n_iter 25 : loss (0.159135) + tot_loss (0.206616) + tot_loss_crop (0.205247) + loss_clip_order (0.203649) = final_loss = 0.774646
n_iter 26 : loss (0.164284) + tot_loss (0.208040) + tot_loss_crop (0.205719) + loss_clip_order (0.222223) = final_loss = 0.800266
n_iter 27 : loss (0.165326) + tot_loss (0.210408) + tot_loss_crop (0.201223) + loss_clip_order (0.202220) = final_loss = 0.779176
n_iter 28 : loss (0.159135) + tot_loss (0.195080) + tot_loss_crop (0.197391) + loss_clip_order (0.203875) = final_loss = 0.755481
n_iter 29 : loss (0.160873) + tot_loss (0.207757) + tot_loss_crop (0.204037) + loss_clip_order (0.205707) = final_loss = 0.778374
n_iter 30 : loss (0.168974) + tot_loss (0.207916) + tot_loss_crop (0.200570) + loss_clip_order (0.209596) = final_loss = 0.787055
[Pretraining Epoch 022] Total-Loss 0.21 =  F-Loss 0.21 + Clip-Loss 0.21 (train)
n_iter  0 : loss (0.176075) + tot_loss (0.199467) + tot_loss_crop (0.200538) + loss_clip_order (0.209486) = final_loss = 0.785566
n_iter  1 : loss (0.168559) + tot_loss (0.215094) + tot_loss_crop (0.202794) + loss_clip_order (0.211441) = final_loss = 0.797887
n_iter  2 : loss (0.157684) + tot_loss (0.207242) + tot_loss_crop (0.196400) + loss_clip_order (0.204444) = final_loss = 0.765770
n_iter  3 : loss (0.161696) + tot_loss (0.199994) + tot_loss_crop (0.197131) + loss_clip_order (0.202215) = final_loss = 0.761037
n_iter  4 : loss (0.168062) + tot_loss (0.197997) + tot_loss_crop (0.195699) + loss_clip_order (0.207021) = final_loss = 0.768780
n_iter  5 : loss (0.169929) + tot_loss (0.203316) + tot_loss_crop (0.197097) + loss_clip_order (0.208939) = final_loss = 0.779281
n_iter  6 : loss (0.157925) + tot_loss (0.199244) + tot_loss_crop (0.190579) + loss_clip_order (0.210958) = final_loss = 0.758705
n_iter  7 : loss (0.164714) + tot_loss (0.185463) + tot_loss_crop (0.186706) + loss_clip_order (0.209473) = final_loss = 0.746356
n_iter  8 : loss (0.156462) + tot_loss (0.194504) + tot_loss_crop (0.189886) + loss_clip_order (0.205437) = final_loss = 0.746289
n_iter  9 : loss (0.159868) + tot_loss (0.190687) + tot_loss_crop (0.186778) + loss_clip_order (0.203783) = final_loss = 0.741116
n_iter 10 : loss (0.156098) + tot_loss (0.198709) + tot_loss_crop (0.189579) + loss_clip_order (0.201759) = final_loss = 0.746144
n_iter 11 : loss (0.172335) + tot_loss (0.191605) + tot_loss_crop (0.186241) + loss_clip_order (0.205293) = final_loss = 0.755474
n_iter 12 : loss (0.173293) + tot_loss (0.200299) + tot_loss_crop (0.188737) + loss_clip_order (0.200854) = final_loss = 0.763183
n_iter 13 : loss (0.157724) + tot_loss (0.198886) + tot_loss_crop (0.189336) + loss_clip_order (0.197474) = final_loss = 0.743420
n_iter 14 : loss (0.176058) + tot_loss (0.199321) + tot_loss_crop (0.189565) + loss_clip_order (0.202543) = final_loss = 0.767487
n_iter 15 : loss (0.169573) + tot_loss (0.195381) + tot_loss_crop (0.190513) + loss_clip_order (0.204663) = final_loss = 0.760130
n_iter 16 : loss (0.158847) + tot_loss (0.196548) + tot_loss_crop (0.186887) + loss_clip_order (0.200336) = final_loss = 0.742618
n_iter 17 : loss (0.151706) + tot_loss (0.194014) + tot_loss_crop (0.182865) + loss_clip_order (0.216420) = final_loss = 0.745006
n_iter 18 : loss (0.165086) + tot_loss (0.194683) + tot_loss_crop (0.180294) + loss_clip_order (0.212125) = final_loss = 0.752189
n_iter 19 : loss (0.167576) + tot_loss (0.182762) + tot_loss_crop (0.179647) + loss_clip_order (0.213767) = final_loss = 0.743752
n_iter 20 : loss (0.152681) + tot_loss (0.191329) + tot_loss_crop (0.179459) + loss_clip_order (0.205110) = final_loss = 0.728580
n_iter 21 : loss (0.159177) + tot_loss (0.204407) + tot_loss_crop (0.184532) + loss_clip_order (0.202221) = final_loss = 0.750336
n_iter 22 : loss (0.176769) + tot_loss (0.188814) + tot_loss_crop (0.177439) + loss_clip_order (0.216070) = final_loss = 0.759092
n_iter 23 : loss (0.157432) + tot_loss (0.191901) + tot_loss_crop (0.180793) + loss_clip_order (0.203153) = final_loss = 0.733279
n_iter 24 : loss (0.158696) + tot_loss (0.180914) + tot_loss_crop (0.175231) + loss_clip_order (0.207407) = final_loss = 0.722248
n_iter 25 : loss (0.165401) + tot_loss (0.187810) + tot_loss_crop (0.179967) + loss_clip_order (0.201993) = final_loss = 0.735170
n_iter 26 : loss (0.159842) + tot_loss (0.189473) + tot_loss_crop (0.179327) + loss_clip_order (0.208404) = final_loss = 0.737046
n_iter 27 : loss (0.156708) + tot_loss (0.192063) + tot_loss_crop (0.177292) + loss_clip_order (0.203111) = final_loss = 0.729174
n_iter 28 : loss (0.156479) + tot_loss (0.176974) + tot_loss_crop (0.172473) + loss_clip_order (0.207152) = final_loss = 0.713079
n_iter 29 : loss (0.167500) + tot_loss (0.190327) + tot_loss_crop (0.176694) + loss_clip_order (0.201801) = final_loss = 0.736322
n_iter 30 : loss (0.168930) + tot_loss (0.189773) + tot_loss_crop (0.173029) + loss_clip_order (0.211772) = final_loss = 0.743505
[Pretraining Epoch 023] Total-Loss 0.19 =  F-Loss 0.19 + Clip-Loss 0.21 (train)
training epoch 21
use Semi !!!
[Iteration 000] Total-Loss 3.12 = T-Loss 2.42 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.40 = T-Loss 1.70 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.14 = T-Loss 1.44 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.98 = T-Loss 1.28 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 021] Total-Loss 1.98 = T-Loss 1.28 + B-Loss 0.69 (train)[0m
[Epoch 021] Total-Loss 2.70 = T-Loss 2.02 + B-Loss 0.68  (val)
training epoch 22
use Semi !!!
[Iteration 000] Total-Loss 1.62 = T-Loss 0.93 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.63 = T-Loss 0.96 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.60 = T-Loss 0.93 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.56 = T-Loss 0.90 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 022] Total-Loss 1.56 = T-Loss 0.90 + B-Loss 0.66 (train)[0m
[Epoch 022] Total-Loss 2.63 = T-Loss 1.96 + B-Loss 0.66  (val)
training epoch 23
use Semi !!!
[Iteration 000] Total-Loss 1.52 = T-Loss 0.85 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.55 = T-Loss 0.89 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.54 = T-Loss 0.88 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.52 = T-Loss 0.86 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 023] Total-Loss 1.52 = T-Loss 0.86 + B-Loss 0.66 (train)[0m
[Epoch 023] Total-Loss 2.58 = T-Loss 1.92 + B-Loss 0.66  (val)
24
n_iter  0 : loss (0.203656) + tot_loss (0.210107) + tot_loss_crop (0.191515) + loss_clip_order (3.342889) = final_loss = 3.948167
n_iter  1 : loss (0.215541) + tot_loss (0.272282) + tot_loss_crop (0.215522) + loss_clip_order (0.478630) = final_loss = 1.181975
n_iter  2 : loss (0.222604) + tot_loss (0.338124) + tot_loss_crop (0.269795) + loss_clip_order (0.633012) = final_loss = 1.463535
n_iter  3 : loss (0.210337) + tot_loss (0.378627) + tot_loss_crop (0.302375) + loss_clip_order (0.674333) = final_loss = 1.565672
n_iter  4 : loss (0.193820) + tot_loss (0.405263) + tot_loss_crop (0.321905) + loss_clip_order (0.696113) = final_loss = 1.617100
n_iter  5 : loss (0.171966) + tot_loss (0.428869) + tot_loss_crop (0.333485) + loss_clip_order (0.658686) = final_loss = 1.593007
n_iter  6 : loss (0.161837) + tot_loss (0.432784) + tot_loss_crop (0.338678) + loss_clip_order (0.658746) = final_loss = 1.592045
n_iter  7 : loss (0.163782) + tot_loss (0.427549) + tot_loss_crop (0.339659) + loss_clip_order (0.678213) = final_loss = 1.609202
n_iter  8 : loss (0.158094) + tot_loss (0.441090) + tot_loss_crop (0.339308) + loss_clip_order (0.615776) = final_loss = 1.554268
n_iter  9 : loss (0.168649) + tot_loss (0.438958) + tot_loss_crop (0.339535) + loss_clip_order (0.583872) = final_loss = 1.531014
n_iter 10 : loss (0.169685) + tot_loss (0.447814) + tot_loss_crop (0.336713) + loss_clip_order (0.499441) = final_loss = 1.453654
n_iter 11 : loss (0.169642) + tot_loss (0.442997) + tot_loss_crop (0.333875) + loss_clip_order (0.477472) = final_loss = 1.423986
n_iter 12 : loss (0.177817) + tot_loss (0.449143) + tot_loss_crop (0.332561) + loss_clip_order (0.407498) = final_loss = 1.367020
n_iter 13 : loss (0.159773) + tot_loss (0.447804) + tot_loss_crop (0.330832) + loss_clip_order (0.342024) = final_loss = 1.280433
n_iter 14 : loss (0.163994) + tot_loss (0.446000) + tot_loss_crop (0.329042) + loss_clip_order (0.342379) = final_loss = 1.281414
n_iter 15 : loss (0.168733) + tot_loss (0.439520) + tot_loss_crop (0.325951) + loss_clip_order (0.318457) = final_loss = 1.252660
n_iter 16 : loss (0.168980) + tot_loss (0.438523) + tot_loss_crop (0.322974) + loss_clip_order (0.287478) = final_loss = 1.217955
n_iter 17 : loss (0.163588) + tot_loss (0.431168) + tot_loss_crop (0.321670) + loss_clip_order (0.283393) = final_loss = 1.199819
n_iter 18 : loss (0.165380) + tot_loss (0.429685) + tot_loss_crop (0.319348) + loss_clip_order (0.255775) = final_loss = 1.170188
n_iter 19 : loss (0.165747) + tot_loss (0.411130) + tot_loss_crop (0.314190) + loss_clip_order (0.275259) = final_loss = 1.166326
n_iter 20 : loss (0.163602) + tot_loss (0.416086) + tot_loss_crop (0.313800) + loss_clip_order (0.256407) = final_loss = 1.149895
n_iter 21 : loss (0.162831) + tot_loss (0.429859) + tot_loss_crop (0.313735) + loss_clip_order (0.231823) = final_loss = 1.138247
n_iter 22 : loss (0.162702) + tot_loss (0.405785) + tot_loss_crop (0.307837) + loss_clip_order (0.244886) = final_loss = 1.121210
n_iter 23 : loss (0.161026) + tot_loss (0.408358) + tot_loss_crop (0.307150) + loss_clip_order (0.226920) = final_loss = 1.103454
n_iter 24 : loss (0.156704) + tot_loss (0.388984) + tot_loss_crop (0.302380) + loss_clip_order (0.222432) = final_loss = 1.070500
n_iter 25 : loss (0.165071) + tot_loss (0.391574) + tot_loss_crop (0.300060) + loss_clip_order (0.226737) = final_loss = 1.083442
n_iter 26 : loss (0.159676) + tot_loss (0.387527) + tot_loss_crop (0.299236) + loss_clip_order (0.209302) = final_loss = 1.055740
n_iter 27 : loss (0.154934) + tot_loss (0.387367) + tot_loss_crop (0.295437) + loss_clip_order (0.222216) = final_loss = 1.059955
n_iter 28 : loss (0.158150) + tot_loss (0.367422) + tot_loss_crop (0.290372) + loss_clip_order (0.216532) = final_loss = 1.032475
n_iter 29 : loss (0.166677) + tot_loss (0.376680) + tot_loss_crop (0.289994) + loss_clip_order (0.221250) = final_loss = 1.054602
n_iter 30 : loss (0.169922) + tot_loss (0.373059) + tot_loss_crop (0.285880) + loss_clip_order (0.208524) = final_loss = 1.037385
[Pretraining Epoch 024] Total-Loss 0.37 =  F-Loss 0.37 + Clip-Loss 0.21 (train)
n_iter  0 : loss (0.162321) + tot_loss (0.358485) + tot_loss_crop (0.282967) + loss_clip_order (0.219715) = final_loss = 1.023489
n_iter  1 : loss (0.157786) + tot_loss (0.368834) + tot_loss_crop (0.282820) + loss_clip_order (0.213720) = final_loss = 1.023161
n_iter  2 : loss (0.160444) + tot_loss (0.356495) + tot_loss_crop (0.276272) + loss_clip_order (0.211964) = final_loss = 1.005175
n_iter  3 : loss (0.166745) + tot_loss (0.343259) + tot_loss_crop (0.273249) + loss_clip_order (0.207694) = final_loss = 0.990947
n_iter  4 : loss (0.156810) + tot_loss (0.340095) + tot_loss_crop (0.271790) + loss_clip_order (0.203472) = final_loss = 0.972166
n_iter  5 : loss (0.161308) + tot_loss (0.341013) + tot_loss_crop (0.269453) + loss_clip_order (0.216812) = final_loss = 0.988586
n_iter  6 : loss (0.165854) + tot_loss (0.330954) + tot_loss_crop (0.265093) + loss_clip_order (0.212341) = final_loss = 0.974242
n_iter  7 : loss (0.165928) + tot_loss (0.314439) + tot_loss_crop (0.258216) + loss_clip_order (0.215619) = final_loss = 0.954202
n_iter  8 : loss (0.161718) + tot_loss (0.318680) + tot_loss_crop (0.258824) + loss_clip_order (0.204994) = final_loss = 0.944216
n_iter  9 : loss (0.164256) + tot_loss (0.310366) + tot_loss_crop (0.254193) + loss_clip_order (0.206652) = final_loss = 0.935466
n_iter 10 : loss (0.170005) + tot_loss (0.315005) + tot_loss_crop (0.254202) + loss_clip_order (0.203371) = final_loss = 0.942583
n_iter 11 : loss (0.166232) + tot_loss (0.306451) + tot_loss_crop (0.249130) + loss_clip_order (0.202986) = final_loss = 0.924799
n_iter 12 : loss (0.159969) + tot_loss (0.306845) + tot_loss_crop (0.246939) + loss_clip_order (0.202304) = final_loss = 0.916056
n_iter 13 : loss (0.155275) + tot_loss (0.305596) + tot_loss_crop (0.246333) + loss_clip_order (0.200916) = final_loss = 0.908119
n_iter 14 : loss (0.164672) + tot_loss (0.301664) + tot_loss_crop (0.242665) + loss_clip_order (0.201238) = final_loss = 0.910238
n_iter 15 : loss (0.155731) + tot_loss (0.293919) + tot_loss_crop (0.241125) + loss_clip_order (0.207988) = final_loss = 0.898763
n_iter 16 : loss (0.160275) + tot_loss (0.291206) + tot_loss_crop (0.238221) + loss_clip_order (0.208286) = final_loss = 0.897988
n_iter 17 : loss (0.160750) + tot_loss (0.284496) + tot_loss_crop (0.235098) + loss_clip_order (0.219760) = final_loss = 0.900104
n_iter 18 : loss (0.152904) + tot_loss (0.283438) + tot_loss_crop (0.232484) + loss_clip_order (0.202312) = final_loss = 0.871138
n_iter 19 : loss (0.161810) + tot_loss (0.264468) + tot_loss_crop (0.226367) + loss_clip_order (0.212623) = final_loss = 0.865268
n_iter 20 : loss (0.167175) + tot_loss (0.271975) + tot_loss_crop (0.228725) + loss_clip_order (0.198986) = final_loss = 0.866860
n_iter 21 : loss (0.158693) + tot_loss (0.285101) + tot_loss_crop (0.226778) + loss_clip_order (0.205059) = final_loss = 0.875629
n_iter 22 : loss (0.163120) + tot_loss (0.262660) + tot_loss_crop (0.222396) + loss_clip_order (0.201390) = final_loss = 0.849566
n_iter 23 : loss (0.165489) + tot_loss (0.266511) + tot_loss_crop (0.222012) + loss_clip_order (0.196119) = final_loss = 0.850132
n_iter 24 : loss (0.158801) + tot_loss (0.248726) + tot_loss_crop (0.217405) + loss_clip_order (0.198728) = final_loss = 0.823660
n_iter 25 : loss (0.166961) + tot_loss (0.252769) + tot_loss_crop (0.218298) + loss_clip_order (0.202672) = final_loss = 0.840701
n_iter 26 : loss (0.156202) + tot_loss (0.251971) + tot_loss_crop (0.214242) + loss_clip_order (0.193924) = final_loss = 0.816338
n_iter 27 : loss (0.164581) + tot_loss (0.252141) + tot_loss_crop (0.215091) + loss_clip_order (0.198048) = final_loss = 0.829862
n_iter 28 : loss (0.164621) + tot_loss (0.233675) + tot_loss_crop (0.210288) + loss_clip_order (0.196811) = final_loss = 0.805396
n_iter 29 : loss (0.163476) + tot_loss (0.244414) + tot_loss_crop (0.211747) + loss_clip_order (0.197870) = final_loss = 0.817507
n_iter 30 : loss (0.158856) + tot_loss (0.243282) + tot_loss_crop (0.206390) + loss_clip_order (0.196017) = final_loss = 0.804546
[Pretraining Epoch 025] Total-Loss 0.24 =  F-Loss 0.24 + Clip-Loss 0.20 (train)
n_iter  0 : loss (0.163903) + tot_loss (0.232135) + tot_loss_crop (0.205542) + loss_clip_order (0.197067) = final_loss = 0.798647
n_iter  1 : loss (0.159415) + tot_loss (0.244458) + tot_loss_crop (0.204442) + loss_clip_order (0.199772) = final_loss = 0.808088
n_iter  2 : loss (0.171847) + tot_loss (0.235051) + tot_loss_crop (0.204158) + loss_clip_order (0.191067) = final_loss = 0.802124
n_iter  3 : loss (0.164448) + tot_loss (0.224531) + tot_loss_crop (0.201102) + loss_clip_order (0.201113) = final_loss = 0.791195
n_iter  4 : loss (0.163776) + tot_loss (0.222642) + tot_loss_crop (0.198289) + loss_clip_order (0.199869) = final_loss = 0.784577
n_iter  5 : loss (0.157025) + tot_loss (0.227006) + tot_loss_crop (0.197938) + loss_clip_order (0.228097) = final_loss = 0.810067
n_iter  6 : loss (0.155314) + tot_loss (0.219404) + tot_loss_crop (0.194041) + loss_clip_order (0.208720) = final_loss = 0.777479
n_iter  7 : loss (0.157144) + tot_loss (0.204813) + tot_loss_crop (0.193367) + loss_clip_order (0.190643) = final_loss = 0.745967
n_iter  8 : loss (0.158330) + tot_loss (0.213044) + tot_loss_crop (0.191809) + loss_clip_order (0.205930) = final_loss = 0.769113
n_iter  9 : loss (0.165271) + tot_loss (0.207894) + tot_loss_crop (0.190527) + loss_clip_order (0.193322) = final_loss = 0.757014
n_iter 10 : loss (0.161117) + tot_loss (0.214908) + tot_loss_crop (0.191122) + loss_clip_order (0.192517) = final_loss = 0.759664
n_iter 11 : loss (0.166002) + tot_loss (0.207111) + tot_loss_crop (0.188963) + loss_clip_order (0.191715) = final_loss = 0.753790
n_iter 12 : loss (0.165343) + tot_loss (0.213001) + tot_loss_crop (0.188807) + loss_clip_order (0.191984) = final_loss = 0.759134
n_iter 13 : loss (0.163418) + tot_loss (0.212660) + tot_loss_crop (0.189569) + loss_clip_order (0.193232) = final_loss = 0.758879
n_iter 14 : loss (0.160618) + tot_loss (0.211568) + tot_loss_crop (0.186509) + loss_clip_order (0.194114) = final_loss = 0.752809
n_iter 15 : loss (0.173867) + tot_loss (0.206966) + tot_loss_crop (0.188725) + loss_clip_order (0.194247) = final_loss = 0.763805
n_iter 16 : loss (0.164867) + tot_loss (0.207143) + tot_loss_crop (0.186135) + loss_clip_order (0.189431) = final_loss = 0.747576
n_iter 17 : loss (0.164533) + tot_loss (0.203145) + tot_loss_crop (0.183319) + loss_clip_order (0.216892) = final_loss = 0.767890
n_iter 18 : loss (0.165731) + tot_loss (0.203757) + tot_loss_crop (0.183510) + loss_clip_order (0.198216) = final_loss = 0.751214
n_iter 19 : loss (0.155854) + tot_loss (0.189305) + tot_loss_crop (0.178688) + loss_clip_order (0.194209) = final_loss = 0.718056
n_iter 20 : loss (0.156976) + tot_loss (0.199577) + tot_loss_crop (0.179365) + loss_clip_order (0.197342) = final_loss = 0.733260
n_iter 21 : loss (0.170092) + tot_loss (0.212576) + tot_loss_crop (0.182632) + loss_clip_order (0.187647) = final_loss = 0.752948
n_iter 22 : loss (0.172296) + tot_loss (0.194584) + tot_loss_crop (0.179484) + loss_clip_order (0.191200) = final_loss = 0.737564
n_iter 23 : loss (0.171846) + tot_loss (0.198258) + tot_loss_crop (0.180743) + loss_clip_order (0.191175) = final_loss = 0.742022
n_iter 24 : loss (0.164459) + tot_loss (0.185098) + tot_loss_crop (0.176393) + loss_clip_order (0.191894) = final_loss = 0.717844
n_iter 25 : loss (0.150815) + tot_loss (0.191175) + tot_loss_crop (0.173834) + loss_clip_order (0.189161) = final_loss = 0.704984
n_iter 26 : loss (0.168472) + tot_loss (0.192860) + tot_loss_crop (0.179895) + loss_clip_order (0.188675) = final_loss = 0.729903
n_iter 27 : loss (0.164446) + tot_loss (0.194723) + tot_loss_crop (0.177601) + loss_clip_order (0.192368) = final_loss = 0.729138
n_iter 28 : loss (0.165354) + tot_loss (0.179290) + tot_loss_crop (0.175007) + loss_clip_order (0.190231) = final_loss = 0.709883
n_iter 29 : loss (0.169273) + tot_loss (0.191878) + tot_loss_crop (0.175993) + loss_clip_order (0.200730) = final_loss = 0.737874
n_iter 30 : loss (0.162992) + tot_loss (0.192389) + tot_loss_crop (0.172766) + loss_clip_order (0.188949) = final_loss = 0.717096
[Pretraining Epoch 026] Total-Loss 0.19 =  F-Loss 0.19 + Clip-Loss 0.19 (train)
training epoch 24
use Semi !!!
[Iteration 000] Total-Loss 3.50 = T-Loss 2.80 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.57 = T-Loss 2.87 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.94 = T-Loss 3.24 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.67 = T-Loss 2.97 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 024] Total-Loss 3.67 = T-Loss 2.97 + B-Loss 0.70 (train)[0m
[Epoch 024] Total-Loss 3.28 = T-Loss 2.58 + B-Loss 0.69  (val)
training epoch 25
use Semi !!!
[Iteration 000] Total-Loss 2.36 = T-Loss 1.66 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.20 = T-Loss 1.51 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.03 = T-Loss 1.34 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.91 = T-Loss 1.22 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 025] Total-Loss 1.91 = T-Loss 1.22 + B-Loss 0.69 (train)[0m
[Epoch 025] Total-Loss 2.76 = T-Loss 2.09 + B-Loss 0.67  (val)
training epoch 26
use Semi !!!
[Iteration 000] Total-Loss 1.60 = T-Loss 0.93 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.66 = T-Loss 0.99 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.63 = T-Loss 0.96 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.58 = T-Loss 0.92 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 026] Total-Loss 1.58 = T-Loss 0.92 + B-Loss 0.66 (train)[0m
[Epoch 026] Total-Loss 2.66 = T-Loss 2.00 + B-Loss 0.66  (val)
27
n_iter  0 : loss (0.218447) + tot_loss (0.277077) + tot_loss_crop (0.244698) + loss_clip_order (0.653365) = final_loss = 1.393587
n_iter  1 : loss (0.218597) + tot_loss (0.286646) + tot_loss_crop (0.240928) + loss_clip_order (0.211052) = final_loss = 0.957224
n_iter  2 : loss (0.211605) + tot_loss (0.298511) + tot_loss_crop (0.245416) + loss_clip_order (0.187928) = final_loss = 0.943460
n_iter  3 : loss (0.204258) + tot_loss (0.313824) + tot_loss_crop (0.254927) + loss_clip_order (0.205858) = final_loss = 0.978867
n_iter  4 : loss (0.185387) + tot_loss (0.330929) + tot_loss_crop (0.263629) + loss_clip_order (0.205277) = final_loss = 0.985221
n_iter  5 : loss (0.170660) + tot_loss (0.348531) + tot_loss_crop (0.270696) + loss_clip_order (0.206112) = final_loss = 0.995999
n_iter  6 : loss (0.164047) + tot_loss (0.351696) + tot_loss_crop (0.271897) + loss_clip_order (0.216651) = final_loss = 1.004291
n_iter  7 : loss (0.163688) + tot_loss (0.344673) + tot_loss_crop (0.272326) + loss_clip_order (0.219395) = final_loss = 1.000083
n_iter  8 : loss (0.157960) + tot_loss (0.357821) + tot_loss_crop (0.275069) + loss_clip_order (0.218360) = final_loss = 1.009210
n_iter  9 : loss (0.169666) + tot_loss (0.355916) + tot_loss_crop (0.274606) + loss_clip_order (0.239947) = final_loss = 1.040135
n_iter 10 : loss (0.182329) + tot_loss (0.365723) + tot_loss_crop (0.275657) + loss_clip_order (0.234240) = final_loss = 1.057949
n_iter 11 : loss (0.160309) + tot_loss (0.361153) + tot_loss_crop (0.274089) + loss_clip_order (0.229833) = final_loss = 1.025385
n_iter 12 : loss (0.170970) + tot_loss (0.366709) + tot_loss_crop (0.273473) + loss_clip_order (0.231474) = final_loss = 1.042626
n_iter 13 : loss (0.163760) + tot_loss (0.367871) + tot_loss_crop (0.274667) + loss_clip_order (0.231204) = final_loss = 1.037503
n_iter 14 : loss (0.174552) + tot_loss (0.366383) + tot_loss_crop (0.271770) + loss_clip_order (0.231053) = final_loss = 1.043757
n_iter 15 : loss (0.158006) + tot_loss (0.361962) + tot_loss_crop (0.271363) + loss_clip_order (0.227460) = final_loss = 1.018791
n_iter 16 : loss (0.163825) + tot_loss (0.361752) + tot_loss_crop (0.270121) + loss_clip_order (0.219710) = final_loss = 1.015407
n_iter 17 : loss (0.160171) + tot_loss (0.356020) + tot_loss_crop (0.268923) + loss_clip_order (0.219555) = final_loss = 1.004669
n_iter 18 : loss (0.168407) + tot_loss (0.356052) + tot_loss_crop (0.266318) + loss_clip_order (0.217037) = final_loss = 1.007814
n_iter 19 : loss (0.160028) + tot_loss (0.339178) + tot_loss_crop (0.262328) + loss_clip_order (0.220841) = final_loss = 0.982375
n_iter 20 : loss (0.163423) + tot_loss (0.346817) + tot_loss_crop (0.262657) + loss_clip_order (0.216492) = final_loss = 0.989388
n_iter 21 : loss (0.158067) + tot_loss (0.361024) + tot_loss_crop (0.264174) + loss_clip_order (0.214834) = final_loss = 0.998099
n_iter 22 : loss (0.172716) + tot_loss (0.339704) + tot_loss_crop (0.257357) + loss_clip_order (0.212184) = final_loss = 0.981961
n_iter 23 : loss (0.171846) + tot_loss (0.343719) + tot_loss_crop (0.257752) + loss_clip_order (0.205510) = final_loss = 0.978827
n_iter 24 : loss (0.159496) + tot_loss (0.326963) + tot_loss_crop (0.253416) + loss_clip_order (0.207616) = final_loss = 0.947491
n_iter 25 : loss (0.158508) + tot_loss (0.332015) + tot_loss_crop (0.253652) + loss_clip_order (0.194643) = final_loss = 0.938817
n_iter 26 : loss (0.167587) + tot_loss (0.329931) + tot_loss_crop (0.252515) + loss_clip_order (0.186604) = final_loss = 0.936637
n_iter 27 : loss (0.153181) + tot_loss (0.331219) + tot_loss_crop (0.250758) + loss_clip_order (0.199574) = final_loss = 0.934732
n_iter 28 : loss (0.162792) + tot_loss (0.314479) + tot_loss_crop (0.245088) + loss_clip_order (0.206961) = final_loss = 0.929319
n_iter 29 : loss (0.163976) + tot_loss (0.324142) + tot_loss_crop (0.247950) + loss_clip_order (0.203775) = final_loss = 0.939843
n_iter 30 : loss (0.150493) + tot_loss (0.322010) + tot_loss_crop (0.244548) + loss_clip_order (0.203270) = final_loss = 0.920320
[Pretraining Epoch 027] Total-Loss 0.32 =  F-Loss 0.32 + Clip-Loss 0.20 (train)
n_iter  0 : loss (0.162265) + tot_loss (0.310224) + tot_loss_crop (0.241443) + loss_clip_order (0.208640) = final_loss = 0.922572
n_iter  1 : loss (0.165752) + tot_loss (0.322801) + tot_loss_crop (0.241720) + loss_clip_order (0.207495) = final_loss = 0.937769
n_iter  2 : loss (0.162522) + tot_loss (0.312183) + tot_loss_crop (0.238568) + loss_clip_order (0.197057) = final_loss = 0.910330
n_iter  3 : loss (0.163767) + tot_loss (0.302100) + tot_loss_crop (0.235461) + loss_clip_order (0.196913) = final_loss = 0.898241
n_iter  4 : loss (0.170119) + tot_loss (0.299599) + tot_loss_crop (0.234383) + loss_clip_order (0.189337) = final_loss = 0.893438
n_iter  5 : loss (0.161363) + tot_loss (0.302733) + tot_loss_crop (0.234328) + loss_clip_order (0.189085) = final_loss = 0.887508
n_iter  6 : loss (0.153599) + tot_loss (0.294106) + tot_loss_crop (0.229996) + loss_clip_order (0.190171) = final_loss = 0.867872
n_iter  7 : loss (0.165161) + tot_loss (0.279325) + tot_loss_crop (0.226915) + loss_clip_order (0.191791) = final_loss = 0.863192
n_iter  8 : loss (0.169019) + tot_loss (0.285906) + tot_loss_crop (0.226523) + loss_clip_order (0.198410) = final_loss = 0.879857
n_iter  9 : loss (0.171554) + tot_loss (0.279407) + tot_loss_crop (0.223300) + loss_clip_order (0.196592) = final_loss = 0.870854
n_iter 10 : loss (0.162786) + tot_loss (0.285147) + tot_loss_crop (0.223869) + loss_clip_order (0.192359) = final_loss = 0.864160
n_iter 11 : loss (0.153528) + tot_loss (0.278475) + tot_loss_crop (0.218879) + loss_clip_order (0.189904) = final_loss = 0.840786
n_iter 12 : loss (0.164664) + tot_loss (0.281136) + tot_loss_crop (0.217979) + loss_clip_order (0.189559) = final_loss = 0.853337
n_iter 13 : loss (0.168324) + tot_loss (0.280190) + tot_loss_crop (0.219708) + loss_clip_order (0.188455) = final_loss = 0.856677
n_iter 14 : loss (0.158714) + tot_loss (0.278598) + tot_loss_crop (0.216734) + loss_clip_order (0.187864) = final_loss = 0.841910
n_iter 15 : loss (0.170111) + tot_loss (0.272181) + tot_loss_crop (0.217541) + loss_clip_order (0.184113) = final_loss = 0.843946
n_iter 16 : loss (0.172057) + tot_loss (0.271441) + tot_loss_crop (0.215312) + loss_clip_order (0.180815) = final_loss = 0.839624
n_iter 17 : loss (0.164393) + tot_loss (0.265879) + tot_loss_crop (0.213279) + loss_clip_order (0.196678) = final_loss = 0.840228
n_iter 18 : loss (0.158366) + tot_loss (0.264943) + tot_loss_crop (0.209601) + loss_clip_order (0.185082) = final_loss = 0.817991
n_iter 19 : loss (0.161916) + tot_loss (0.248409) + tot_loss_crop (0.204474) + loss_clip_order (0.192015) = final_loss = 0.806815
n_iter 20 : loss (0.158745) + tot_loss (0.256734) + tot_loss_crop (0.205614) + loss_clip_order (0.179344) = final_loss = 0.800438
n_iter 21 : loss (0.152308) + tot_loss (0.270602) + tot_loss_crop (0.206974) + loss_clip_order (0.182571) = final_loss = 0.812455
n_iter 22 : loss (0.154510) + tot_loss (0.250421) + tot_loss_crop (0.201180) + loss_clip_order (0.186278) = final_loss = 0.792390
n_iter 23 : loss (0.157492) + tot_loss (0.253964) + tot_loss_crop (0.203828) + loss_clip_order (0.185447) = final_loss = 0.800731
n_iter 24 : loss (0.150523) + tot_loss (0.238854) + tot_loss_crop (0.198405) + loss_clip_order (0.182028) = final_loss = 0.769809
n_iter 25 : loss (0.157041) + tot_loss (0.243917) + tot_loss_crop (0.199348) + loss_clip_order (0.187739) = final_loss = 0.788044
n_iter 26 : loss (0.161344) + tot_loss (0.243230) + tot_loss_crop (0.200396) + loss_clip_order (0.179308) = final_loss = 0.784278
n_iter 27 : loss (0.159052) + tot_loss (0.244553) + tot_loss_crop (0.197563) + loss_clip_order (0.184732) = final_loss = 0.785899
n_iter 28 : loss (0.152250) + tot_loss (0.228656) + tot_loss_crop (0.193377) + loss_clip_order (0.181172) = final_loss = 0.755454
n_iter 29 : loss (0.158699) + tot_loss (0.239233) + tot_loss_crop (0.194409) + loss_clip_order (0.180811) = final_loss = 0.773152
n_iter 30 : loss (0.159707) + tot_loss (0.238504) + tot_loss_crop (0.191554) + loss_clip_order (0.186246) = final_loss = 0.776011
[Pretraining Epoch 028] Total-Loss 0.24 =  F-Loss 0.24 + Clip-Loss 0.19 (train)
n_iter  0 : loss (0.158352) + tot_loss (0.227251) + tot_loss_crop (0.189769) + loss_clip_order (0.179562) = final_loss = 0.754935
n_iter  1 : loss (0.156988) + tot_loss (0.240617) + tot_loss_crop (0.192765) + loss_clip_order (0.182117) = final_loss = 0.772487
n_iter  2 : loss (0.155778) + tot_loss (0.231851) + tot_loss_crop (0.187858) + loss_clip_order (0.180191) = final_loss = 0.755679
n_iter  3 : loss (0.162420) + tot_loss (0.222619) + tot_loss_crop (0.187159) + loss_clip_order (0.179804) = final_loss = 0.752003
n_iter  4 : loss (0.163680) + tot_loss (0.220779) + tot_loss_crop (0.185468) + loss_clip_order (0.184462) = final_loss = 0.754389
n_iter  5 : loss (0.165674) + tot_loss (0.225364) + tot_loss_crop (0.186492) + loss_clip_order (0.192000) = final_loss = 0.769530
n_iter  6 : loss (0.153617) + tot_loss (0.218598) + tot_loss_crop (0.183636) + loss_clip_order (0.183337) = final_loss = 0.739188
n_iter  7 : loss (0.155428) + tot_loss (0.204330) + tot_loss_crop (0.180038) + loss_clip_order (0.181290) = final_loss = 0.721086
n_iter  8 : loss (0.156668) + tot_loss (0.211906) + tot_loss_crop (0.179591) + loss_clip_order (0.182036) = final_loss = 0.730201
n_iter  9 : loss (0.157436) + tot_loss (0.206476) + tot_loss_crop (0.175964) + loss_clip_order (0.182894) = final_loss = 0.722770
n_iter 10 : loss (0.162909) + tot_loss (0.214076) + tot_loss_crop (0.178911) + loss_clip_order (0.175521) = final_loss = 0.731417
n_iter 11 : loss (0.178719) + tot_loss (0.206748) + tot_loss_crop (0.177675) + loss_clip_order (0.175523) = final_loss = 0.738665
n_iter 12 : loss (0.167753) + tot_loss (0.212256) + tot_loss_crop (0.176547) + loss_clip_order (0.183097) = final_loss = 0.739653
n_iter 13 : loss (0.169144) + tot_loss (0.212196) + tot_loss_crop (0.177092) + loss_clip_order (0.178986) = final_loss = 0.737419
n_iter 14 : loss (0.160692) + tot_loss (0.210821) + tot_loss_crop (0.173478) + loss_clip_order (0.180340) = final_loss = 0.725331
n_iter 15 : loss (0.162983) + tot_loss (0.206376) + tot_loss_crop (0.173362) + loss_clip_order (0.180980) = final_loss = 0.723701
n_iter 16 : loss (0.162100) + tot_loss (0.206243) + tot_loss_crop (0.172565) + loss_clip_order (0.177697) = final_loss = 0.718605
n_iter 17 : loss (0.158987) + tot_loss (0.202060) + tot_loss_crop (0.171934) + loss_clip_order (0.199853) = final_loss = 0.732835
n_iter 18 : loss (0.154440) + tot_loss (0.202079) + tot_loss_crop (0.170667) + loss_clip_order (0.178164) = final_loss = 0.705351
n_iter 19 : loss (0.163548) + tot_loss (0.187943) + tot_loss_crop (0.165815) + loss_clip_order (0.177409) = final_loss = 0.694715
n_iter 20 : loss (0.164772) + tot_loss (0.196835) + tot_loss_crop (0.168034) + loss_clip_order (0.176474) = final_loss = 0.706114
n_iter 21 : loss (0.172300) + tot_loss (0.210679) + tot_loss_crop (0.171077) + loss_clip_order (0.173462) = final_loss = 0.727518
n_iter 22 : loss (0.162358) + tot_loss (0.192494) + tot_loss_crop (0.163551) + loss_clip_order (0.184636) = final_loss = 0.703038
n_iter 23 : loss (0.155361) + tot_loss (0.195909) + tot_loss_crop (0.164666) + loss_clip_order (0.172344) = final_loss = 0.688278
n_iter 24 : loss (0.172227) + tot_loss (0.182136) + tot_loss_crop (0.162291) + loss_clip_order (0.186968) = final_loss = 0.703622
n_iter 25 : loss (0.162804) + tot_loss (0.189187) + tot_loss_crop (0.165350) + loss_clip_order (0.171012) = final_loss = 0.688353
n_iter 26 : loss (0.168003) + tot_loss (0.189476) + tot_loss_crop (0.165550) + loss_clip_order (0.175657) = final_loss = 0.698685
n_iter 27 : loss (0.152804) + tot_loss (0.191907) + tot_loss_crop (0.161240) + loss_clip_order (0.179260) = final_loss = 0.685211
n_iter 28 : loss (0.160567) + tot_loss (0.176180) + tot_loss_crop (0.161530) + loss_clip_order (0.172203) = final_loss = 0.670480
n_iter 29 : loss (0.163932) + tot_loss (0.188050) + tot_loss_crop (0.162238) + loss_clip_order (0.178221) = final_loss = 0.692440
n_iter 30 : loss (0.161265) + tot_loss (0.187753) + tot_loss_crop (0.158879) + loss_clip_order (0.177387) = final_loss = 0.685284
[Pretraining Epoch 029] Total-Loss 0.19 =  F-Loss 0.19 + Clip-Loss 0.18 (train)
training epoch 27
use Semi !!!
[Iteration 000] Total-Loss 3.19 = T-Loss 2.50 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.78 = T-Loss 3.08 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.87 = T-Loss 3.17 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.47 = T-Loss 2.77 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 027] Total-Loss 3.47 = T-Loss 2.77 + B-Loss 0.70 (train)[0m
[Epoch 027] Total-Loss 3.28 = T-Loss 2.60 + B-Loss 0.69  (val)
training epoch 28
use Semi !!!
[Iteration 000] Total-Loss 2.45 = T-Loss 1.74 + B-Loss 0.71 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 2.23 = T-Loss 1.54 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 2.10 = T-Loss 1.41 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.96 = T-Loss 1.28 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 028] Total-Loss 1.96 = T-Loss 1.28 + B-Loss 0.68 (train)[0m
[Epoch 028] Total-Loss 2.75 = T-Loss 2.08 + B-Loss 0.67  (val)
training epoch 29
use Semi !!!
[Iteration 000] Total-Loss 1.69 = T-Loss 1.01 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.74 = T-Loss 1.08 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.71 = T-Loss 1.05 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.68 = T-Loss 1.01 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 029] Total-Loss 1.68 = T-Loss 1.01 + B-Loss 0.66 (train)[0m
[Epoch 029] Total-Loss 2.75 = T-Loss 2.07 + B-Loss 0.68  (val)
training epoch 30
use Semi !!!
[Iteration 000] Total-Loss 1.78 = T-Loss 1.10 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.74 = T-Loss 1.08 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.70 = T-Loss 1.03 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.65 = T-Loss 0.99 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 030] Total-Loss 1.65 = T-Loss 0.99 + B-Loss 0.66 (train)[0m
[Epoch 030] Total-Loss 2.66 = T-Loss 1.99 + B-Loss 0.68  (val)
training epoch 31
use Semi !!!
[Iteration 000] Total-Loss 1.62 = T-Loss 0.94 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.65 = T-Loss 0.99 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.62 = T-Loss 0.96 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.59 = T-Loss 0.92 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 031] Total-Loss 1.59 = T-Loss 0.92 + B-Loss 0.67 (train)[0m
[Epoch 031] Total-Loss 2.64 = T-Loss 1.96 + B-Loss 0.68  (val)
training epoch 32
use Semi !!!
[Iteration 000] Total-Loss 1.66 = T-Loss 0.98 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.64 = T-Loss 0.97 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.60 = T-Loss 0.93 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.55 = T-Loss 0.88 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 032] Total-Loss 1.55 = T-Loss 0.88 + B-Loss 0.67 (train)[0m
[Epoch 032] Total-Loss 2.55 = T-Loss 1.88 + B-Loss 0.66  (val)
training epoch 33
use Semi !!!
[Iteration 000] Total-Loss 1.46 = T-Loss 0.78 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.53 = T-Loss 0.87 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.52 = T-Loss 0.85 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.48 = T-Loss 0.81 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 033] Total-Loss 1.48 = T-Loss 0.81 + B-Loss 0.66 (train)[0m
[Epoch 033] Total-Loss 2.59 = T-Loss 1.92 + B-Loss 0.67  (val)
training epoch 34
use Semi !!!
[Iteration 000] Total-Loss 1.41 = T-Loss 0.74 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.47 = T-Loss 0.81 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.45 = T-Loss 0.79 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.42 = T-Loss 0.76 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 034] Total-Loss 1.42 = T-Loss 0.76 + B-Loss 0.66 (train)[0m
[Epoch 034] Total-Loss 2.60 = T-Loss 1.93 + B-Loss 0.67  (val)
training epoch 35
use Semi !!!
[Iteration 000] Total-Loss 1.42 = T-Loss 0.74 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.44 = T-Loss 0.78 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.42 = T-Loss 0.76 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.40 = T-Loss 0.73 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 035] Total-Loss 1.40 = T-Loss 0.73 + B-Loss 0.66 (train)[0m
[Epoch 035] Total-Loss 2.66 = T-Loss 2.00 + B-Loss 0.66  (val)
training epoch 36
use Semi !!!
[Iteration 000] Total-Loss 1.40 = T-Loss 0.73 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.40 = T-Loss 0.74 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.39 = T-Loss 0.73 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.37 = T-Loss 0.71 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 036] Total-Loss 1.37 = T-Loss 0.71 + B-Loss 0.66 (train)[0m
[Epoch 036] Total-Loss 2.58 = T-Loss 1.92 + B-Loss 0.66  (val)
training epoch 37
use Semi !!!
[Iteration 000] Total-Loss 1.35 = T-Loss 0.67 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.37 = T-Loss 0.71 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.36 = T-Loss 0.69 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.34 = T-Loss 0.67 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 037] Total-Loss 1.34 = T-Loss 0.67 + B-Loss 0.66 (train)[0m
[Epoch 037] Total-Loss 2.57 = T-Loss 1.91 + B-Loss 0.66  (val)
training epoch 38
use Semi !!!
[Iteration 000] Total-Loss 1.32 = T-Loss 0.65 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.34 = T-Loss 0.68 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.33 = T-Loss 0.67 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.31 = T-Loss 0.65 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 038] Total-Loss 1.31 = T-Loss 0.65 + B-Loss 0.66 (train)[0m
[Epoch 038] Total-Loss 2.57 = T-Loss 1.90 + B-Loss 0.66  (val)
training epoch 39
use Semi !!!
[Iteration 000] Total-Loss 1.30 = T-Loss 0.63 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.33 = T-Loss 0.66 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.31 = T-Loss 0.65 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.29 = T-Loss 0.63 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 039] Total-Loss 1.29 = T-Loss 0.63 + B-Loss 0.66 (train)[0m
[Epoch 039] Total-Loss 2.56 = T-Loss 1.89 + B-Loss 0.66  (val)
training epoch 40
use Semi !!!
[Iteration 000] Total-Loss 1.28 = T-Loss 0.61 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.31 = T-Loss 0.64 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.29 = T-Loss 0.63 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.28 = T-Loss 0.61 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 040] Total-Loss 1.28 = T-Loss 0.61 + B-Loss 0.66 (train)[0m
[Epoch 040] Total-Loss 2.54 = T-Loss 1.87 + B-Loss 0.66  (val)
training epoch 41
use Semi !!!
[Iteration 000] Total-Loss 1.26 = T-Loss 0.59 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 1.29 = T-Loss 0.63 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 1.28 = T-Loss 0.62 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 1.26 = T-Loss 0.60 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 041] Total-Loss 1.26 = T-Loss 0.60 + B-Loss 0.66 (train)[0m
[Epoch 041] Total-Loss 2.52 = T-Loss 1.85 + B-Loss 0.67  (val)
Total Time taken for Running 40 epoch is :2134.496 secs

real	36m3.776s
user	51m30.268s
sys	15m24.135s
{'dataset': {'name': 'anet', 'num_classes': 200, 'training': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}, 'testing': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}}, 'model': {'embedding_head': 1, 'feat_dim': 400, 'temporal_scale': 100}, 'pretraining': {'warmup_epoch': 30, 'consecutive_warmup_epochs': 3, 'unlabeled_pretrain': False}, 'training': {'batch_size': 25, 'learning_rate': 0.0004, 'weight_decay': 0.005, 'alternate': True, 'max_epoch': 40, 'consecutive_train_epochs': 3, 'checkpoint_path': './output/', 'random_seed': 1, 'step': 10, 'gamma': 0.2, 'scheduler': False, 'feature_path': '/data/i5O/ActivityNet1.3/train/', 'num_gpu': 1, 'loss_balance': 0.9, 'loss_balance_full': 0.5, 'regular_eval': False}, 'loss': {'lambda_1': 0.5, 'lambda_2': 0.9}, 'testing': {'feature_path': '/data/i5O/ActivityNet1.3/test/', 'cls_thresh': 0.01, 'mask_thresh': [0, 0.2, 0.4, 0.6, 0.8], 'class_thresh': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'top_k_snip': 10, 'top_k': 500, 'nms_thresh': 0.6}}
Loading validation Video Information ...
  0% 0/4728 [00:00<?, ?it/s] 19% 921/4728 [00:00<00:00, 9206.80it/s] 39% 1842/4728 [00:00<00:00, 8525.71it/s] 57% 2698/4728 [00:00<00:00, 7990.57it/s] 74% 3501/4728 [00:00<00:00, 7442.11it/s] 90% 4250/4728 [00:00<00:00, 5782.01it/s]100% 4728/4728 [00:00<00:00, 6607.46it/s]len(test_loader), 3852
Inference start

Inference finished
Start Post-Processing
End Post-Processing

real	5m9.563s
user	10m2.549s
sys	1m33.616s
Detection: average-mAP 26.924 mAP@0.50 44.836 mAP@0.55 40.959 mAP@0.60 37.654 mAP@0.65 34.102 mAP@0.70 30.348 mAP@0.75 26.538 mAP@0.80 21.901 mAP@0.85 16.736 mAP@0.90 11.185 mAP@0.95 4.976

real	1m18.505s
user	14m23.573s
sys	0m51.999s
