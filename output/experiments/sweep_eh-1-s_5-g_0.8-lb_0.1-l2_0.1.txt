./spot_train_eval.sh 0 sweep_eh-1-s_5-g_0.8-lb_0.1-l2_0.1.txt ./configs/anet.yaml model.embedding_head=1 training.step=5 training.gamma=0.8 training.loss_balance=0.1 loss.lambda_2=0.1 dataset.training.output_path=./output/ dataset.testing.output_path=./output/ training.checkpoint_path=./output/
{'dataset': {'name': 'anet', 'num_classes': 200, 'training': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}, 'testing': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}}, 'model': {'embedding_head': 1, 'feat_dim': 400, 'temporal_scale': 100}, 'pretraining': {'warmup_epoch': 30, 'consecutive_warmup_epochs': 3, 'unlabeled_pretrain': False}, 'training': {'batch_size': 25, 'learning_rate': 0.0004, 'weight_decay': 0.005, 'alternate': True, 'max_epoch': 40, 'consecutive_train_epochs': 3, 'checkpoint_path': './output/', 'random_seed': 1, 'step': 5, 'gamma': 0.8, 'scheduler': False, 'feature_path': '/data/i5O/ActivityNet1.3/train/', 'num_gpu': 1, 'loss_balance': 0.1, 'loss_balance_full': 0.5, 'regular_eval': False}, 'loss': {'lambda_1': 0.5, 'lambda_2': 0.1}, 'testing': {'feature_path': '/data/i5O/ActivityNet1.3/test/', 'cls_thresh': 0.01, 'mask_thresh': [0, 0.2, 0.4, 0.6, 0.8], 'class_thresh': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'top_k_snip': 10, 'top_k': 500, 'nms_thresh': 0.6}}

Total Number of Learnable Paramters (in M) :  2.83706
No of Gpus using to Train :  1 
 Saving all Checkpoints in path : ./output/
train_loader
Loading train Video Information ...
  0% 0/9649 [00:00<?, ?it/s]  7% 669/9649 [00:00<00:01, 6675.76it/s] 14% 1337/9649 [00:00<00:01, 6104.84it/s] 20% 1951/9649 [00:00<00:01, 5819.79it/s] 26% 2536/9649 [00:00<00:01, 5667.50it/s] 32% 3104/9649 [00:00<00:01, 5456.48it/s] 38% 3654/9649 [00:00<00:01, 5467.81it/s] 44% 4215/9649 [00:00<00:00, 5511.13it/s] 49% 4769/9649 [00:00<00:00, 5517.88it/s] 55% 5322/9649 [00:00<00:00, 5425.17it/s] 62% 5943/9649 [00:01<00:00, 5658.07it/s] 68% 6538/9649 [00:01<00:00, 5744.31it/s] 74% 7152/9649 [00:01<00:00, 5862.60it/s] 80% 7751/9649 [00:01<00:00, 5899.48it/s] 86% 8343/9649 [00:01<00:00, 5904.99it/s] 93% 8934/9649 [00:01<00:00, 5822.38it/s] 99% 9517/9649 [00:01<00:00, 5555.86it/s]100% 9649/9649 [00:01<00:00, 5667.33it/s]
train_loader_pretrain
Loading train Video Information ...
  0% 0/9649 [00:00<?, ?it/s] 30% 2855/9649 [00:00<00:00, 28538.66it/s] 60% 5772/9649 [00:00<00:00, 28905.90it/s] 90% 8663/9649 [00:00<00:00, 28866.87it/s]100% 9649/9649 [00:00<00:00, 28807.78it/s]
train_loader_unlabel
Loading unlabel Video Information ...
  0% 0/8683 [00:00<?, ?it/s]  7% 566/8683 [00:00<00:01, 5642.54it/s] 13% 1131/8683 [00:00<00:01, 5435.59it/s] 19% 1676/8683 [00:00<00:01, 5287.68it/s] 25% 2206/8683 [00:00<00:01, 5174.73it/s] 31% 2724/8683 [00:00<00:01, 5009.26it/s] 37% 3226/8683 [00:00<00:01, 4887.46it/s] 43% 3716/8683 [00:00<00:01, 4798.20it/s] 48% 4197/8683 [00:00<00:00, 4677.21it/s] 54% 4666/8683 [00:00<00:00, 4524.86it/s] 59% 5120/8683 [00:01<00:00, 4436.98it/s] 64% 5565/8683 [00:01<00:00, 4297.18it/s] 69% 5996/8683 [00:01<00:00, 4176.60it/s] 74% 6415/8683 [00:01<00:00, 4078.32it/s] 79% 6824/8683 [00:01<00:00, 4006.11it/s] 83% 7225/8683 [00:01<00:00, 3783.11it/s] 88% 7605/8683 [00:01<00:00, 3472.95it/s] 92% 7966/8683 [00:01<00:00, 3506.68it/s] 96% 8321/8683 [00:01<00:00, 3517.82it/s]100% 8676/8683 [00:02<00:00, 3476.54it/s]100% 8683/8683 [00:02<00:00, 4195.80it/s]
training: len(train_loader_unlabel) 295
test_loader
Loading validation Video Information ...
  0% 0/4728 [00:00<?, ?it/s] 11% 503/4728 [00:00<00:00, 5026.18it/s] 21% 1006/4728 [00:00<00:00, 4995.60it/s] 32% 1506/4728 [00:00<00:00, 4834.50it/s] 42% 1991/4728 [00:00<00:00, 4757.07it/s] 52% 2468/4728 [00:00<00:00, 4647.99it/s] 62% 2934/4728 [00:00<00:00, 4542.89it/s] 72% 3389/4728 [00:00<00:00, 4416.58it/s] 81% 3832/4728 [00:00<00:00, 4238.25it/s] 90% 4257/4728 [00:00<00:00, 4059.43it/s] 99% 4665/4728 [00:01<00:00, 3915.22it/s]100% 4728/4728 [00:01<00:00, 4307.77it/s]training: len(train_loader) 31
training: len(train_loader_pretrain) 31
training: len(test_loader) 154
0

n_iter  0 : loss (0.251516) + tot_loss (0.944717) + tot_loss_crop (0.907943) + loss_clip_order (0.692506) = final_loss = 2.796683
n_iter  1 : loss (0.240168) + tot_loss (0.944975) + tot_loss_crop (0.894988) + loss_clip_order (0.697859) = final_loss = 2.777990
n_iter  2 : loss (0.230398) + tot_loss (0.923077) + tot_loss_crop (0.883829) + loss_clip_order (0.697347) = final_loss = 2.734650
n_iter  3 : loss (0.223330) + tot_loss (0.909091) + tot_loss_crop (0.876070) + loss_clip_order (0.694492) = final_loss = 2.702983
n_iter  4 : loss (0.219778) + tot_loss (0.899420) + tot_loss_crop (0.868574) + loss_clip_order (0.693866) = final_loss = 2.681638
n_iter  5 : loss (0.212646) + tot_loss (0.898166) + tot_loss_crop (0.870378) + loss_clip_order (0.695119) = final_loss = 2.676308
n_iter  6 : loss (0.209596) + tot_loss (0.891535) + tot_loss_crop (0.868376) + loss_clip_order (0.692412) = final_loss = 2.661918
n_iter  7 : loss (0.208262) + tot_loss (0.868612) + tot_loss_crop (0.863038) + loss_clip_order (0.694322) = final_loss = 2.634233
n_iter  8 : loss (0.206440) + tot_loss (0.879261) + tot_loss_crop (0.856473) + loss_clip_order (0.694538) = final_loss = 2.636712
n_iter  9 : loss (0.196381) + tot_loss (0.866972) + tot_loss_crop (0.859547) + loss_clip_order (0.694542) = final_loss = 2.617442
n_iter 10 : loss (0.192351) + tot_loss (0.877073) + tot_loss_crop (0.858059) + loss_clip_order (0.694921) = final_loss = 2.622404
n_iter 11 : loss (0.189773) + tot_loss (0.862690) + tot_loss_crop (0.854542) + loss_clip_order (0.692727) = final_loss = 2.599732
n_iter 12 : loss (0.188804) + tot_loss (0.870511) + tot_loss_crop (0.848608) + loss_clip_order (0.695791) = final_loss = 2.603714
n_iter 13 : loss (0.184304) + tot_loss (0.870803) + tot_loss_crop (0.852125) + loss_clip_order (0.696274) = final_loss = 2.603507
n_iter 14 : loss (0.171993) + tot_loss (0.870010) + tot_loss_crop (0.853542) + loss_clip_order (0.693737) = final_loss = 2.589282
n_iter 15 : loss (0.179033) + tot_loss (0.869000) + tot_loss_crop (0.847489) + loss_clip_order (0.695010) = final_loss = 2.590533
n_iter 16 : loss (0.173335) + tot_loss (0.863445) + tot_loss_crop (0.847296) + loss_clip_order (0.694174) = final_loss = 2.578251
n_iter 17 : loss (0.172316) + tot_loss (0.860186) + tot_loss_crop (0.848950) + loss_clip_order (0.695503) = final_loss = 2.576956
n_iter 18 : loss (0.170411) + tot_loss (0.858792) + tot_loss_crop (0.846344) + loss_clip_order (0.693901) = final_loss = 2.569448
n_iter 19 : loss (0.170526) + tot_loss (0.841938) + tot_loss_crop (0.844401) + loss_clip_order (0.694619) = final_loss = 2.551485
n_iter 20 : loss (0.164702) + tot_loss (0.851020) + tot_loss_crop (0.846768) + loss_clip_order (0.696514) = final_loss = 2.559004
n_iter 21 : loss (0.159851) + tot_loss (0.869221) + tot_loss_crop (0.849921) + loss_clip_order (0.695967) = final_loss = 2.574960
n_iter 22 : loss (0.170408) + tot_loss (0.846959) + tot_loss_crop (0.838298) + loss_clip_order (0.693754) = final_loss = 2.549420
n_iter 23 : loss (0.170778) + tot_loss (0.847686) + tot_loss_crop (0.843512) + loss_clip_order (0.695705) = final_loss = 2.557681
n_iter 24 : loss (0.168300) + tot_loss (0.835293) + tot_loss_crop (0.840233) + loss_clip_order (0.695996) = final_loss = 2.539823
n_iter 25 : loss (0.172329) + tot_loss (0.837278) + tot_loss_crop (0.834277) + loss_clip_order (0.696769) = final_loss = 2.540653
n_iter 26 : loss (0.162847) + tot_loss (0.844527) + tot_loss_crop (0.842844) + loss_clip_order (0.696898) = final_loss = 2.547114
n_iter 27 : loss (0.158413) + tot_loss (0.847834) + tot_loss_crop (0.843221) + loss_clip_order (0.692486) = final_loss = 2.541955
n_iter 28 : loss (0.163233) + tot_loss (0.820823) + tot_loss_crop (0.838498) + loss_clip_order (0.694937) = final_loss = 2.517491
n_iter 29 : loss (0.165894) + tot_loss (0.846967) + tot_loss_crop (0.836629) + loss_clip_order (0.693413) = final_loss = 2.542903
n_iter 30 : loss (0.162540) + tot_loss (0.842678) + tot_loss_crop (0.837021) + loss_clip_order (0.693626) = final_loss = 2.535865
[Pretraining Epoch 000] Total-Loss 0.84 =  F-Loss 0.84 + Clip-Loss 0.69 (train)
/root/models/venv_SPOT/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
n_iter  0 : loss (0.168233) + tot_loss (0.832463) + tot_loss_crop (0.834745) + loss_clip_order (0.692781) = final_loss = 2.528222
n_iter  1 : loss (0.171901) + tot_loss (0.852256) + tot_loss_crop (0.830803) + loss_clip_order (0.693870) = final_loss = 2.548831
n_iter  2 : loss (0.166134) + tot_loss (0.838158) + tot_loss_crop (0.832995) + loss_clip_order (0.695471) = final_loss = 2.532757
n_iter  3 : loss (0.170385) + tot_loss (0.828762) + tot_loss_crop (0.827428) + loss_clip_order (0.693435) = final_loss = 2.520010
n_iter  4 : loss (0.171223) + tot_loss (0.821481) + tot_loss_crop (0.830208) + loss_clip_order (0.693916) = final_loss = 2.516828
n_iter  5 : loss (0.170344) + tot_loss (0.822699) + tot_loss_crop (0.826256) + loss_clip_order (0.695513) = final_loss = 2.514812
n_iter  6 : loss (0.162128) + tot_loss (0.821697) + tot_loss_crop (0.829868) + loss_clip_order (0.693072) = final_loss = 2.506766
n_iter  7 : loss (0.160316) + tot_loss (0.802545) + tot_loss_crop (0.829077) + loss_clip_order (0.694240) = final_loss = 2.486178
n_iter  8 : loss (0.164167) + tot_loss (0.815243) + tot_loss_crop (0.829827) + loss_clip_order (0.694065) = final_loss = 2.503302
n_iter  9 : loss (0.168311) + tot_loss (0.807345) + tot_loss_crop (0.826653) + loss_clip_order (0.692927) = final_loss = 2.495236
n_iter 10 : loss (0.165052) + tot_loss (0.820984) + tot_loss_crop (0.825874) + loss_clip_order (0.691779) = final_loss = 2.503689
n_iter 11 : loss (0.171735) + tot_loss (0.806640) + tot_loss_crop (0.819028) + loss_clip_order (0.693709) = final_loss = 2.491112
n_iter 12 : loss (0.160096) + tot_loss (0.816181) + tot_loss_crop (0.822909) + loss_clip_order (0.693322) = final_loss = 2.492508
n_iter 13 : loss (0.169279) + tot_loss (0.816177) + tot_loss_crop (0.818010) + loss_clip_order (0.690847) = final_loss = 2.494313
n_iter 14 : loss (0.173586) + tot_loss (0.815796) + tot_loss_crop (0.816315) + loss_clip_order (0.694292) = final_loss = 2.499989
n_iter 15 : loss (0.163622) + tot_loss (0.813893) + tot_loss_crop (0.819197) + loss_clip_order (0.692357) = final_loss = 2.489068
n_iter 16 : loss (0.171242) + tot_loss (0.808634) + tot_loss_crop (0.818208) + loss_clip_order (0.693921) = final_loss = 2.492005
n_iter 17 : loss (0.164149) + tot_loss (0.806038) + tot_loss_crop (0.821025) + loss_clip_order (0.693178) = final_loss = 2.484391
n_iter 18 : loss (0.168559) + tot_loss (0.806375) + tot_loss_crop (0.815636) + loss_clip_order (0.692593) = final_loss = 2.483164
n_iter 19 : loss (0.174219) + tot_loss (0.792734) + tot_loss_crop (0.807971) + loss_clip_order (0.692677) = final_loss = 2.467601
n_iter 20 : loss (0.167579) + tot_loss (0.801990) + tot_loss_crop (0.814770) + loss_clip_order (0.693329) = final_loss = 2.477668
n_iter 21 : loss (0.169767) + tot_loss (0.820769) + tot_loss_crop (0.809428) + loss_clip_order (0.692616) = final_loss = 2.492579
n_iter 22 : loss (0.162244) + tot_loss (0.800281) + tot_loss_crop (0.814246) + loss_clip_order (0.690781) = final_loss = 2.467552
n_iter 23 : loss (0.155854) + tot_loss (0.801139) + tot_loss_crop (0.817569) + loss_clip_order (0.694230) = final_loss = 2.468791
n_iter 24 : loss (0.163622) + tot_loss (0.790515) + tot_loss_crop (0.811080) + loss_clip_order (0.691008) = final_loss = 2.456224
n_iter 25 : loss (0.162601) + tot_loss (0.792784) + tot_loss_crop (0.809363) + loss_clip_order (0.692842) = final_loss = 2.457589
n_iter 26 : loss (0.161754) + tot_loss (0.800041) + tot_loss_crop (0.812283) + loss_clip_order (0.692986) = final_loss = 2.467064
n_iter 27 : loss (0.163210) + tot_loss (0.802775) + tot_loss_crop (0.806979) + loss_clip_order (0.691335) = final_loss = 2.464298
n_iter 28 : loss (0.165766) + tot_loss (0.777564) + tot_loss_crop (0.803299) + loss_clip_order (0.693064) = final_loss = 2.439693
n_iter 29 : loss (0.157056) + tot_loss (0.801951) + tot_loss_crop (0.810439) + loss_clip_order (0.693217) = final_loss = 2.462664
n_iter 30 : loss (0.164671) + tot_loss (0.797187) + tot_loss_crop (0.805092) + loss_clip_order (0.690688) = final_loss = 2.457639
[Pretraining Epoch 001] Total-Loss 0.80 =  F-Loss 0.80 + Clip-Loss 0.69 (train)
n_iter  0 : loss (0.168993) + tot_loss (0.787765) + tot_loss_crop (0.800054) + loss_clip_order (0.692226) = final_loss = 2.449037
n_iter  1 : loss (0.156278) + tot_loss (0.807357) + tot_loss_crop (0.807067) + loss_clip_order (0.693104) = final_loss = 2.463806
n_iter  2 : loss (0.159333) + tot_loss (0.794322) + tot_loss_crop (0.801841) + loss_clip_order (0.690330) = final_loss = 2.445826
n_iter  3 : loss (0.156664) + tot_loss (0.785839) + tot_loss_crop (0.804172) + loss_clip_order (0.692142) = final_loss = 2.438817
n_iter  4 : loss (0.165708) + tot_loss (0.779969) + tot_loss_crop (0.797988) + loss_clip_order (0.691759) = final_loss = 2.435424
n_iter  5 : loss (0.174950) + tot_loss (0.781475) + tot_loss_crop (0.789810) + loss_clip_order (0.692182) = final_loss = 2.438418
n_iter  6 : loss (0.161439) + tot_loss (0.780220) + tot_loss_crop (0.798080) + loss_clip_order (0.689677) = final_loss = 2.429416
n_iter  7 : loss (0.166582) + tot_loss (0.761855) + tot_loss_crop (0.793336) + loss_clip_order (0.690281) = final_loss = 2.412054
n_iter  8 : loss (0.167913) + tot_loss (0.772120) + tot_loss_crop (0.793571) + loss_clip_order (0.695367) = final_loss = 2.428971
n_iter  9 : loss (0.168611) + tot_loss (0.764596) + tot_loss_crop (0.792256) + loss_clip_order (0.687923) = final_loss = 2.413386
n_iter 10 : loss (0.168855) + tot_loss (0.777548) + tot_loss_crop (0.791023) + loss_clip_order (0.690429) = final_loss = 2.427855
n_iter 11 : loss (0.162950) + tot_loss (0.763452) + tot_loss_crop (0.790242) + loss_clip_order (0.688318) = final_loss = 2.404963
n_iter 12 : loss (0.168306) + tot_loss (0.774529) + tot_loss_crop (0.786120) + loss_clip_order (0.691289) = final_loss = 2.420243
n_iter 13 : loss (0.157820) + tot_loss (0.774464) + tot_loss_crop (0.793147) + loss_clip_order (0.685302) = final_loss = 2.410734
n_iter 14 : loss (0.162611) + tot_loss (0.775880) + tot_loss_crop (0.789333) + loss_clip_order (0.688044) = final_loss = 2.415869
n_iter 15 : loss (0.170150) + tot_loss (0.773431) + tot_loss_crop (0.781990) + loss_clip_order (0.683713) = final_loss = 2.409284
n_iter 16 : loss (0.164647) + tot_loss (0.768730) + tot_loss_crop (0.784328) + loss_clip_order (0.686970) = final_loss = 2.404675
n_iter 17 : loss (0.167059) + tot_loss (0.766455) + tot_loss_crop (0.784785) + loss_clip_order (0.686882) = final_loss = 2.405180
n_iter 18 : loss (0.167062) + tot_loss (0.765925) + tot_loss_crop (0.782824) + loss_clip_order (0.687688) = final_loss = 2.403499
n_iter 19 : loss (0.175141) + tot_loss (0.753517) + tot_loss_crop (0.773862) + loss_clip_order (0.688531) = final_loss = 2.391050
n_iter 20 : loss (0.165770) + tot_loss (0.761650) + tot_loss_crop (0.780015) + loss_clip_order (0.682196) = final_loss = 2.389631
n_iter 21 : loss (0.153543) + tot_loss (0.779794) + tot_loss_crop (0.786856) + loss_clip_order (0.678664) = final_loss = 2.398857
n_iter 22 : loss (0.173105) + tot_loss (0.760469) + tot_loss_crop (0.772958) + loss_clip_order (0.677096) = final_loss = 2.383628
n_iter 23 : loss (0.156426) + tot_loss (0.760931) + tot_loss_crop (0.782004) + loss_clip_order (0.680572) = final_loss = 2.379933
n_iter 24 : loss (0.164450) + tot_loss (0.751156) + tot_loss_crop (0.778320) + loss_clip_order (0.672634) = final_loss = 2.366560
n_iter 25 : loss (0.168917) + tot_loss (0.753083) + tot_loss_crop (0.770942) + loss_clip_order (0.672935) = final_loss = 2.365877
n_iter 26 : loss (0.164828) + tot_loss (0.759373) + tot_loss_crop (0.772253) + loss_clip_order (0.665414) = final_loss = 2.361869
n_iter 27 : loss (0.162392) + tot_loss (0.762641) + tot_loss_crop (0.777330) + loss_clip_order (0.665090) = final_loss = 2.367454
n_iter 28 : loss (0.173891) + tot_loss (0.739666) + tot_loss_crop (0.766931) + loss_clip_order (0.654738) = final_loss = 2.335226
n_iter 29 : loss (0.158278) + tot_loss (0.763365) + tot_loss_crop (0.776098) + loss_clip_order (0.643338) = final_loss = 2.341079
n_iter 30 : loss (0.155988) + tot_loss (0.758739) + tot_loss_crop (0.773080) + loss_clip_order (0.628380) = final_loss = 2.316187
[Pretraining Epoch 002] Total-Loss 0.76 =  F-Loss 0.76 + Clip-Loss 0.63 (train)
training epoch 0
use Semi !!!
[Iteration 000] Total-Loss 6.23 = T-Loss 5.50 + B-Loss 0.74 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 5.17 = T-Loss 4.47 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 5.09 = T-Loss 4.41 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 5.10 = T-Loss 4.42 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 000] Total-Loss 5.10 = T-Loss 4.42 + B-Loss 0.68 (train)[0m
[Epoch 000] Total-Loss 5.00 = T-Loss 4.35 + B-Loss 0.65  (val)
training epoch 1
use Semi !!!
[Iteration 000] Total-Loss 4.54 = T-Loss 3.84 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.70 = T-Loss 4.03 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.70 = T-Loss 4.03 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.73 = T-Loss 4.06 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 001] Total-Loss 4.73 = T-Loss 4.06 + B-Loss 0.67 (train)[0m
[Epoch 001] Total-Loss 4.73 = T-Loss 4.08 + B-Loss 0.65  (val)
training epoch 2
use Semi !!!
[Iteration 000] Total-Loss 4.10 = T-Loss 3.40 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.28 = T-Loss 3.61 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.16 = T-Loss 3.49 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.07 = T-Loss 3.41 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 002] Total-Loss 4.07 = T-Loss 3.41 + B-Loss 0.67 (train)[0m
[Epoch 002] Total-Loss 4.04 = T-Loss 3.40 + B-Loss 0.64  (val)
3
n_iter  0 : loss (0.241492) + tot_loss (0.710777) + tot_loss_crop (0.738852) + loss_clip_order (0.674342) = final_loss = 2.365463
n_iter  1 : loss (0.236695) + tot_loss (0.733049) + tot_loss_crop (0.740106) + loss_clip_order (0.644429) = final_loss = 2.354279
n_iter  2 : loss (0.229484) + tot_loss (0.726172) + tot_loss_crop (0.742867) + loss_clip_order (0.669010) = final_loss = 2.367532
n_iter  3 : loss (0.220302) + tot_loss (0.723460) + tot_loss_crop (0.744073) + loss_clip_order (0.678458) = final_loss = 2.366293
n_iter  4 : loss (0.207526) + tot_loss (0.722225) + tot_loss_crop (0.747396) + loss_clip_order (0.683714) = final_loss = 2.360861
n_iter  5 : loss (0.202126) + tot_loss (0.726601) + tot_loss_crop (0.745707) + loss_clip_order (0.680489) = final_loss = 2.354923
n_iter  6 : loss (0.187802) + tot_loss (0.724900) + tot_loss_crop (0.743053) + loss_clip_order (0.682373) = final_loss = 2.338128
n_iter  7 : loss (0.178307) + tot_loss (0.707571) + tot_loss_crop (0.738577) + loss_clip_order (0.666499) = final_loss = 2.290954
n_iter  8 : loss (0.177596) + tot_loss (0.715209) + tot_loss_crop (0.737485) + loss_clip_order (0.654903) = final_loss = 2.285194
n_iter  9 : loss (0.176588) + tot_loss (0.706851) + tot_loss_crop (0.735137) + loss_clip_order (0.587344) = final_loss = 2.205921
n_iter 10 : loss (0.180412) + tot_loss (0.717685) + tot_loss_crop (0.743316) + loss_clip_order (0.629970) = final_loss = 2.271383
n_iter 11 : loss (0.171949) + tot_loss (0.704143) + tot_loss_crop (0.730672) + loss_clip_order (0.571769) = final_loss = 2.178532
n_iter 12 : loss (0.157755) + tot_loss (0.720051) + tot_loss_crop (0.732124) + loss_clip_order (0.623349) = final_loss = 2.233279
n_iter 13 : loss (0.157896) + tot_loss (0.724029) + tot_loss_crop (0.735888) + loss_clip_order (0.627346) = final_loss = 2.245159
n_iter 14 : loss (0.177355) + tot_loss (0.728925) + tot_loss_crop (0.728467) + loss_clip_order (0.609044) = final_loss = 2.243791
n_iter 15 : loss (0.158452) + tot_loss (0.725320) + tot_loss_crop (0.729508) + loss_clip_order (0.568087) = final_loss = 2.181366
n_iter 16 : loss (0.162716) + tot_loss (0.721392) + tot_loss_crop (0.727620) + loss_clip_order (0.531885) = final_loss = 2.143614
n_iter 17 : loss (0.162922) + tot_loss (0.715676) + tot_loss_crop (0.727933) + loss_clip_order (0.483845) = final_loss = 2.090376
n_iter 18 : loss (0.166817) + tot_loss (0.710220) + tot_loss_crop (0.724284) + loss_clip_order (0.446517) = final_loss = 2.047838
n_iter 19 : loss (0.165129) + tot_loss (0.694225) + tot_loss_crop (0.724593) + loss_clip_order (0.440292) = final_loss = 2.024239
n_iter 20 : loss (0.183264) + tot_loss (0.698728) + tot_loss_crop (0.715759) + loss_clip_order (0.434195) = final_loss = 2.031947
n_iter 21 : loss (0.168773) + tot_loss (0.715280) + tot_loss_crop (0.729111) + loss_clip_order (0.438176) = final_loss = 2.051340
n_iter 22 : loss (0.186064) + tot_loss (0.695560) + tot_loss_crop (0.719710) + loss_clip_order (0.485245) = final_loss = 2.086579
n_iter 23 : loss (0.166880) + tot_loss (0.696250) + tot_loss_crop (0.723521) + loss_clip_order (0.445142) = final_loss = 2.031793
n_iter 24 : loss (0.169747) + tot_loss (0.688502) + tot_loss_crop (0.717717) + loss_clip_order (0.407634) = final_loss = 1.983600
n_iter 25 : loss (0.171206) + tot_loss (0.694095) + tot_loss_crop (0.711471) + loss_clip_order (0.416131) = final_loss = 1.992903
n_iter 26 : loss (0.163149) + tot_loss (0.701881) + tot_loss_crop (0.717456) + loss_clip_order (0.417424) = final_loss = 1.999910
n_iter 27 : loss (0.179557) + tot_loss (0.708567) + tot_loss_crop (0.709076) + loss_clip_order (0.382866) = final_loss = 1.980066
n_iter 28 : loss (0.158360) + tot_loss (0.689964) + tot_loss_crop (0.713447) + loss_clip_order (0.388352) = final_loss = 1.950123
n_iter 29 : loss (0.176494) + tot_loss (0.715225) + tot_loss_crop (0.711318) + loss_clip_order (0.388661) = final_loss = 1.991698
n_iter 30 : loss (0.170675) + tot_loss (0.712413) + tot_loss_crop (0.709171) + loss_clip_order (0.389520) = final_loss = 1.981779
[Pretraining Epoch 003] Total-Loss 0.71 =  F-Loss 0.71 + Clip-Loss 0.39 (train)
n_iter  0 : loss (0.162499) + tot_loss (0.704711) + tot_loss_crop (0.710723) + loss_clip_order (0.387941) = final_loss = 1.965874
n_iter  1 : loss (0.168271) + tot_loss (0.722024) + tot_loss_crop (0.712563) + loss_clip_order (0.387623) = final_loss = 1.990481
n_iter  2 : loss (0.161654) + tot_loss (0.708203) + tot_loss_crop (0.709557) + loss_clip_order (0.379991) = final_loss = 1.959405
n_iter  3 : loss (0.164840) + tot_loss (0.698227) + tot_loss_crop (0.709203) + loss_clip_order (0.371802) = final_loss = 1.944072
n_iter  4 : loss (0.155009) + tot_loss (0.692258) + tot_loss_crop (0.711450) + loss_clip_order (0.369605) = final_loss = 1.928322
n_iter  5 : loss (0.154449) + tot_loss (0.692205) + tot_loss_crop (0.713132) + loss_clip_order (0.368246) = final_loss = 1.928032
n_iter  6 : loss (0.154910) + tot_loss (0.687743) + tot_loss_crop (0.707787) + loss_clip_order (0.370921) = final_loss = 1.921360
n_iter  7 : loss (0.165290) + tot_loss (0.670704) + tot_loss_crop (0.703684) + loss_clip_order (0.350631) = final_loss = 1.890309
n_iter  8 : loss (0.164543) + tot_loss (0.678921) + tot_loss_crop (0.704173) + loss_clip_order (0.360812) = final_loss = 1.908450
n_iter  9 : loss (0.160913) + tot_loss (0.672469) + tot_loss_crop (0.706849) + loss_clip_order (0.357217) = final_loss = 1.897449
n_iter 10 : loss (0.168181) + tot_loss (0.683336) + tot_loss_crop (0.698052) + loss_clip_order (0.360183) = final_loss = 1.909752
n_iter 11 : loss (0.174526) + tot_loss (0.670098) + tot_loss_crop (0.694008) + loss_clip_order (0.357306) = final_loss = 1.895937
n_iter 12 : loss (0.169277) + tot_loss (0.680444) + tot_loss_crop (0.693470) + loss_clip_order (0.353485) = final_loss = 1.896676
n_iter 13 : loss (0.162335) + tot_loss (0.680034) + tot_loss_crop (0.696686) + loss_clip_order (0.346138) = final_loss = 1.885192
n_iter 14 : loss (0.149540) + tot_loss (0.682660) + tot_loss_crop (0.704099) + loss_clip_order (0.352771) = final_loss = 1.889070
n_iter 15 : loss (0.168699) + tot_loss (0.679791) + tot_loss_crop (0.695512) + loss_clip_order (0.355479) = final_loss = 1.899481
n_iter 16 : loss (0.171431) + tot_loss (0.677258) + tot_loss_crop (0.690452) + loss_clip_order (0.361425) = final_loss = 1.900566
n_iter 17 : loss (0.157746) + tot_loss (0.675390) + tot_loss_crop (0.695979) + loss_clip_order (0.356211) = final_loss = 1.885325
n_iter 18 : loss (0.162543) + tot_loss (0.674024) + tot_loss_crop (0.690603) + loss_clip_order (0.351452) = final_loss = 1.878622
n_iter 19 : loss (0.168081) + tot_loss (0.662365) + tot_loss_crop (0.685513) + loss_clip_order (0.366063) = final_loss = 1.882022
n_iter 20 : loss (0.167426) + tot_loss (0.668603) + tot_loss_crop (0.684502) + loss_clip_order (0.356700) = final_loss = 1.877232
n_iter 21 : loss (0.161168) + tot_loss (0.685819) + tot_loss_crop (0.689156) + loss_clip_order (0.343428) = final_loss = 1.879570
n_iter 22 : loss (0.169981) + tot_loss (0.666898) + tot_loss_crop (0.683177) + loss_clip_order (0.357379) = final_loss = 1.877435
n_iter 23 : loss (0.152368) + tot_loss (0.667759) + tot_loss_crop (0.693798) + loss_clip_order (0.340558) = final_loss = 1.854482
n_iter 24 : loss (0.151530) + tot_loss (0.658757) + tot_loss_crop (0.689366) + loss_clip_order (0.345936) = final_loss = 1.845590
n_iter 25 : loss (0.169866) + tot_loss (0.662299) + tot_loss_crop (0.680360) + loss_clip_order (0.344759) = final_loss = 1.857284
n_iter 26 : loss (0.160129) + tot_loss (0.667089) + tot_loss_crop (0.684334) + loss_clip_order (0.347326) = final_loss = 1.858879
n_iter 27 : loss (0.159591) + tot_loss (0.670788) + tot_loss_crop (0.683879) + loss_clip_order (0.356654) = final_loss = 1.870913
n_iter 28 : loss (0.164975) + tot_loss (0.650399) + tot_loss_crop (0.678979) + loss_clip_order (0.342038) = final_loss = 1.836391
n_iter 29 : loss (0.158543) + tot_loss (0.673109) + tot_loss_crop (0.684425) + loss_clip_order (0.348061) = final_loss = 1.864137
n_iter 30 : loss (0.160040) + tot_loss (0.668729) + tot_loss_crop (0.681640) + loss_clip_order (0.338985) = final_loss = 1.849393
[Pretraining Epoch 004] Total-Loss 0.67 =  F-Loss 0.67 + Clip-Loss 0.34 (train)
n_iter  0 : loss (0.165331) + tot_loss (0.661361) + tot_loss_crop (0.677849) + loss_clip_order (0.339993) = final_loss = 1.844535
n_iter  1 : loss (0.169023) + tot_loss (0.679468) + tot_loss_crop (0.677215) + loss_clip_order (0.334702) = final_loss = 1.860408
n_iter  2 : loss (0.164206) + tot_loss (0.667294) + tot_loss_crop (0.675732) + loss_clip_order (0.332554) = final_loss = 1.839785
n_iter  3 : loss (0.162920) + tot_loss (0.659394) + tot_loss_crop (0.676110) + loss_clip_order (0.333770) = final_loss = 1.832194
n_iter  4 : loss (0.171898) + tot_loss (0.654352) + tot_loss_crop (0.666917) + loss_clip_order (0.331978) = final_loss = 1.825145
n_iter  5 : loss (0.159983) + tot_loss (0.656657) + tot_loss_crop (0.674477) + loss_clip_order (0.326930) = final_loss = 1.818046
n_iter  6 : loss (0.157328) + tot_loss (0.655290) + tot_loss_crop (0.671376) + loss_clip_order (0.335663) = final_loss = 1.819657
n_iter  7 : loss (0.168425) + tot_loss (0.640551) + tot_loss_crop (0.671206) + loss_clip_order (0.335481) = final_loss = 1.815664
n_iter  8 : loss (0.159836) + tot_loss (0.649993) + tot_loss_crop (0.666997) + loss_clip_order (0.333876) = final_loss = 1.810702
n_iter  9 : loss (0.171897) + tot_loss (0.644907) + tot_loss_crop (0.665047) + loss_clip_order (0.333422) = final_loss = 1.815273
n_iter 10 : loss (0.166318) + tot_loss (0.655971) + tot_loss_crop (0.665157) + loss_clip_order (0.329766) = final_loss = 1.817212
n_iter 11 : loss (0.165093) + tot_loss (0.643201) + tot_loss_crop (0.664501) + loss_clip_order (0.333882) = final_loss = 1.806677
n_iter 12 : loss (0.153060) + tot_loss (0.653269) + tot_loss_crop (0.667363) + loss_clip_order (0.328209) = final_loss = 1.801901
n_iter 13 : loss (0.164024) + tot_loss (0.652841) + tot_loss_crop (0.660450) + loss_clip_order (0.326896) = final_loss = 1.804212
n_iter 14 : loss (0.166222) + tot_loss (0.655098) + tot_loss_crop (0.661645) + loss_clip_order (0.335394) = final_loss = 1.818360
n_iter 15 : loss (0.159819) + tot_loss (0.651881) + tot_loss_crop (0.664764) + loss_clip_order (0.336612) = final_loss = 1.813076
n_iter 16 : loss (0.159811) + tot_loss (0.649116) + tot_loss_crop (0.662618) + loss_clip_order (0.325390) = final_loss = 1.796935
n_iter 17 : loss (0.169830) + tot_loss (0.647564) + tot_loss_crop (0.657530) + loss_clip_order (0.328793) = final_loss = 1.803717
n_iter 18 : loss (0.153204) + tot_loss (0.646430) + tot_loss_crop (0.662978) + loss_clip_order (0.329559) = final_loss = 1.792171
n_iter 19 : loss (0.157557) + tot_loss (0.635031) + tot_loss_crop (0.661633) + loss_clip_order (0.332927) = final_loss = 1.787148
n_iter 20 : loss (0.156249) + tot_loss (0.641972) + tot_loss_crop (0.657249) + loss_clip_order (0.326574) = final_loss = 1.782044
n_iter 21 : loss (0.160894) + tot_loss (0.659575) + tot_loss_crop (0.655583) + loss_clip_order (0.329169) = final_loss = 1.805222
n_iter 22 : loss (0.163919) + tot_loss (0.640708) + tot_loss_crop (0.655352) + loss_clip_order (0.335022) = final_loss = 1.795002
n_iter 23 : loss (0.160421) + tot_loss (0.641931) + tot_loss_crop (0.656330) + loss_clip_order (0.325352) = final_loss = 1.784035
n_iter 24 : loss (0.162924) + tot_loss (0.632609) + tot_loss_crop (0.652595) + loss_clip_order (0.328109) = final_loss = 1.776237
n_iter 25 : loss (0.158769) + tot_loss (0.635548) + tot_loss_crop (0.654260) + loss_clip_order (0.321742) = final_loss = 1.770318
n_iter 26 : loss (0.163670) + tot_loss (0.639553) + tot_loss_crop (0.652137) + loss_clip_order (0.334650) = final_loss = 1.790010
n_iter 27 : loss (0.166838) + tot_loss (0.642800) + tot_loss_crop (0.648135) + loss_clip_order (0.336261) = final_loss = 1.794034
n_iter 28 : loss (0.163614) + tot_loss (0.622256) + tot_loss_crop (0.647309) + loss_clip_order (0.323314) = final_loss = 1.756494
n_iter 29 : loss (0.155416) + tot_loss (0.644165) + tot_loss_crop (0.652688) + loss_clip_order (0.329686) = final_loss = 1.781955
n_iter 30 : loss (0.155699) + tot_loss (0.639691) + tot_loss_crop (0.650033) + loss_clip_order (0.322121) = final_loss = 1.767543
[Pretraining Epoch 005] Total-Loss 0.64 =  F-Loss 0.64 + Clip-Loss 0.32 (train)
training epoch 3
use Semi !!!
[Iteration 000] Total-Loss 5.37 = T-Loss 4.65 + B-Loss 0.72 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.72 = T-Loss 4.04 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.67 = T-Loss 3.99 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.65 = T-Loss 3.97 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 003] Total-Loss 4.65 = T-Loss 3.97 + B-Loss 0.68 (train)[0m
[Epoch 003] Total-Loss 4.60 = T-Loss 3.95 + B-Loss 0.65  (val)
training epoch 4
use Semi !!!
[Iteration 000] Total-Loss 3.92 = T-Loss 3.22 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.92 = T-Loss 3.25 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.87 = T-Loss 3.21 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.82 = T-Loss 3.16 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 004] Total-Loss 3.82 = T-Loss 3.16 + B-Loss 0.66 (train)[0m
[Epoch 004] Total-Loss 3.95 = T-Loss 3.31 + B-Loss 0.64  (val)
training epoch 5
use Semi !!!
[Iteration 000] Total-Loss 3.03 = T-Loss 2.34 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.29 = T-Loss 2.63 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.28 = T-Loss 2.63 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.28 = T-Loss 2.62 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 005] Total-Loss 3.28 = T-Loss 2.62 + B-Loss 0.66 (train)[0m
[Epoch 005] Total-Loss 3.73 = T-Loss 3.09 + B-Loss 0.64  (val)
6
n_iter  0 : loss (0.222304) + tot_loss (0.603329) + tot_loss_crop (0.618771) + loss_clip_order (0.493130) = final_loss = 1.937534
n_iter  1 : loss (0.222013) + tot_loss (0.622180) + tot_loss_crop (0.623860) + loss_clip_order (0.471604) = final_loss = 1.939657
n_iter  2 : loss (0.219606) + tot_loss (0.610953) + tot_loss_crop (0.623526) + loss_clip_order (0.440177) = final_loss = 1.894261
n_iter  3 : loss (0.216111) + tot_loss (0.603581) + tot_loss_crop (0.622629) + loss_clip_order (0.472946) = final_loss = 1.915267
n_iter  4 : loss (0.204083) + tot_loss (0.598220) + tot_loss_crop (0.620379) + loss_clip_order (0.422179) = final_loss = 1.844860
n_iter  5 : loss (0.193663) + tot_loss (0.601401) + tot_loss_crop (0.620702) + loss_clip_order (0.426758) = final_loss = 1.842523
n_iter  6 : loss (0.189177) + tot_loss (0.601582) + tot_loss_crop (0.611009) + loss_clip_order (0.406910) = final_loss = 1.808678
n_iter  7 : loss (0.176474) + tot_loss (0.588510) + tot_loss_crop (0.618763) + loss_clip_order (0.378967) = final_loss = 1.762714
n_iter  8 : loss (0.168588) + tot_loss (0.598745) + tot_loss_crop (0.619041) + loss_clip_order (0.363502) = final_loss = 1.749876
n_iter  9 : loss (0.163432) + tot_loss (0.595516) + tot_loss_crop (0.617243) + loss_clip_order (0.357996) = final_loss = 1.734187
n_iter 10 : loss (0.170886) + tot_loss (0.608398) + tot_loss_crop (0.609273) + loss_clip_order (0.339728) = final_loss = 1.728285
n_iter 11 : loss (0.175570) + tot_loss (0.598950) + tot_loss_crop (0.606239) + loss_clip_order (0.325347) = final_loss = 1.706105
n_iter 12 : loss (0.161093) + tot_loss (0.611308) + tot_loss_crop (0.607983) + loss_clip_order (0.317594) = final_loss = 1.697978
n_iter 13 : loss (0.163794) + tot_loss (0.613146) + tot_loss_crop (0.611942) + loss_clip_order (0.312954) = final_loss = 1.701835
n_iter 14 : loss (0.164318) + tot_loss (0.616224) + tot_loss_crop (0.608941) + loss_clip_order (0.323588) = final_loss = 1.713070
n_iter 15 : loss (0.174578) + tot_loss (0.613849) + tot_loss_crop (0.604705) + loss_clip_order (0.326661) = final_loss = 1.719793
n_iter 16 : loss (0.177980) + tot_loss (0.612419) + tot_loss_crop (0.603702) + loss_clip_order (0.312604) = final_loss = 1.706705
n_iter 17 : loss (0.164200) + tot_loss (0.610678) + tot_loss_crop (0.605245) + loss_clip_order (0.333047) = final_loss = 1.713169
n_iter 18 : loss (0.164272) + tot_loss (0.609639) + tot_loss_crop (0.607009) + loss_clip_order (0.320952) = final_loss = 1.701871
n_iter 19 : loss (0.160318) + tot_loss (0.597305) + tot_loss_crop (0.604069) + loss_clip_order (0.322673) = final_loss = 1.684366
n_iter 20 : loss (0.168608) + tot_loss (0.604819) + tot_loss_crop (0.598953) + loss_clip_order (0.324378) = final_loss = 1.696758
n_iter 21 : loss (0.153815) + tot_loss (0.623794) + tot_loss_crop (0.605949) + loss_clip_order (0.321820) = final_loss = 1.705378
n_iter 22 : loss (0.163898) + tot_loss (0.603424) + tot_loss_crop (0.601225) + loss_clip_order (0.331779) = final_loss = 1.700326
n_iter 23 : loss (0.152716) + tot_loss (0.605905) + tot_loss_crop (0.605202) + loss_clip_order (0.313013) = final_loss = 1.676836
n_iter 24 : loss (0.165991) + tot_loss (0.594418) + tot_loss_crop (0.598469) + loss_clip_order (0.315970) = final_loss = 1.674848
n_iter 25 : loss (0.161741) + tot_loss (0.597905) + tot_loss_crop (0.599122) + loss_clip_order (0.313656) = final_loss = 1.672426
n_iter 26 : loss (0.161330) + tot_loss (0.599708) + tot_loss_crop (0.598461) + loss_clip_order (0.321999) = final_loss = 1.681497
n_iter 27 : loss (0.156272) + tot_loss (0.601210) + tot_loss_crop (0.600434) + loss_clip_order (0.310692) = final_loss = 1.668608
n_iter 28 : loss (0.162787) + tot_loss (0.579744) + tot_loss_crop (0.593128) + loss_clip_order (0.313292) = final_loss = 1.648951
n_iter 29 : loss (0.161551) + tot_loss (0.599161) + tot_loss_crop (0.595166) + loss_clip_order (0.313878) = final_loss = 1.669756
n_iter 30 : loss (0.159714) + tot_loss (0.593269) + tot_loss_crop (0.595365) + loss_clip_order (0.312943) = final_loss = 1.661291
[Pretraining Epoch 006] Total-Loss 0.59 =  F-Loss 0.59 + Clip-Loss 0.31 (train)
n_iter  0 : loss (0.166887) + tot_loss (0.584976) + tot_loss_crop (0.590325) + loss_clip_order (0.311772) = final_loss = 1.653960
n_iter  1 : loss (0.155027) + tot_loss (0.602261) + tot_loss_crop (0.593294) + loss_clip_order (0.321195) = final_loss = 1.671776
n_iter  2 : loss (0.163013) + tot_loss (0.590568) + tot_loss_crop (0.587704) + loss_clip_order (0.316663) = final_loss = 1.657948
n_iter  3 : loss (0.167517) + tot_loss (0.582765) + tot_loss_crop (0.586061) + loss_clip_order (0.311610) = final_loss = 1.647953
n_iter  4 : loss (0.154094) + tot_loss (0.577659) + tot_loss_crop (0.589186) + loss_clip_order (0.311305) = final_loss = 1.632244
n_iter  5 : loss (0.160809) + tot_loss (0.580639) + tot_loss_crop (0.587281) + loss_clip_order (0.307426) = final_loss = 1.636155
n_iter  6 : loss (0.159408) + tot_loss (0.578850) + tot_loss_crop (0.587842) + loss_clip_order (0.316749) = final_loss = 1.642849
n_iter  7 : loss (0.165538) + tot_loss (0.564719) + tot_loss_crop (0.580822) + loss_clip_order (0.313564) = final_loss = 1.624643
n_iter  8 : loss (0.174910) + tot_loss (0.573458) + tot_loss_crop (0.578628) + loss_clip_order (0.319822) = final_loss = 1.646817
n_iter  9 : loss (0.152718) + tot_loss (0.568520) + tot_loss_crop (0.584349) + loss_clip_order (0.320732) = final_loss = 1.626318
n_iter 10 : loss (0.164233) + tot_loss (0.578852) + tot_loss_crop (0.579340) + loss_clip_order (0.321957) = final_loss = 1.644382
n_iter 11 : loss (0.178778) + tot_loss (0.566843) + tot_loss_crop (0.572317) + loss_clip_order (0.317913) = final_loss = 1.635851
n_iter 12 : loss (0.168902) + tot_loss (0.576546) + tot_loss_crop (0.573386) + loss_clip_order (0.309484) = final_loss = 1.628319
n_iter 13 : loss (0.151992) + tot_loss (0.575335) + tot_loss_crop (0.582112) + loss_clip_order (0.305953) = final_loss = 1.615392
n_iter 14 : loss (0.158175) + tot_loss (0.577576) + tot_loss_crop (0.573936) + loss_clip_order (0.311758) = final_loss = 1.621445
n_iter 15 : loss (0.172075) + tot_loss (0.574000) + tot_loss_crop (0.571311) + loss_clip_order (0.312961) = final_loss = 1.630347
n_iter 16 : loss (0.159455) + tot_loss (0.571464) + tot_loss_crop (0.572569) + loss_clip_order (0.303104) = final_loss = 1.606592
n_iter 17 : loss (0.165120) + tot_loss (0.570093) + tot_loss_crop (0.571887) + loss_clip_order (0.319453) = final_loss = 1.626554
n_iter 18 : loss (0.152321) + tot_loss (0.569335) + tot_loss_crop (0.573991) + loss_clip_order (0.306618) = final_loss = 1.602266
n_iter 19 : loss (0.159917) + tot_loss (0.559058) + tot_loss_crop (0.568768) + loss_clip_order (0.305560) = final_loss = 1.593303
n_iter 20 : loss (0.170621) + tot_loss (0.566467) + tot_loss_crop (0.564119) + loss_clip_order (0.307837) = final_loss = 1.609044
n_iter 21 : loss (0.162173) + tot_loss (0.583974) + tot_loss_crop (0.566116) + loss_clip_order (0.304189) = final_loss = 1.616451
n_iter 22 : loss (0.165333) + tot_loss (0.565948) + tot_loss_crop (0.565200) + loss_clip_order (0.308317) = final_loss = 1.604797
n_iter 23 : loss (0.164931) + tot_loss (0.567512) + tot_loss_crop (0.562382) + loss_clip_order (0.300758) = final_loss = 1.595583
n_iter 24 : loss (0.165302) + tot_loss (0.558192) + tot_loss_crop (0.559735) + loss_clip_order (0.304807) = final_loss = 1.588037
n_iter 25 : loss (0.165023) + tot_loss (0.561717) + tot_loss_crop (0.561027) + loss_clip_order (0.295258) = final_loss = 1.583025
n_iter 26 : loss (0.163092) + tot_loss (0.564908) + tot_loss_crop (0.559127) + loss_clip_order (0.308270) = final_loss = 1.595397
n_iter 27 : loss (0.167122) + tot_loss (0.568008) + tot_loss_crop (0.556323) + loss_clip_order (0.303702) = final_loss = 1.595155
n_iter 28 : loss (0.172159) + tot_loss (0.548072) + tot_loss_crop (0.552623) + loss_clip_order (0.308762) = final_loss = 1.581617
n_iter 29 : loss (0.170556) + tot_loss (0.568314) + tot_loss_crop (0.555789) + loss_clip_order (0.308119) = final_loss = 1.602777
n_iter 30 : loss (0.160718) + tot_loss (0.563856) + tot_loss_crop (0.554472) + loss_clip_order (0.299336) = final_loss = 1.578382
[Pretraining Epoch 007] Total-Loss 0.56 =  F-Loss 0.56 + Clip-Loss 0.30 (train)
n_iter  0 : loss (0.160099) + tot_loss (0.556224) + tot_loss_crop (0.557239) + loss_clip_order (0.303932) = final_loss = 1.577495
n_iter  1 : loss (0.170672) + tot_loss (0.574099) + tot_loss_crop (0.553607) + loss_clip_order (0.304265) = final_loss = 1.602643
n_iter  2 : loss (0.170785) + tot_loss (0.562844) + tot_loss_crop (0.549605) + loss_clip_order (0.306607) = final_loss = 1.589841
n_iter  3 : loss (0.164464) + tot_loss (0.555123) + tot_loss_crop (0.549627) + loss_clip_order (0.299605) = final_loss = 1.568818
n_iter  4 : loss (0.156919) + tot_loss (0.550170) + tot_loss_crop (0.551590) + loss_clip_order (0.297132) = final_loss = 1.555810
n_iter  5 : loss (0.170304) + tot_loss (0.553501) + tot_loss_crop (0.545828) + loss_clip_order (0.300557) = final_loss = 1.570190
n_iter  6 : loss (0.167224) + tot_loss (0.551834) + tot_loss_crop (0.543952) + loss_clip_order (0.308677) = final_loss = 1.571687
n_iter  7 : loss (0.153557) + tot_loss (0.537924) + tot_loss_crop (0.546893) + loss_clip_order (0.300829) = final_loss = 1.539205
n_iter  8 : loss (0.167191) + tot_loss (0.546470) + tot_loss_crop (0.543862) + loss_clip_order (0.297380) = final_loss = 1.554903
n_iter  9 : loss (0.152093) + tot_loss (0.541532) + tot_loss_crop (0.548172) + loss_clip_order (0.298179) = final_loss = 1.539977
n_iter 10 : loss (0.168087) + tot_loss (0.551616) + tot_loss_crop (0.541702) + loss_clip_order (0.303864) = final_loss = 1.565269
n_iter 11 : loss (0.166503) + tot_loss (0.540198) + tot_loss_crop (0.536328) + loss_clip_order (0.301230) = final_loss = 1.544259
n_iter 12 : loss (0.169221) + tot_loss (0.550056) + tot_loss_crop (0.536160) + loss_clip_order (0.294582) = final_loss = 1.550019
n_iter 13 : loss (0.166992) + tot_loss (0.549186) + tot_loss_crop (0.536516) + loss_clip_order (0.291486) = final_loss = 1.544180
n_iter 14 : loss (0.162104) + tot_loss (0.551592) + tot_loss_crop (0.537222) + loss_clip_order (0.296506) = final_loss = 1.547424
n_iter 15 : loss (0.161118) + tot_loss (0.548150) + tot_loss_crop (0.535733) + loss_clip_order (0.296801) = final_loss = 1.541802
n_iter 16 : loss (0.168656) + tot_loss (0.545927) + tot_loss_crop (0.529596) + loss_clip_order (0.296391) = final_loss = 1.540570
n_iter 17 : loss (0.161246) + tot_loss (0.544400) + tot_loss_crop (0.531443) + loss_clip_order (0.295840) = final_loss = 1.532928
n_iter 18 : loss (0.167837) + tot_loss (0.543101) + tot_loss_crop (0.530236) + loss_clip_order (0.300285) = final_loss = 1.541458
n_iter 19 : loss (0.157072) + tot_loss (0.531987) + tot_loss_crop (0.527539) + loss_clip_order (0.296828) = final_loss = 1.513427
n_iter 20 : loss (0.182200) + tot_loss (0.538920) + tot_loss_crop (0.522536) + loss_clip_order (0.302079) = final_loss = 1.545735
n_iter 21 : loss (0.167094) + tot_loss (0.554861) + tot_loss_crop (0.527637) + loss_clip_order (0.295725) = final_loss = 1.545318
n_iter 22 : loss (0.168205) + tot_loss (0.536922) + tot_loss_crop (0.523133) + loss_clip_order (0.303315) = final_loss = 1.531574
n_iter 23 : loss (0.158976) + tot_loss (0.537778) + tot_loss_crop (0.524654) + loss_clip_order (0.294464) = final_loss = 1.515872
n_iter 24 : loss (0.158098) + tot_loss (0.529032) + tot_loss_crop (0.526261) + loss_clip_order (0.295346) = final_loss = 1.508738
n_iter 25 : loss (0.160835) + tot_loss (0.532398) + tot_loss_crop (0.521908) + loss_clip_order (0.289601) = final_loss = 1.504741
n_iter 26 : loss (0.154894) + tot_loss (0.535692) + tot_loss_crop (0.523770) + loss_clip_order (0.302823) = final_loss = 1.517179
n_iter 27 : loss (0.160774) + tot_loss (0.539311) + tot_loss_crop (0.519507) + loss_clip_order (0.295181) = final_loss = 1.514774
n_iter 28 : loss (0.169304) + tot_loss (0.520545) + tot_loss_crop (0.512232) + loss_clip_order (0.299796) = final_loss = 1.501878
n_iter 29 : loss (0.160222) + tot_loss (0.540085) + tot_loss_crop (0.518450) + loss_clip_order (0.304392) = final_loss = 1.523149
n_iter 30 : loss (0.172599) + tot_loss (0.536092) + tot_loss_crop (0.511175) + loss_clip_order (0.297779) = final_loss = 1.517645
[Pretraining Epoch 008] Total-Loss 0.54 =  F-Loss 0.54 + Clip-Loss 0.30 (train)
training epoch 6
use Semi !!!
[Iteration 000] Total-Loss 4.82 = T-Loss 4.10 + B-Loss 0.72 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.46 = T-Loss 3.78 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.30 = T-Loss 3.63 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.20 = T-Loss 3.53 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 006] Total-Loss 4.20 = T-Loss 3.53 + B-Loss 0.66 (train)[0m
[Epoch 006] Total-Loss 4.31 = T-Loss 3.67 + B-Loss 0.64  (val)
training epoch 7
use Semi !!!
[Iteration 000] Total-Loss 3.57 = T-Loss 2.88 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.67 = T-Loss 3.02 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.60 = T-Loss 2.94 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.59 = T-Loss 2.93 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 007] Total-Loss 3.59 = T-Loss 2.93 + B-Loss 0.66 (train)[0m
[Epoch 007] Total-Loss 4.01 = T-Loss 3.37 + B-Loss 0.64  (val)
training epoch 8
use Semi !!!
[Iteration 000] Total-Loss 3.12 = T-Loss 2.43 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.38 = T-Loss 2.72 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.32 = T-Loss 2.67 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.34 = T-Loss 2.68 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 008] Total-Loss 3.34 = T-Loss 2.68 + B-Loss 0.65 (train)[0m
[Epoch 008] Total-Loss 3.89 = T-Loss 3.25 + B-Loss 0.65  (val)
9
n_iter  0 : loss (0.201718) + tot_loss (0.507246) + tot_loss_crop (0.499400) + loss_clip_order (0.441340) = final_loss = 1.649704
n_iter  1 : loss (0.206033) + tot_loss (0.526139) + tot_loss_crop (0.498130) + loss_clip_order (0.456902) = final_loss = 1.687204
n_iter  2 : loss (0.201137) + tot_loss (0.515404) + tot_loss_crop (0.492876) + loss_clip_order (0.437904) = final_loss = 1.647322
n_iter  3 : loss (0.190802) + tot_loss (0.507403) + tot_loss_crop (0.493811) + loss_clip_order (0.429266) = final_loss = 1.621283
n_iter  4 : loss (0.188642) + tot_loss (0.502434) + tot_loss_crop (0.492110) + loss_clip_order (0.414546) = final_loss = 1.597732
n_iter  5 : loss (0.183525) + tot_loss (0.505752) + tot_loss_crop (0.492333) + loss_clip_order (0.399173) = final_loss = 1.580782
n_iter  6 : loss (0.179688) + tot_loss (0.505108) + tot_loss_crop (0.494202) + loss_clip_order (0.397210) = final_loss = 1.576208
n_iter  7 : loss (0.170252) + tot_loss (0.491872) + tot_loss_crop (0.493437) + loss_clip_order (0.348137) = final_loss = 1.503698
n_iter  8 : loss (0.169806) + tot_loss (0.500586) + tot_loss_crop (0.490342) + loss_clip_order (0.331659) = final_loss = 1.492392
n_iter  9 : loss (0.155464) + tot_loss (0.496630) + tot_loss_crop (0.494388) + loss_clip_order (0.301647) = final_loss = 1.448129
n_iter 10 : loss (0.158106) + tot_loss (0.507651) + tot_loss_crop (0.491151) + loss_clip_order (0.293752) = final_loss = 1.450660
n_iter 11 : loss (0.171227) + tot_loss (0.497918) + tot_loss_crop (0.486200) + loss_clip_order (0.286840) = final_loss = 1.442185
n_iter 12 : loss (0.165305) + tot_loss (0.508449) + tot_loss_crop (0.486481) + loss_clip_order (0.292309) = final_loss = 1.452545
n_iter 13 : loss (0.164018) + tot_loss (0.509048) + tot_loss_crop (0.488631) + loss_clip_order (0.286702) = final_loss = 1.448399
n_iter 14 : loss (0.161504) + tot_loss (0.512043) + tot_loss_crop (0.487704) + loss_clip_order (0.311804) = final_loss = 1.473054
n_iter 15 : loss (0.168009) + tot_loss (0.509442) + tot_loss_crop (0.486791) + loss_clip_order (0.302506) = final_loss = 1.466748
n_iter 16 : loss (0.161451) + tot_loss (0.509255) + tot_loss_crop (0.485383) + loss_clip_order (0.285704) = final_loss = 1.441794
n_iter 17 : loss (0.161331) + tot_loss (0.508302) + tot_loss_crop (0.485454) + loss_clip_order (0.311073) = final_loss = 1.466159
n_iter 18 : loss (0.159757) + tot_loss (0.508411) + tot_loss_crop (0.483480) + loss_clip_order (0.293101) = final_loss = 1.444750
n_iter 19 : loss (0.167681) + tot_loss (0.497386) + tot_loss_crop (0.479214) + loss_clip_order (0.283526) = final_loss = 1.427808
n_iter 20 : loss (0.154539) + tot_loss (0.506373) + tot_loss_crop (0.480943) + loss_clip_order (0.298166) = final_loss = 1.440021
n_iter 21 : loss (0.159139) + tot_loss (0.524106) + tot_loss_crop (0.482357) + loss_clip_order (0.292206) = final_loss = 1.457808
n_iter 22 : loss (0.170057) + tot_loss (0.504844) + tot_loss_crop (0.476915) + loss_clip_order (0.289933) = final_loss = 1.441748
n_iter 23 : loss (0.171178) + tot_loss (0.507770) + tot_loss_crop (0.475613) + loss_clip_order (0.287294) = final_loss = 1.441856
n_iter 24 : loss (0.165593) + tot_loss (0.496239) + tot_loss_crop (0.472992) + loss_clip_order (0.285620) = final_loss = 1.420445
n_iter 25 : loss (0.156150) + tot_loss (0.499778) + tot_loss_crop (0.473478) + loss_clip_order (0.286031) = final_loss = 1.415436
n_iter 26 : loss (0.157154) + tot_loss (0.500880) + tot_loss_crop (0.472638) + loss_clip_order (0.293150) = final_loss = 1.423821
n_iter 27 : loss (0.167547) + tot_loss (0.502198) + tot_loss_crop (0.468801) + loss_clip_order (0.293139) = final_loss = 1.431684
n_iter 28 : loss (0.172791) + tot_loss (0.482295) + tot_loss_crop (0.464243) + loss_clip_order (0.287332) = final_loss = 1.406661
n_iter 29 : loss (0.158375) + tot_loss (0.499016) + tot_loss_crop (0.470239) + loss_clip_order (0.287384) = final_loss = 1.415014
n_iter 30 : loss (0.156055) + tot_loss (0.494238) + tot_loss_crop (0.467360) + loss_clip_order (0.284400) = final_loss = 1.402053
[Pretraining Epoch 009] Total-Loss 0.49 =  F-Loss 0.49 + Clip-Loss 0.28 (train)
n_iter  0 : loss (0.160176) + tot_loss (0.485524) + tot_loss_crop (0.467710) + loss_clip_order (0.282539) = final_loss = 1.395948
n_iter  1 : loss (0.160562) + tot_loss (0.501948) + tot_loss_crop (0.468357) + loss_clip_order (0.290968) = final_loss = 1.421836
n_iter  2 : loss (0.155725) + tot_loss (0.491049) + tot_loss_crop (0.464507) + loss_clip_order (0.285258) = final_loss = 1.396540
n_iter  3 : loss (0.164478) + tot_loss (0.483273) + tot_loss_crop (0.461549) + loss_clip_order (0.285229) = final_loss = 1.394529
n_iter  4 : loss (0.168140) + tot_loss (0.478469) + tot_loss_crop (0.457828) + loss_clip_order (0.281977) = final_loss = 1.386414
n_iter  5 : loss (0.155186) + tot_loss (0.482210) + tot_loss_crop (0.460717) + loss_clip_order (0.279477) = final_loss = 1.377591
n_iter  6 : loss (0.161506) + tot_loss (0.479309) + tot_loss_crop (0.456924) + loss_clip_order (0.289249) = final_loss = 1.386988
n_iter  7 : loss (0.167188) + tot_loss (0.465635) + tot_loss_crop (0.452113) + loss_clip_order (0.296035) = final_loss = 1.380971
n_iter  8 : loss (0.167863) + tot_loss (0.473469) + tot_loss_crop (0.452294) + loss_clip_order (0.288404) = final_loss = 1.382030
n_iter  9 : loss (0.155155) + tot_loss (0.468319) + tot_loss_crop (0.452191) + loss_clip_order (0.291478) = final_loss = 1.367143
n_iter 10 : loss (0.171951) + tot_loss (0.477286) + tot_loss_crop (0.452231) + loss_clip_order (0.293384) = final_loss = 1.394852
n_iter 11 : loss (0.158471) + tot_loss (0.466455) + tot_loss_crop (0.448050) + loss_clip_order (0.285573) = final_loss = 1.358550
n_iter 12 : loss (0.162129) + tot_loss (0.475321) + tot_loss_crop (0.448609) + loss_clip_order (0.283171) = final_loss = 1.369229
n_iter 13 : loss (0.165329) + tot_loss (0.473646) + tot_loss_crop (0.448304) + loss_clip_order (0.281683) = final_loss = 1.368962
n_iter 14 : loss (0.150298) + tot_loss (0.475845) + tot_loss_crop (0.450159) + loss_clip_order (0.285245) = final_loss = 1.361547
n_iter 15 : loss (0.152213) + tot_loss (0.472082) + tot_loss_crop (0.450882) + loss_clip_order (0.278054) = final_loss = 1.353231
n_iter 16 : loss (0.155626) + tot_loss (0.470277) + tot_loss_crop (0.446840) + loss_clip_order (0.280963) = final_loss = 1.353705
n_iter 17 : loss (0.162659) + tot_loss (0.468482) + tot_loss_crop (0.443486) + loss_clip_order (0.286909) = final_loss = 1.361536
n_iter 18 : loss (0.156237) + tot_loss (0.467759) + tot_loss_crop (0.444052) + loss_clip_order (0.286108) = final_loss = 1.354157
n_iter 19 : loss (0.155190) + tot_loss (0.456811) + tot_loss_crop (0.440456) + loss_clip_order (0.286581) = final_loss = 1.339038
n_iter 20 : loss (0.154148) + tot_loss (0.464231) + tot_loss_crop (0.439300) + loss_clip_order (0.283852) = final_loss = 1.341531
n_iter 21 : loss (0.166227) + tot_loss (0.478746) + tot_loss_crop (0.438834) + loss_clip_order (0.283189) = final_loss = 1.366997
n_iter 22 : loss (0.162484) + tot_loss (0.461538) + tot_loss_crop (0.437258) + loss_clip_order (0.290908) = final_loss = 1.352187
n_iter 23 : loss (0.170187) + tot_loss (0.462172) + tot_loss_crop (0.434601) + loss_clip_order (0.281551) = final_loss = 1.348511
n_iter 24 : loss (0.178265) + tot_loss (0.453251) + tot_loss_crop (0.430174) + loss_clip_order (0.288079) = final_loss = 1.349770
n_iter 25 : loss (0.164053) + tot_loss (0.456870) + tot_loss_crop (0.433522) + loss_clip_order (0.279316) = final_loss = 1.333761
n_iter 26 : loss (0.155667) + tot_loss (0.459437) + tot_loss_crop (0.437141) + loss_clip_order (0.295236) = final_loss = 1.347482
n_iter 27 : loss (0.159948) + tot_loss (0.462831) + tot_loss_crop (0.431710) + loss_clip_order (0.277467) = final_loss = 1.331957
n_iter 28 : loss (0.153152) + tot_loss (0.445073) + tot_loss_crop (0.432111) + loss_clip_order (0.272051) = final_loss = 1.302387
n_iter 29 : loss (0.165036) + tot_loss (0.462599) + tot_loss_crop (0.432328) + loss_clip_order (0.285633) = final_loss = 1.345597
n_iter 30 : loss (0.152459) + tot_loss (0.459524) + tot_loss_crop (0.430015) + loss_clip_order (0.277324) = final_loss = 1.319320
[Pretraining Epoch 010] Total-Loss 0.46 =  F-Loss 0.46 + Clip-Loss 0.28 (train)
n_iter  0 : loss (0.163331) + tot_loss (0.451838) + tot_loss_crop (0.426938) + loss_clip_order (0.277191) = final_loss = 1.319299
n_iter  1 : loss (0.173429) + tot_loss (0.468694) + tot_loss_crop (0.427664) + loss_clip_order (0.286438) = final_loss = 1.356226
n_iter  2 : loss (0.159380) + tot_loss (0.457948) + tot_loss_crop (0.426084) + loss_clip_order (0.277061) = final_loss = 1.320473
n_iter  3 : loss (0.162341) + tot_loss (0.450543) + tot_loss_crop (0.423507) + loss_clip_order (0.279338) = final_loss = 1.315729
n_iter  4 : loss (0.160054) + tot_loss (0.445813) + tot_loss_crop (0.422781) + loss_clip_order (0.269327) = final_loss = 1.297975
n_iter  5 : loss (0.159519) + tot_loss (0.449575) + tot_loss_crop (0.422912) + loss_clip_order (0.272736) = final_loss = 1.304741
n_iter  6 : loss (0.171850) + tot_loss (0.446335) + tot_loss_crop (0.421681) + loss_clip_order (0.277374) = final_loss = 1.317240
n_iter  7 : loss (0.169961) + tot_loss (0.432875) + tot_loss_crop (0.415988) + loss_clip_order (0.278668) = final_loss = 1.297492
n_iter  8 : loss (0.161152) + tot_loss (0.440309) + tot_loss_crop (0.419165) + loss_clip_order (0.278246) = final_loss = 1.298871
n_iter  9 : loss (0.169379) + tot_loss (0.435821) + tot_loss_crop (0.415006) + loss_clip_order (0.277980) = final_loss = 1.298187
n_iter 10 : loss (0.155994) + tot_loss (0.444833) + tot_loss_crop (0.416555) + loss_clip_order (0.279950) = final_loss = 1.297332
n_iter 11 : loss (0.167584) + tot_loss (0.435016) + tot_loss_crop (0.413132) + loss_clip_order (0.273745) = final_loss = 1.289477
n_iter 12 : loss (0.159789) + tot_loss (0.443884) + tot_loss_crop (0.414558) + loss_clip_order (0.270401) = final_loss = 1.288633
n_iter 13 : loss (0.169351) + tot_loss (0.442878) + tot_loss_crop (0.411382) + loss_clip_order (0.270658) = final_loss = 1.294270
n_iter 14 : loss (0.157705) + tot_loss (0.444625) + tot_loss_crop (0.414306) + loss_clip_order (0.278422) = final_loss = 1.295058
n_iter 15 : loss (0.167710) + tot_loss (0.440474) + tot_loss_crop (0.410292) + loss_clip_order (0.276030) = final_loss = 1.294506
n_iter 16 : loss (0.165734) + tot_loss (0.439184) + tot_loss_crop (0.410568) + loss_clip_order (0.267672) = final_loss = 1.283159
n_iter 17 : loss (0.157412) + tot_loss (0.436769) + tot_loss_crop (0.410696) + loss_clip_order (0.279977) = final_loss = 1.284854
n_iter 18 : loss (0.157849) + tot_loss (0.435641) + tot_loss_crop (0.407407) + loss_clip_order (0.269556) = final_loss = 1.270453
n_iter 19 : loss (0.175412) + tot_loss (0.424542) + tot_loss_crop (0.404463) + loss_clip_order (0.282700) = final_loss = 1.287117
n_iter 20 : loss (0.164138) + tot_loss (0.432267) + tot_loss_crop (0.405421) + loss_clip_order (0.268958) = final_loss = 1.270785
n_iter 21 : loss (0.160813) + tot_loss (0.445940) + tot_loss_crop (0.407722) + loss_clip_order (0.274277) = final_loss = 1.288752
n_iter 22 : loss (0.158243) + tot_loss (0.429202) + tot_loss_crop (0.403789) + loss_clip_order (0.278230) = final_loss = 1.269464
n_iter 23 : loss (0.154132) + tot_loss (0.430423) + tot_loss_crop (0.403524) + loss_clip_order (0.269748) = final_loss = 1.257827
n_iter 24 : loss (0.147760) + tot_loss (0.421251) + tot_loss_crop (0.402786) + loss_clip_order (0.273468) = final_loss = 1.245265
n_iter 25 : loss (0.157599) + tot_loss (0.425605) + tot_loss_crop (0.402166) + loss_clip_order (0.268039) = final_loss = 1.253409
n_iter 26 : loss (0.159544) + tot_loss (0.427887) + tot_loss_crop (0.398990) + loss_clip_order (0.274666) = final_loss = 1.261086
n_iter 27 : loss (0.163752) + tot_loss (0.430771) + tot_loss_crop (0.398980) + loss_clip_order (0.277875) = final_loss = 1.271377
n_iter 28 : loss (0.157213) + tot_loss (0.413555) + tot_loss_crop (0.396117) + loss_clip_order (0.275452) = final_loss = 1.242337
n_iter 29 : loss (0.161330) + tot_loss (0.429501) + tot_loss_crop (0.400026) + loss_clip_order (0.268801) = final_loss = 1.259659
n_iter 30 : loss (0.161095) + tot_loss (0.426562) + tot_loss_crop (0.395119) + loss_clip_order (0.273343) = final_loss = 1.256119
[Pretraining Epoch 011] Total-Loss 0.43 =  F-Loss 0.43 + Clip-Loss 0.27 (train)
training epoch 9
use Semi !!!
[Iteration 000] Total-Loss 5.50 = T-Loss 4.77 + B-Loss 0.73 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.81 = T-Loss 4.13 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.73 = T-Loss 4.05 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.68 = T-Loss 4.01 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 009] Total-Loss 4.68 = T-Loss 4.01 + B-Loss 0.67 (train)[0m
[Epoch 009] Total-Loss 4.55 = T-Loss 3.90 + B-Loss 0.65  (val)
training epoch 10
use Semi !!!
[Iteration 000] Total-Loss 3.87 = T-Loss 3.18 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.95 = T-Loss 3.30 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.88 = T-Loss 3.22 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.86 = T-Loss 3.20 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 010] Total-Loss 3.86 = T-Loss 3.20 + B-Loss 0.66 (train)[0m
[Epoch 010] Total-Loss 4.13 = T-Loss 3.49 + B-Loss 0.64  (val)
training epoch 11
use Semi !!!
[Iteration 000] Total-Loss 3.32 = T-Loss 2.63 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.54 = T-Loss 2.89 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.52 = T-Loss 2.86 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.53 = T-Loss 2.87 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 011] Total-Loss 3.53 = T-Loss 2.87 + B-Loss 0.65 (train)[0m
[Epoch 011] Total-Loss 3.98 = T-Loss 3.33 + B-Loss 0.65  (val)
12
n_iter  0 : loss (0.192793) + tot_loss (0.412233) + tot_loss_crop (0.383562) + loss_clip_order (0.441735) = final_loss = 1.430323
n_iter  1 : loss (0.194070) + tot_loss (0.429509) + tot_loss_crop (0.385639) + loss_clip_order (0.433150) = final_loss = 1.442369
n_iter  2 : loss (0.184228) + tot_loss (0.419232) + tot_loss_crop (0.380036) + loss_clip_order (0.421584) = final_loss = 1.405080
n_iter  3 : loss (0.187129) + tot_loss (0.411494) + tot_loss_crop (0.382229) + loss_clip_order (0.420623) = final_loss = 1.401476
n_iter  4 : loss (0.179012) + tot_loss (0.406365) + tot_loss_crop (0.381961) + loss_clip_order (0.371824) = final_loss = 1.339162
n_iter  5 : loss (0.180704) + tot_loss (0.409817) + tot_loss_crop (0.380667) + loss_clip_order (0.379182) = final_loss = 1.350370
n_iter  6 : loss (0.173043) + tot_loss (0.407998) + tot_loss_crop (0.380735) + loss_clip_order (0.355931) = final_loss = 1.317708
n_iter  7 : loss (0.169080) + tot_loss (0.394937) + tot_loss_crop (0.378760) + loss_clip_order (0.339202) = final_loss = 1.281979
n_iter  8 : loss (0.172267) + tot_loss (0.402359) + tot_loss_crop (0.378806) + loss_clip_order (0.327751) = final_loss = 1.281183
n_iter  9 : loss (0.160482) + tot_loss (0.397458) + tot_loss_crop (0.379929) + loss_clip_order (0.295849) = final_loss = 1.233718
n_iter 10 : loss (0.157696) + tot_loss (0.407404) + tot_loss_crop (0.381379) + loss_clip_order (0.277347) = final_loss = 1.223827
n_iter 11 : loss (0.158127) + tot_loss (0.398450) + tot_loss_crop (0.377920) + loss_clip_order (0.273203) = final_loss = 1.207700
n_iter 12 : loss (0.157318) + tot_loss (0.408478) + tot_loss_crop (0.378855) + loss_clip_order (0.263261) = final_loss = 1.207912
n_iter 13 : loss (0.168410) + tot_loss (0.408104) + tot_loss_crop (0.379701) + loss_clip_order (0.262518) = final_loss = 1.218733
n_iter 14 : loss (0.149409) + tot_loss (0.410257) + tot_loss_crop (0.379018) + loss_clip_order (0.275160) = final_loss = 1.213844
n_iter 15 : loss (0.162349) + tot_loss (0.407239) + tot_loss_crop (0.378802) + loss_clip_order (0.272959) = final_loss = 1.221349
n_iter 16 : loss (0.169836) + tot_loss (0.406209) + tot_loss_crop (0.377452) + loss_clip_order (0.267511) = final_loss = 1.221009
n_iter 17 : loss (0.177130) + tot_loss (0.404098) + tot_loss_crop (0.377626) + loss_clip_order (0.287018) = final_loss = 1.245871
n_iter 18 : loss (0.171703) + tot_loss (0.404105) + tot_loss_crop (0.375923) + loss_clip_order (0.272704) = final_loss = 1.224434
n_iter 19 : loss (0.170331) + tot_loss (0.393656) + tot_loss_crop (0.371532) + loss_clip_order (0.265834) = final_loss = 1.201354
n_iter 20 : loss (0.164197) + tot_loss (0.403437) + tot_loss_crop (0.374267) + loss_clip_order (0.271170) = final_loss = 1.213071
n_iter 21 : loss (0.161803) + tot_loss (0.418544) + tot_loss_crop (0.375378) + loss_clip_order (0.272188) = final_loss = 1.227913
n_iter 22 : loss (0.161439) + tot_loss (0.401429) + tot_loss_crop (0.371294) + loss_clip_order (0.272605) = final_loss = 1.206767
n_iter 23 : loss (0.160309) + tot_loss (0.403873) + tot_loss_crop (0.371004) + loss_clip_order (0.263484) = final_loss = 1.198669
n_iter 24 : loss (0.150407) + tot_loss (0.393466) + tot_loss_crop (0.368462) + loss_clip_order (0.271969) = final_loss = 1.184304
n_iter 25 : loss (0.160460) + tot_loss (0.397391) + tot_loss_crop (0.368462) + loss_clip_order (0.259147) = final_loss = 1.185459
n_iter 26 : loss (0.174999) + tot_loss (0.398699) + tot_loss_crop (0.366872) + loss_clip_order (0.277709) = final_loss = 1.218280
n_iter 27 : loss (0.163417) + tot_loss (0.400507) + tot_loss_crop (0.365986) + loss_clip_order (0.258646) = final_loss = 1.188556
n_iter 28 : loss (0.176045) + tot_loss (0.382613) + tot_loss_crop (0.361691) + loss_clip_order (0.262941) = final_loss = 1.183291
n_iter 29 : loss (0.159043) + tot_loss (0.397512) + tot_loss_crop (0.366365) + loss_clip_order (0.263445) = final_loss = 1.186365
n_iter 30 : loss (0.162338) + tot_loss (0.394231) + tot_loss_crop (0.361354) + loss_clip_order (0.257195) = final_loss = 1.175117
[Pretraining Epoch 012] Total-Loss 0.39 =  F-Loss 0.39 + Clip-Loss 0.26 (train)
n_iter  0 : loss (0.160168) + tot_loss (0.386072) + tot_loss_crop (0.361698) + loss_clip_order (0.262184) = final_loss = 1.170121
n_iter  1 : loss (0.160241) + tot_loss (0.401802) + tot_loss_crop (0.363099) + loss_clip_order (0.270264) = final_loss = 1.195407
n_iter  2 : loss (0.159490) + tot_loss (0.392069) + tot_loss_crop (0.360495) + loss_clip_order (0.260784) = final_loss = 1.172837
n_iter  3 : loss (0.160539) + tot_loss (0.384872) + tot_loss_crop (0.357882) + loss_clip_order (0.264585) = final_loss = 1.167878
n_iter  4 : loss (0.164385) + tot_loss (0.380718) + tot_loss_crop (0.355458) + loss_clip_order (0.259284) = final_loss = 1.159845
n_iter  5 : loss (0.172322) + tot_loss (0.385069) + tot_loss_crop (0.356347) + loss_clip_order (0.255755) = final_loss = 1.169493
n_iter  6 : loss (0.154643) + tot_loss (0.381423) + tot_loss_crop (0.355901) + loss_clip_order (0.264212) = final_loss = 1.156179
n_iter  7 : loss (0.163152) + tot_loss (0.368124) + tot_loss_crop (0.350941) + loss_clip_order (0.261708) = final_loss = 1.143924
n_iter  8 : loss (0.165635) + tot_loss (0.375781) + tot_loss_crop (0.351481) + loss_clip_order (0.274606) = final_loss = 1.167503
n_iter  9 : loss (0.166925) + tot_loss (0.370873) + tot_loss_crop (0.350225) + loss_clip_order (0.270227) = final_loss = 1.158249
n_iter 10 : loss (0.167668) + tot_loss (0.379352) + tot_loss_crop (0.349371) + loss_clip_order (0.269872) = final_loss = 1.166262
n_iter 11 : loss (0.160300) + tot_loss (0.370308) + tot_loss_crop (0.349711) + loss_clip_order (0.264896) = final_loss = 1.145215
n_iter 12 : loss (0.156069) + tot_loss (0.378666) + tot_loss_crop (0.348885) + loss_clip_order (0.269217) = final_loss = 1.152837
n_iter 13 : loss (0.153529) + tot_loss (0.377544) + tot_loss_crop (0.349498) + loss_clip_order (0.261481) = final_loss = 1.142053
n_iter 14 : loss (0.159797) + tot_loss (0.378943) + tot_loss_crop (0.348091) + loss_clip_order (0.266340) = final_loss = 1.153171
n_iter 15 : loss (0.157658) + tot_loss (0.374770) + tot_loss_crop (0.348437) + loss_clip_order (0.258383) = final_loss = 1.139247
n_iter 16 : loss (0.163712) + tot_loss (0.374178) + tot_loss_crop (0.344584) + loss_clip_order (0.257896) = final_loss = 1.140370
n_iter 17 : loss (0.161303) + tot_loss (0.372096) + tot_loss_crop (0.346486) + loss_clip_order (0.269676) = final_loss = 1.149560
n_iter 18 : loss (0.153724) + tot_loss (0.371372) + tot_loss_crop (0.346037) + loss_clip_order (0.255679) = final_loss = 1.126811
n_iter 19 : loss (0.173574) + tot_loss (0.360229) + tot_loss_crop (0.340980) + loss_clip_order (0.275100) = final_loss = 1.149884
n_iter 20 : loss (0.160954) + tot_loss (0.368359) + tot_loss_crop (0.343116) + loss_clip_order (0.258234) = final_loss = 1.130663
n_iter 21 : loss (0.160746) + tot_loss (0.381318) + tot_loss_crop (0.343590) + loss_clip_order (0.259653) = final_loss = 1.145307
n_iter 22 : loss (0.162645) + tot_loss (0.365354) + tot_loss_crop (0.340810) + loss_clip_order (0.266028) = final_loss = 1.134838
n_iter 23 : loss (0.163834) + tot_loss (0.366437) + tot_loss_crop (0.342625) + loss_clip_order (0.255270) = final_loss = 1.128166
n_iter 24 : loss (0.162592) + tot_loss (0.357602) + tot_loss_crop (0.337654) + loss_clip_order (0.261607) = final_loss = 1.119455
n_iter 25 : loss (0.160026) + tot_loss (0.362150) + tot_loss_crop (0.338609) + loss_clip_order (0.254821) = final_loss = 1.115607
n_iter 26 : loss (0.162579) + tot_loss (0.364451) + tot_loss_crop (0.340309) + loss_clip_order (0.257242) = final_loss = 1.124581
n_iter 27 : loss (0.162696) + tot_loss (0.367451) + tot_loss_crop (0.336197) + loss_clip_order (0.260407) = final_loss = 1.126752
n_iter 28 : loss (0.168258) + tot_loss (0.351036) + tot_loss_crop (0.333130) + loss_clip_order (0.262720) = final_loss = 1.115144
n_iter 29 : loss (0.157985) + tot_loss (0.366323) + tot_loss_crop (0.336812) + loss_clip_order (0.261441) = final_loss = 1.122561
n_iter 30 : loss (0.160705) + tot_loss (0.363656) + tot_loss_crop (0.335927) + loss_clip_order (0.252131) = final_loss = 1.112420
[Pretraining Epoch 013] Total-Loss 0.36 =  F-Loss 0.36 + Clip-Loss 0.25 (train)
n_iter  0 : loss (0.159245) + tot_loss (0.356017) + tot_loss_crop (0.333929) + loss_clip_order (0.253841) = final_loss = 1.103032
n_iter  1 : loss (0.152973) + tot_loss (0.371935) + tot_loss_crop (0.335717) + loss_clip_order (0.257847) = final_loss = 1.118471
n_iter  2 : loss (0.173040) + tot_loss (0.362538) + tot_loss_crop (0.332037) + loss_clip_order (0.259520) = final_loss = 1.127136
n_iter  3 : loss (0.161882) + tot_loss (0.355537) + tot_loss_crop (0.331962) + loss_clip_order (0.256120) = final_loss = 1.105501
n_iter  4 : loss (0.160872) + tot_loss (0.351245) + tot_loss_crop (0.329886) + loss_clip_order (0.255272) = final_loss = 1.097275
n_iter  5 : loss (0.160865) + tot_loss (0.356092) + tot_loss_crop (0.331268) + loss_clip_order (0.253325) = final_loss = 1.101550
n_iter  6 : loss (0.150392) + tot_loss (0.353004) + tot_loss_crop (0.329258) + loss_clip_order (0.257323) = final_loss = 1.089978
n_iter  7 : loss (0.158419) + tot_loss (0.339945) + tot_loss_crop (0.327951) + loss_clip_order (0.252672) = final_loss = 1.078988
n_iter  8 : loss (0.165941) + tot_loss (0.347738) + tot_loss_crop (0.328016) + loss_clip_order (0.263959) = final_loss = 1.105654
n_iter  9 : loss (0.158644) + tot_loss (0.343255) + tot_loss_crop (0.326476) + loss_clip_order (0.259262) = final_loss = 1.087638
n_iter 10 : loss (0.163896) + tot_loss (0.351919) + tot_loss_crop (0.324943) + loss_clip_order (0.261397) = final_loss = 1.102155
n_iter 11 : loss (0.161792) + tot_loss (0.343334) + tot_loss_crop (0.321944) + loss_clip_order (0.249255) = final_loss = 1.076324
n_iter 12 : loss (0.159724) + tot_loss (0.351410) + tot_loss_crop (0.324535) + loss_clip_order (0.248984) = final_loss = 1.084653
n_iter 13 : loss (0.158847) + tot_loss (0.350024) + tot_loss_crop (0.323828) + loss_clip_order (0.252980) = final_loss = 1.085678
n_iter 14 : loss (0.162256) + tot_loss (0.351327) + tot_loss_crop (0.324702) + loss_clip_order (0.260828) = final_loss = 1.099113
n_iter 15 : loss (0.154001) + tot_loss (0.347177) + tot_loss_crop (0.322547) + loss_clip_order (0.256287) = final_loss = 1.080012
n_iter 16 : loss (0.163300) + tot_loss (0.346799) + tot_loss_crop (0.322148) + loss_clip_order (0.256147) = final_loss = 1.088394
n_iter 17 : loss (0.164658) + tot_loss (0.345154) + tot_loss_crop (0.318938) + loss_clip_order (0.271171) = final_loss = 1.099921
n_iter 18 : loss (0.161057) + tot_loss (0.344550) + tot_loss_crop (0.319295) + loss_clip_order (0.249065) = final_loss = 1.073966
n_iter 19 : loss (0.169360) + tot_loss (0.333975) + tot_loss_crop (0.314256) + loss_clip_order (0.262339) = final_loss = 1.079931
n_iter 20 : loss (0.151445) + tot_loss (0.341974) + tot_loss_crop (0.318263) + loss_clip_order (0.246515) = final_loss = 1.058198
n_iter 21 : loss (0.162628) + tot_loss (0.355000) + tot_loss_crop (0.318360) + loss_clip_order (0.251024) = final_loss = 1.087011
n_iter 22 : loss (0.157772) + tot_loss (0.339105) + tot_loss_crop (0.316589) + loss_clip_order (0.256955) = final_loss = 1.070421
n_iter 23 : loss (0.158372) + tot_loss (0.340434) + tot_loss_crop (0.316805) + loss_clip_order (0.246066) = final_loss = 1.061677
n_iter 24 : loss (0.157075) + tot_loss (0.330962) + tot_loss_crop (0.313677) + loss_clip_order (0.250811) = final_loss = 1.052525
n_iter 25 : loss (0.157262) + tot_loss (0.335399) + tot_loss_crop (0.316185) + loss_clip_order (0.247862) = final_loss = 1.056707
n_iter 26 : loss (0.163579) + tot_loss (0.337667) + tot_loss_crop (0.314806) + loss_clip_order (0.256838) = final_loss = 1.072891
n_iter 27 : loss (0.157758) + tot_loss (0.340760) + tot_loss_crop (0.315660) + loss_clip_order (0.248516) = final_loss = 1.062695
n_iter 28 : loss (0.154380) + tot_loss (0.324634) + tot_loss_crop (0.311942) + loss_clip_order (0.245942) = final_loss = 1.036898
n_iter 29 : loss (0.154386) + tot_loss (0.339315) + tot_loss_crop (0.313385) + loss_clip_order (0.250731) = final_loss = 1.057817
n_iter 30 : loss (0.155278) + tot_loss (0.337461) + tot_loss_crop (0.311499) + loss_clip_order (0.249987) = final_loss = 1.054224
[Pretraining Epoch 014] Total-Loss 0.34 =  F-Loss 0.34 + Clip-Loss 0.25 (train)
training epoch 12
use Semi !!!
[Iteration 000] Total-Loss 5.10 = T-Loss 4.33 + B-Loss 0.76 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.74 = T-Loss 4.04 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.67 = T-Loss 3.98 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.65 = T-Loss 3.97 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 012] Total-Loss 4.65 = T-Loss 3.97 + B-Loss 0.68 (train)[0m
[Epoch 012] Total-Loss 4.66 = T-Loss 4.01 + B-Loss 0.65  (val)
training epoch 13
use Semi !!!
[Iteration 000] Total-Loss 4.20 = T-Loss 3.50 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.11 = T-Loss 3.44 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.99 = T-Loss 3.32 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.94 = T-Loss 3.27 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 013] Total-Loss 3.94 = T-Loss 3.27 + B-Loss 0.66 (train)[0m
[Epoch 013] Total-Loss 4.20 = T-Loss 3.56 + B-Loss 0.64  (val)
training epoch 14
use Semi !!!
[Iteration 000] Total-Loss 3.50 = T-Loss 2.81 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.64 = T-Loss 2.99 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.61 = T-Loss 2.96 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.62 = T-Loss 2.97 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 014] Total-Loss 3.62 = T-Loss 2.97 + B-Loss 0.66 (train)[0m
[Epoch 014] Total-Loss 4.09 = T-Loss 3.45 + B-Loss 0.64  (val)
15
n_iter  0 : loss (0.192606) + tot_loss (0.336087) + tot_loss_crop (0.305184) + loss_clip_order (0.438169) = final_loss = 1.272046
n_iter  1 : loss (0.193537) + tot_loss (0.351381) + tot_loss_crop (0.300939) + loss_clip_order (0.482202) = final_loss = 1.328059
n_iter  2 : loss (0.186771) + tot_loss (0.342776) + tot_loss_crop (0.300611) + loss_clip_order (0.514901) = final_loss = 1.345059
n_iter  3 : loss (0.184436) + tot_loss (0.335710) + tot_loss_crop (0.297757) + loss_clip_order (0.516532) = final_loss = 1.334436
n_iter  4 : loss (0.183770) + tot_loss (0.330420) + tot_loss_crop (0.298912) + loss_clip_order (0.445742) = final_loss = 1.258844
n_iter  5 : loss (0.176155) + tot_loss (0.334863) + tot_loss_crop (0.300538) + loss_clip_order (0.323317) = final_loss = 1.134874
n_iter  6 : loss (0.182840) + tot_loss (0.337189) + tot_loss_crop (0.305847) + loss_clip_order (0.431652) = final_loss = 1.257528
n_iter  7 : loss (0.168461) + tot_loss (0.322041) + tot_loss_crop (0.302105) + loss_clip_order (0.282610) = final_loss = 1.075217
n_iter  8 : loss (0.177560) + tot_loss (0.327720) + tot_loss_crop (0.301520) + loss_clip_order (0.287942) = final_loss = 1.094742
n_iter  9 : loss (0.159846) + tot_loss (0.323699) + tot_loss_crop (0.300925) + loss_clip_order (0.270203) = final_loss = 1.054673
n_iter 10 : loss (0.158432) + tot_loss (0.333289) + tot_loss_crop (0.302971) + loss_clip_order (0.269539) = final_loss = 1.064231
n_iter 11 : loss (0.164042) + tot_loss (0.324549) + tot_loss_crop (0.302098) + loss_clip_order (0.261204) = final_loss = 1.051893
n_iter 12 : loss (0.162401) + tot_loss (0.333455) + tot_loss_crop (0.302991) + loss_clip_order (0.252082) = final_loss = 1.050929
n_iter 13 : loss (0.167479) + tot_loss (0.331203) + tot_loss_crop (0.304806) + loss_clip_order (0.239652) = final_loss = 1.043139
n_iter 14 : loss (0.155340) + tot_loss (0.331941) + tot_loss_crop (0.303757) + loss_clip_order (0.248072) = final_loss = 1.039111
n_iter 15 : loss (0.168578) + tot_loss (0.327711) + tot_loss_crop (0.303216) + loss_clip_order (0.256552) = final_loss = 1.056057
n_iter 16 : loss (0.166748) + tot_loss (0.326253) + tot_loss_crop (0.301570) + loss_clip_order (0.246939) = final_loss = 1.041510
n_iter 17 : loss (0.160883) + tot_loss (0.323658) + tot_loss_crop (0.301875) + loss_clip_order (0.273500) = final_loss = 1.059916
n_iter 18 : loss (0.174626) + tot_loss (0.323509) + tot_loss_crop (0.299191) + loss_clip_order (0.259725) = final_loss = 1.057052
n_iter 19 : loss (0.169403) + tot_loss (0.313792) + tot_loss_crop (0.299285) + loss_clip_order (0.246407) = final_loss = 1.028887
n_iter 20 : loss (0.146365) + tot_loss (0.323262) + tot_loss_crop (0.297491) + loss_clip_order (0.254606) = final_loss = 1.021724
n_iter 21 : loss (0.153526) + tot_loss (0.338042) + tot_loss_crop (0.300225) + loss_clip_order (0.250262) = final_loss = 1.042055
n_iter 22 : loss (0.153409) + tot_loss (0.323109) + tot_loss_crop (0.296433) + loss_clip_order (0.250504) = final_loss = 1.023455
n_iter 23 : loss (0.174822) + tot_loss (0.325848) + tot_loss_crop (0.297205) + loss_clip_order (0.250249) = final_loss = 1.048123
n_iter 24 : loss (0.159674) + tot_loss (0.316304) + tot_loss_crop (0.294486) + loss_clip_order (0.249456) = final_loss = 1.019919
n_iter 25 : loss (0.172866) + tot_loss (0.320815) + tot_loss_crop (0.295093) + loss_clip_order (0.244704) = final_loss = 1.033478
n_iter 26 : loss (0.163328) + tot_loss (0.322139) + tot_loss_crop (0.294474) + loss_clip_order (0.249948) = final_loss = 1.029889
n_iter 27 : loss (0.154507) + tot_loss (0.323178) + tot_loss_crop (0.293482) + loss_clip_order (0.246680) = final_loss = 1.017848
n_iter 28 : loss (0.156403) + tot_loss (0.306123) + tot_loss_crop (0.288648) + loss_clip_order (0.247879) = final_loss = 0.999054
n_iter 29 : loss (0.159200) + tot_loss (0.319147) + tot_loss_crop (0.291043) + loss_clip_order (0.247232) = final_loss = 1.016621
n_iter 30 : loss (0.160665) + tot_loss (0.316578) + tot_loss_crop (0.289441) + loss_clip_order (0.242794) = final_loss = 1.009478
[Pretraining Epoch 015] Total-Loss 0.32 =  F-Loss 0.32 + Clip-Loss 0.24 (train)
n_iter  0 : loss (0.154288) + tot_loss (0.308060) + tot_loss_crop (0.288934) + loss_clip_order (0.240807) = final_loss = 0.992088
n_iter  1 : loss (0.164666) + tot_loss (0.323403) + tot_loss_crop (0.289525) + loss_clip_order (0.252113) = final_loss = 1.029707
n_iter  2 : loss (0.168688) + tot_loss (0.314456) + tot_loss_crop (0.286260) + loss_clip_order (0.241796) = final_loss = 1.011199
n_iter  3 : loss (0.156332) + tot_loss (0.307439) + tot_loss_crop (0.285445) + loss_clip_order (0.237493) = final_loss = 0.986709
n_iter  4 : loss (0.164472) + tot_loss (0.304104) + tot_loss_crop (0.283337) + loss_clip_order (0.240667) = final_loss = 0.992580
n_iter  5 : loss (0.168616) + tot_loss (0.309212) + tot_loss_crop (0.283036) + loss_clip_order (0.239238) = final_loss = 1.000102
n_iter  6 : loss (0.157558) + tot_loss (0.305222) + tot_loss_crop (0.283380) + loss_clip_order (0.238754) = final_loss = 0.984914
n_iter  7 : loss (0.163917) + tot_loss (0.292513) + tot_loss_crop (0.278682) + loss_clip_order (0.249126) = final_loss = 0.984237
n_iter  8 : loss (0.162558) + tot_loss (0.300130) + tot_loss_crop (0.278377) + loss_clip_order (0.249175) = final_loss = 0.990241
n_iter  9 : loss (0.159184) + tot_loss (0.295928) + tot_loss_crop (0.278938) + loss_clip_order (0.241792) = final_loss = 0.975843
n_iter 10 : loss (0.166574) + tot_loss (0.303925) + tot_loss_crop (0.278043) + loss_clip_order (0.243841) = final_loss = 0.992383
n_iter 11 : loss (0.162354) + tot_loss (0.296335) + tot_loss_crop (0.274761) + loss_clip_order (0.248717) = final_loss = 0.982166
n_iter 12 : loss (0.154371) + tot_loss (0.304212) + tot_loss_crop (0.276281) + loss_clip_order (0.237194) = final_loss = 0.972057
n_iter 13 : loss (0.160817) + tot_loss (0.302642) + tot_loss_crop (0.277176) + loss_clip_order (0.236837) = final_loss = 0.977471
n_iter 14 : loss (0.154408) + tot_loss (0.303846) + tot_loss_crop (0.277135) + loss_clip_order (0.246194) = final_loss = 0.981583
n_iter 15 : loss (0.168070) + tot_loss (0.299744) + tot_loss_crop (0.274743) + loss_clip_order (0.245677) = final_loss = 0.988235
n_iter 16 : loss (0.151205) + tot_loss (0.299799) + tot_loss_crop (0.274404) + loss_clip_order (0.240275) = final_loss = 0.965683
n_iter 17 : loss (0.158097) + tot_loss (0.297855) + tot_loss_crop (0.273844) + loss_clip_order (0.246852) = final_loss = 0.976648
n_iter 18 : loss (0.163019) + tot_loss (0.297599) + tot_loss_crop (0.272301) + loss_clip_order (0.242416) = final_loss = 0.975336
n_iter 19 : loss (0.176951) + tot_loss (0.286826) + tot_loss_crop (0.267539) + loss_clip_order (0.253716) = final_loss = 0.985033
n_iter 20 : loss (0.165401) + tot_loss (0.294545) + tot_loss_crop (0.269153) + loss_clip_order (0.245818) = final_loss = 0.974917
n_iter 21 : loss (0.171082) + tot_loss (0.307351) + tot_loss_crop (0.271939) + loss_clip_order (0.240037) = final_loss = 0.990409
n_iter 22 : loss (0.161414) + tot_loss (0.291876) + tot_loss_crop (0.270504) + loss_clip_order (0.257180) = final_loss = 0.980975
n_iter 23 : loss (0.148724) + tot_loss (0.293406) + tot_loss_crop (0.271002) + loss_clip_order (0.232320) = final_loss = 0.945452
n_iter 24 : loss (0.166639) + tot_loss (0.284572) + tot_loss_crop (0.266326) + loss_clip_order (0.246600) = final_loss = 0.964138
n_iter 25 : loss (0.167767) + tot_loss (0.290027) + tot_loss_crop (0.267879) + loss_clip_order (0.258872) = final_loss = 0.984544
n_iter 26 : loss (0.164213) + tot_loss (0.291732) + tot_loss_crop (0.268159) + loss_clip_order (0.238494) = final_loss = 0.962597
n_iter 27 : loss (0.154094) + tot_loss (0.294092) + tot_loss_crop (0.268353) + loss_clip_order (0.239047) = final_loss = 0.955587
n_iter 28 : loss (0.161652) + tot_loss (0.278276) + tot_loss_crop (0.265410) + loss_clip_order (0.232028) = final_loss = 0.937366
n_iter 29 : loss (0.154360) + tot_loss (0.291748) + tot_loss_crop (0.270538) + loss_clip_order (0.241155) = final_loss = 0.957801
n_iter 30 : loss (0.157689) + tot_loss (0.290471) + tot_loss_crop (0.266238) + loss_clip_order (0.236781) = final_loss = 0.951179
[Pretraining Epoch 016] Total-Loss 0.29 =  F-Loss 0.29 + Clip-Loss 0.24 (train)
n_iter  0 : loss (0.163385) + tot_loss (0.283364) + tot_loss_crop (0.265652) + loss_clip_order (0.237352) = final_loss = 0.949753
n_iter  1 : loss (0.169267) + tot_loss (0.298948) + tot_loss_crop (0.268284) + loss_clip_order (0.239021) = final_loss = 0.975520
n_iter  2 : loss (0.158172) + tot_loss (0.290706) + tot_loss_crop (0.263480) + loss_clip_order (0.241669) = final_loss = 0.954026
n_iter  3 : loss (0.159101) + tot_loss (0.284117) + tot_loss_crop (0.263042) + loss_clip_order (0.230710) = final_loss = 0.936971
n_iter  4 : loss (0.162117) + tot_loss (0.280512) + tot_loss_crop (0.262926) + loss_clip_order (0.233920) = final_loss = 0.939475
n_iter  5 : loss (0.168189) + tot_loss (0.285251) + tot_loss_crop (0.262148) + loss_clip_order (0.236303) = final_loss = 0.951891
n_iter  6 : loss (0.152047) + tot_loss (0.281327) + tot_loss_crop (0.262061) + loss_clip_order (0.230857) = final_loss = 0.926292
n_iter  7 : loss (0.170927) + tot_loss (0.268935) + tot_loss_crop (0.259024) + loss_clip_order (0.240236) = final_loss = 0.939122
n_iter  8 : loss (0.154901) + tot_loss (0.276112) + tot_loss_crop (0.262689) + loss_clip_order (0.237138) = final_loss = 0.930839
n_iter  9 : loss (0.146540) + tot_loss (0.272822) + tot_loss_crop (0.260522) + loss_clip_order (0.232652) = final_loss = 0.912536
n_iter 10 : loss (0.172648) + tot_loss (0.281804) + tot_loss_crop (0.259276) + loss_clip_order (0.238254) = final_loss = 0.951981
n_iter 11 : loss (0.152350) + tot_loss (0.274449) + tot_loss_crop (0.256641) + loss_clip_order (0.241274) = final_loss = 0.924714
n_iter 12 : loss (0.150282) + tot_loss (0.283058) + tot_loss_crop (0.258611) + loss_clip_order (0.234473) = final_loss = 0.926423
n_iter 13 : loss (0.158935) + tot_loss (0.281667) + tot_loss_crop (0.257666) + loss_clip_order (0.249230) = final_loss = 0.947498
n_iter 14 : loss (0.173419) + tot_loss (0.282720) + tot_loss_crop (0.257102) + loss_clip_order (0.247376) = final_loss = 0.960616
n_iter 15 : loss (0.164260) + tot_loss (0.277793) + tot_loss_crop (0.258004) + loss_clip_order (0.235340) = final_loss = 0.935397
n_iter 16 : loss (0.162659) + tot_loss (0.277311) + tot_loss_crop (0.257914) + loss_clip_order (0.229861) = final_loss = 0.927745
n_iter 17 : loss (0.164686) + tot_loss (0.275094) + tot_loss_crop (0.257014) + loss_clip_order (0.253875) = final_loss = 0.950669
n_iter 18 : loss (0.163386) + tot_loss (0.274988) + tot_loss_crop (0.255598) + loss_clip_order (0.236813) = final_loss = 0.930786
n_iter 19 : loss (0.160046) + tot_loss (0.264797) + tot_loss_crop (0.252149) + loss_clip_order (0.233118) = final_loss = 0.910109
n_iter 20 : loss (0.168297) + tot_loss (0.274172) + tot_loss_crop (0.255240) + loss_clip_order (0.239359) = final_loss = 0.937068
n_iter 21 : loss (0.166963) + tot_loss (0.287109) + tot_loss_crop (0.256373) + loss_clip_order (0.232800) = final_loss = 0.943245
n_iter 22 : loss (0.162678) + tot_loss (0.271605) + tot_loss_crop (0.251034) + loss_clip_order (0.245773) = final_loss = 0.931090
n_iter 23 : loss (0.152696) + tot_loss (0.272903) + tot_loss_crop (0.253654) + loss_clip_order (0.232876) = final_loss = 0.912129
n_iter 24 : loss (0.166947) + tot_loss (0.263597) + tot_loss_crop (0.248240) + loss_clip_order (0.237076) = final_loss = 0.915860
n_iter 25 : loss (0.158036) + tot_loss (0.268459) + tot_loss_crop (0.253183) + loss_clip_order (0.229694) = final_loss = 0.909372
n_iter 26 : loss (0.166663) + tot_loss (0.269871) + tot_loss_crop (0.250966) + loss_clip_order (0.240371) = final_loss = 0.927871
n_iter 27 : loss (0.161217) + tot_loss (0.272708) + tot_loss_crop (0.249986) + loss_clip_order (0.230911) = final_loss = 0.914822
n_iter 28 : loss (0.152863) + tot_loss (0.257462) + tot_loss_crop (0.248138) + loss_clip_order (0.229833) = final_loss = 0.888296
n_iter 29 : loss (0.162765) + tot_loss (0.271628) + tot_loss_crop (0.250437) + loss_clip_order (0.235362) = final_loss = 0.920192
n_iter 30 : loss (0.155191) + tot_loss (0.270189) + tot_loss_crop (0.249247) + loss_clip_order (0.228187) = final_loss = 0.902814
[Pretraining Epoch 017] Total-Loss 0.27 =  F-Loss 0.27 + Clip-Loss 0.23 (train)
training epoch 15
use Semi !!!
[Iteration 000] Total-Loss 5.53 = T-Loss 4.81 + B-Loss 0.72 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.76 = T-Loss 4.08 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.69 = T-Loss 4.00 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.67 = T-Loss 3.99 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 015] Total-Loss 4.67 = T-Loss 3.99 + B-Loss 0.68 (train)[0m
[Epoch 015] Total-Loss 4.65 = T-Loss 3.99 + B-Loss 0.66  (val)
training epoch 16
use Semi !!!
[Iteration 000] Total-Loss 4.04 = T-Loss 3.34 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.11 = T-Loss 3.43 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.01 = T-Loss 3.34 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.98 = T-Loss 3.31 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 016] Total-Loss 3.98 = T-Loss 3.31 + B-Loss 0.67 (train)[0m
[Epoch 016] Total-Loss 4.24 = T-Loss 3.60 + B-Loss 0.64  (val)
training epoch 17
use Semi !!!
[Iteration 000] Total-Loss 3.60 = T-Loss 2.90 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.73 = T-Loss 3.07 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.69 = T-Loss 3.03 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.70 = T-Loss 3.04 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 017] Total-Loss 3.70 = T-Loss 3.04 + B-Loss 0.66 (train)[0m
[Epoch 017] Total-Loss 4.14 = T-Loss 3.50 + B-Loss 0.64  (val)
18
n_iter  0 : loss (0.200821) + tot_loss (0.269316) + tot_loss_crop (0.234109) + loss_clip_order (0.458819) = final_loss = 1.163064
n_iter  1 : loss (0.204158) + tot_loss (0.285562) + tot_loss_crop (0.236670) + loss_clip_order (0.400341) = final_loss = 1.126732
n_iter  2 : loss (0.199066) + tot_loss (0.277769) + tot_loss_crop (0.239028) + loss_clip_order (0.307706) = final_loss = 1.023568
n_iter  3 : loss (0.199463) + tot_loss (0.270758) + tot_loss_crop (0.239886) + loss_clip_order (0.365678) = final_loss = 1.075784
n_iter  4 : loss (0.188644) + tot_loss (0.265009) + tot_loss_crop (0.236152) + loss_clip_order (0.320147) = final_loss = 1.009951
n_iter  5 : loss (0.184484) + tot_loss (0.271434) + tot_loss_crop (0.236114) + loss_clip_order (0.335718) = final_loss = 1.027750
n_iter  6 : loss (0.184764) + tot_loss (0.270557) + tot_loss_crop (0.238368) + loss_clip_order (0.331421) = final_loss = 1.025110
n_iter  7 : loss (0.185404) + tot_loss (0.258639) + tot_loss_crop (0.236262) + loss_clip_order (0.309862) = final_loss = 0.990167
n_iter  8 : loss (0.169662) + tot_loss (0.265524) + tot_loss_crop (0.240357) + loss_clip_order (0.249610) = final_loss = 0.925153
n_iter  9 : loss (0.178180) + tot_loss (0.260498) + tot_loss_crop (0.241915) + loss_clip_order (0.236418) = final_loss = 0.917010
n_iter 10 : loss (0.169435) + tot_loss (0.269518) + tot_loss_crop (0.245349) + loss_clip_order (0.240581) = final_loss = 0.924883
n_iter 11 : loss (0.174534) + tot_loss (0.260559) + tot_loss_crop (0.242578) + loss_clip_order (0.256391) = final_loss = 0.934063
n_iter 12 : loss (0.163618) + tot_loss (0.269054) + tot_loss_crop (0.243185) + loss_clip_order (0.258638) = final_loss = 0.934494
n_iter 13 : loss (0.171663) + tot_loss (0.266978) + tot_loss_crop (0.243271) + loss_clip_order (0.229047) = final_loss = 0.910959
n_iter 14 : loss (0.169979) + tot_loss (0.269896) + tot_loss_crop (0.244377) + loss_clip_order (0.233375) = final_loss = 0.917627
n_iter 15 : loss (0.171560) + tot_loss (0.268286) + tot_loss_crop (0.242815) + loss_clip_order (0.236293) = final_loss = 0.918954
n_iter 16 : loss (0.159893) + tot_loss (0.269662) + tot_loss_crop (0.244108) + loss_clip_order (0.229628) = final_loss = 0.903290
n_iter 17 : loss (0.167564) + tot_loss (0.268468) + tot_loss_crop (0.243765) + loss_clip_order (0.229648) = final_loss = 0.909446
n_iter 18 : loss (0.150972) + tot_loss (0.269686) + tot_loss_crop (0.243337) + loss_clip_order (0.226382) = final_loss = 0.890377
n_iter 19 : loss (0.174380) + tot_loss (0.258925) + tot_loss_crop (0.239851) + loss_clip_order (0.229290) = final_loss = 0.902446
n_iter 20 : loss (0.171415) + tot_loss (0.267626) + tot_loss_crop (0.241830) + loss_clip_order (0.230909) = final_loss = 0.911779
n_iter 21 : loss (0.163988) + tot_loss (0.280558) + tot_loss_crop (0.243797) + loss_clip_order (0.229255) = final_loss = 0.917598
n_iter 22 : loss (0.158694) + tot_loss (0.264141) + tot_loss_crop (0.238844) + loss_clip_order (0.240706) = final_loss = 0.902385
n_iter 23 : loss (0.153197) + tot_loss (0.265627) + tot_loss_crop (0.240165) + loss_clip_order (0.224955) = final_loss = 0.883944
n_iter 24 : loss (0.159986) + tot_loss (0.254538) + tot_loss_crop (0.236980) + loss_clip_order (0.233630) = final_loss = 0.885134
n_iter 25 : loss (0.160099) + tot_loss (0.258997) + tot_loss_crop (0.237917) + loss_clip_order (0.224596) = final_loss = 0.881609
n_iter 26 : loss (0.160937) + tot_loss (0.260215) + tot_loss_crop (0.237045) + loss_clip_order (0.242387) = final_loss = 0.900584
n_iter 27 : loss (0.160704) + tot_loss (0.261356) + tot_loss_crop (0.235439) + loss_clip_order (0.225911) = final_loss = 0.883410
n_iter 28 : loss (0.158630) + tot_loss (0.245077) + tot_loss_crop (0.232555) + loss_clip_order (0.223249) = final_loss = 0.859512
n_iter 29 : loss (0.160106) + tot_loss (0.258222) + tot_loss_crop (0.236498) + loss_clip_order (0.223760) = final_loss = 0.878586
n_iter 30 : loss (0.156149) + tot_loss (0.256010) + tot_loss_crop (0.232988) + loss_clip_order (0.223219) = final_loss = 0.868367
[Pretraining Epoch 018] Total-Loss 0.26 =  F-Loss 0.26 + Clip-Loss 0.22 (train)
n_iter  0 : loss (0.171107) + tot_loss (0.248012) + tot_loss_crop (0.230478) + loss_clip_order (0.226847) = final_loss = 0.876444
n_iter  1 : loss (0.169269) + tot_loss (0.262989) + tot_loss_crop (0.235347) + loss_clip_order (0.242678) = final_loss = 0.910283
n_iter  2 : loss (0.159649) + tot_loss (0.254609) + tot_loss_crop (0.230243) + loss_clip_order (0.226753) = final_loss = 0.871254
n_iter  3 : loss (0.150694) + tot_loss (0.247761) + tot_loss_crop (0.229030) + loss_clip_order (0.221737) = final_loss = 0.849223
n_iter  4 : loss (0.162071) + tot_loss (0.244711) + tot_loss_crop (0.228214) + loss_clip_order (0.223004) = final_loss = 0.857999
n_iter  5 : loss (0.147457) + tot_loss (0.249475) + tot_loss_crop (0.228442) + loss_clip_order (0.223010) = final_loss = 0.848384
n_iter  6 : loss (0.161909) + tot_loss (0.246001) + tot_loss_crop (0.228307) + loss_clip_order (0.224118) = final_loss = 0.860335
n_iter  7 : loss (0.152410) + tot_loss (0.234155) + tot_loss_crop (0.224573) + loss_clip_order (0.217629) = final_loss = 0.828766
n_iter  8 : loss (0.155066) + tot_loss (0.241864) + tot_loss_crop (0.225172) + loss_clip_order (0.229720) = final_loss = 0.851821
n_iter  9 : loss (0.161163) + tot_loss (0.237903) + tot_loss_crop (0.224042) + loss_clip_order (0.226452) = final_loss = 0.849559
n_iter 10 : loss (0.173136) + tot_loss (0.246073) + tot_loss_crop (0.223976) + loss_clip_order (0.224103) = final_loss = 0.867289
n_iter 11 : loss (0.168310) + tot_loss (0.238838) + tot_loss_crop (0.221424) + loss_clip_order (0.224854) = final_loss = 0.853426
n_iter 12 : loss (0.167784) + tot_loss (0.246155) + tot_loss_crop (0.221486) + loss_clip_order (0.224191) = final_loss = 0.859617
n_iter 13 : loss (0.163117) + tot_loss (0.244509) + tot_loss_crop (0.222498) + loss_clip_order (0.218659) = final_loss = 0.848782
n_iter 14 : loss (0.155568) + tot_loss (0.245230) + tot_loss_crop (0.220711) + loss_clip_order (0.230701) = final_loss = 0.852210
n_iter 15 : loss (0.157119) + tot_loss (0.241136) + tot_loss_crop (0.220609) + loss_clip_order (0.221635) = final_loss = 0.840500
n_iter 16 : loss (0.159308) + tot_loss (0.241343) + tot_loss_crop (0.220350) + loss_clip_order (0.220050) = final_loss = 0.841051
n_iter 17 : loss (0.163404) + tot_loss (0.239165) + tot_loss_crop (0.218814) + loss_clip_order (0.240761) = final_loss = 0.862143
n_iter 18 : loss (0.154814) + tot_loss (0.239272) + tot_loss_crop (0.218027) + loss_clip_order (0.233154) = final_loss = 0.845267
n_iter 19 : loss (0.175092) + tot_loss (0.228787) + tot_loss_crop (0.214690) + loss_clip_order (0.220894) = final_loss = 0.839463
n_iter 20 : loss (0.168920) + tot_loss (0.237484) + tot_loss_crop (0.216061) + loss_clip_order (0.228473) = final_loss = 0.850938
n_iter 21 : loss (0.174702) + tot_loss (0.250428) + tot_loss_crop (0.217581) + loss_clip_order (0.232369) = final_loss = 0.875080
n_iter 22 : loss (0.172507) + tot_loss (0.235565) + tot_loss_crop (0.212465) + loss_clip_order (0.239880) = final_loss = 0.860417
n_iter 23 : loss (0.167610) + tot_loss (0.237026) + tot_loss_crop (0.214785) + loss_clip_order (0.230356) = final_loss = 0.849776
n_iter 24 : loss (0.159531) + tot_loss (0.227849) + tot_loss_crop (0.211569) + loss_clip_order (0.228993) = final_loss = 0.827943
n_iter 25 : loss (0.160396) + tot_loss (0.232635) + tot_loss_crop (0.213710) + loss_clip_order (0.228095) = final_loss = 0.834836
n_iter 26 : loss (0.163384) + tot_loss (0.233750) + tot_loss_crop (0.213886) + loss_clip_order (0.228371) = final_loss = 0.839391
n_iter 27 : loss (0.163098) + tot_loss (0.236727) + tot_loss_crop (0.213098) + loss_clip_order (0.228895) = final_loss = 0.841818
n_iter 28 : loss (0.163186) + tot_loss (0.222205) + tot_loss_crop (0.209337) + loss_clip_order (0.227844) = final_loss = 0.822572
n_iter 29 : loss (0.149475) + tot_loss (0.235481) + tot_loss_crop (0.212618) + loss_clip_order (0.227369) = final_loss = 0.824943
n_iter 30 : loss (0.157558) + tot_loss (0.234589) + tot_loss_crop (0.212630) + loss_clip_order (0.218587) = final_loss = 0.823365
[Pretraining Epoch 019] Total-Loss 0.23 =  F-Loss 0.23 + Clip-Loss 0.22 (train)
n_iter  0 : loss (0.172401) + tot_loss (0.227094) + tot_loss_crop (0.209943) + loss_clip_order (0.229357) = final_loss = 0.838795
n_iter  1 : loss (0.159682) + tot_loss (0.242620) + tot_loss_crop (0.212844) + loss_clip_order (0.232567) = final_loss = 0.847712
n_iter  2 : loss (0.159122) + tot_loss (0.234824) + tot_loss_crop (0.209825) + loss_clip_order (0.221771) = final_loss = 0.825541
n_iter  3 : loss (0.159609) + tot_loss (0.228393) + tot_loss_crop (0.207740) + loss_clip_order (0.222786) = final_loss = 0.818528
n_iter  4 : loss (0.148544) + tot_loss (0.224651) + tot_loss_crop (0.208364) + loss_clip_order (0.220643) = final_loss = 0.802202
n_iter  5 : loss (0.153960) + tot_loss (0.229529) + tot_loss_crop (0.208228) + loss_clip_order (0.216274) = final_loss = 0.807991
n_iter  6 : loss (0.165122) + tot_loss (0.226124) + tot_loss_crop (0.206513) + loss_clip_order (0.219872) = final_loss = 0.817631
n_iter  7 : loss (0.158430) + tot_loss (0.214121) + tot_loss_crop (0.203962) + loss_clip_order (0.233656) = final_loss = 0.810168
n_iter  8 : loss (0.160132) + tot_loss (0.221465) + tot_loss_crop (0.206324) + loss_clip_order (0.229419) = final_loss = 0.817340
n_iter  9 : loss (0.159967) + tot_loss (0.217671) + tot_loss_crop (0.205371) + loss_clip_order (0.223277) = final_loss = 0.806285
n_iter 10 : loss (0.165919) + tot_loss (0.225674) + tot_loss_crop (0.203618) + loss_clip_order (0.233598) = final_loss = 0.828809
n_iter 11 : loss (0.175331) + tot_loss (0.219002) + tot_loss_crop (0.202604) + loss_clip_order (0.230668) = final_loss = 0.827605
n_iter 12 : loss (0.162505) + tot_loss (0.227535) + tot_loss_crop (0.204465) + loss_clip_order (0.221125) = final_loss = 0.815629
n_iter 13 : loss (0.157580) + tot_loss (0.225624) + tot_loss_crop (0.205286) + loss_clip_order (0.215120) = final_loss = 0.803609
n_iter 14 : loss (0.171866) + tot_loss (0.227204) + tot_loss_crop (0.204628) + loss_clip_order (0.228470) = final_loss = 0.832168
n_iter 15 : loss (0.165215) + tot_loss (0.223752) + tot_loss_crop (0.205192) + loss_clip_order (0.216932) = final_loss = 0.811091
n_iter 16 : loss (0.155753) + tot_loss (0.223307) + tot_loss_crop (0.201458) + loss_clip_order (0.222352) = final_loss = 0.802870
n_iter 17 : loss (0.150784) + tot_loss (0.221672) + tot_loss_crop (0.203584) + loss_clip_order (0.231525) = final_loss = 0.807564
n_iter 18 : loss (0.161681) + tot_loss (0.221831) + tot_loss_crop (0.204007) + loss_clip_order (0.216876) = final_loss = 0.804394
n_iter 19 : loss (0.173026) + tot_loss (0.211616) + tot_loss_crop (0.197825) + loss_clip_order (0.227922) = final_loss = 0.810389
n_iter 20 : loss (0.165516) + tot_loss (0.219725) + tot_loss_crop (0.199741) + loss_clip_order (0.220177) = final_loss = 0.805160
n_iter 21 : loss (0.167915) + tot_loss (0.232077) + tot_loss_crop (0.204174) + loss_clip_order (0.222232) = final_loss = 0.826398
n_iter 22 : loss (0.162122) + tot_loss (0.217593) + tot_loss_crop (0.198394) + loss_clip_order (0.224357) = final_loss = 0.802466
n_iter 23 : loss (0.162183) + tot_loss (0.219100) + tot_loss_crop (0.200299) + loss_clip_order (0.219286) = final_loss = 0.800868
n_iter 24 : loss (0.172284) + tot_loss (0.210683) + tot_loss_crop (0.195824) + loss_clip_order (0.222020) = final_loss = 0.800811
n_iter 25 : loss (0.156856) + tot_loss (0.215926) + tot_loss_crop (0.199498) + loss_clip_order (0.216201) = final_loss = 0.788480
n_iter 26 : loss (0.165555) + tot_loss (0.217417) + tot_loss_crop (0.198981) + loss_clip_order (0.218507) = final_loss = 0.800460
n_iter 27 : loss (0.164287) + tot_loss (0.220501) + tot_loss_crop (0.198813) + loss_clip_order (0.222941) = final_loss = 0.806542
n_iter 28 : loss (0.163767) + tot_loss (0.205290) + tot_loss_crop (0.193260) + loss_clip_order (0.225900) = final_loss = 0.788217
n_iter 29 : loss (0.158399) + tot_loss (0.218726) + tot_loss_crop (0.199751) + loss_clip_order (0.223314) = final_loss = 0.800190
n_iter 30 : loss (0.159973) + tot_loss (0.217963) + tot_loss_crop (0.197234) + loss_clip_order (0.216143) = final_loss = 0.791313
[Pretraining Epoch 020] Total-Loss 0.22 =  F-Loss 0.22 + Clip-Loss 0.22 (train)
training epoch 18
use Semi !!!
[Iteration 000] Total-Loss 4.84 = T-Loss 4.12 + B-Loss 0.72 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.58 = T-Loss 3.89 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.46 = T-Loss 3.78 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.40 = T-Loss 3.72 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 018] Total-Loss 4.40 = T-Loss 3.72 + B-Loss 0.68 (train)[0m
[Epoch 018] Total-Loss 4.52 = T-Loss 3.87 + B-Loss 0.64  (val)
training epoch 19
use Semi !!!
[Iteration 000] Total-Loss 3.84 = T-Loss 3.14 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.01 = T-Loss 3.35 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.94 = T-Loss 3.28 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.92 = T-Loss 3.26 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 019] Total-Loss 3.92 = T-Loss 3.26 + B-Loss 0.66 (train)[0m
[Epoch 019] Total-Loss 4.28 = T-Loss 3.64 + B-Loss 0.64  (val)
training epoch 20
use Semi !!!
[Iteration 000] Total-Loss 3.56 = T-Loss 2.87 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.76 = T-Loss 3.10 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.70 = T-Loss 3.05 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.69 = T-Loss 3.03 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 020] Total-Loss 3.69 = T-Loss 3.03 + B-Loss 0.66 (train)[0m
[Epoch 020] Total-Loss 4.10 = T-Loss 3.46 + B-Loss 0.64  (val)
21
n_iter  0 : loss (0.199237) + tot_loss (0.212816) + tot_loss_crop (0.185089) + loss_clip_order (0.291582) = final_loss = 0.888725
n_iter  1 : loss (0.198197) + tot_loss (0.228721) + tot_loss_crop (0.188577) + loss_clip_order (0.276711) = final_loss = 0.892206
n_iter  2 : loss (0.194628) + tot_loss (0.220892) + tot_loss_crop (0.186907) + loss_clip_order (0.268853) = final_loss = 0.871280
n_iter  3 : loss (0.190696) + tot_loss (0.214253) + tot_loss_crop (0.185137) + loss_clip_order (0.258840) = final_loss = 0.848926
n_iter  4 : loss (0.188088) + tot_loss (0.209440) + tot_loss_crop (0.184782) + loss_clip_order (0.258810) = final_loss = 0.841119
n_iter  5 : loss (0.181891) + tot_loss (0.214710) + tot_loss_crop (0.187066) + loss_clip_order (0.236685) = final_loss = 0.820352
n_iter  6 : loss (0.183188) + tot_loss (0.212667) + tot_loss_crop (0.186469) + loss_clip_order (0.257115) = final_loss = 0.839439
n_iter  7 : loss (0.173251) + tot_loss (0.201287) + tot_loss_crop (0.186819) + loss_clip_order (0.247205) = final_loss = 0.808562
n_iter  8 : loss (0.177646) + tot_loss (0.209198) + tot_loss_crop (0.188122) + loss_clip_order (0.237540) = final_loss = 0.812506
n_iter  9 : loss (0.163398) + tot_loss (0.205447) + tot_loss_crop (0.188429) + loss_clip_order (0.231847) = final_loss = 0.789122
n_iter 10 : loss (0.158146) + tot_loss (0.213988) + tot_loss_crop (0.190083) + loss_clip_order (0.226198) = final_loss = 0.788415
n_iter 11 : loss (0.173527) + tot_loss (0.206822) + tot_loss_crop (0.186608) + loss_clip_order (0.233554) = final_loss = 0.800511
n_iter 12 : loss (0.165417) + tot_loss (0.215682) + tot_loss_crop (0.190141) + loss_clip_order (0.218536) = final_loss = 0.789776
n_iter 13 : loss (0.173601) + tot_loss (0.213505) + tot_loss_crop (0.190258) + loss_clip_order (0.225143) = final_loss = 0.802508
n_iter 14 : loss (0.163574) + tot_loss (0.215021) + tot_loss_crop (0.190615) + loss_clip_order (0.217573) = final_loss = 0.786782
n_iter 15 : loss (0.163940) + tot_loss (0.211266) + tot_loss_crop (0.189491) + loss_clip_order (0.214641) = final_loss = 0.779337
n_iter 16 : loss (0.161013) + tot_loss (0.210294) + tot_loss_crop (0.190169) + loss_clip_order (0.213890) = final_loss = 0.775367
n_iter 17 : loss (0.157853) + tot_loss (0.208406) + tot_loss_crop (0.188165) + loss_clip_order (0.228890) = final_loss = 0.783315
n_iter 18 : loss (0.160754) + tot_loss (0.208206) + tot_loss_crop (0.188557) + loss_clip_order (0.221831) = final_loss = 0.779348
n_iter 19 : loss (0.168297) + tot_loss (0.199062) + tot_loss_crop (0.184810) + loss_clip_order (0.222624) = final_loss = 0.774793
n_iter 20 : loss (0.158853) + tot_loss (0.207246) + tot_loss_crop (0.185541) + loss_clip_order (0.215143) = final_loss = 0.766783
n_iter 21 : loss (0.153288) + tot_loss (0.219828) + tot_loss_crop (0.187622) + loss_clip_order (0.204274) = final_loss = 0.765012
n_iter 22 : loss (0.149370) + tot_loss (0.205757) + tot_loss_crop (0.185086) + loss_clip_order (0.216419) = final_loss = 0.756631
n_iter 23 : loss (0.167118) + tot_loss (0.207650) + tot_loss_crop (0.187189) + loss_clip_order (0.211001) = final_loss = 0.772957
n_iter 24 : loss (0.169725) + tot_loss (0.200028) + tot_loss_crop (0.185527) + loss_clip_order (0.213850) = final_loss = 0.769130
n_iter 25 : loss (0.166999) + tot_loss (0.204846) + tot_loss_crop (0.186255) + loss_clip_order (0.213442) = final_loss = 0.771542
n_iter 26 : loss (0.164635) + tot_loss (0.207178) + tot_loss_crop (0.186008) + loss_clip_order (0.220572) = final_loss = 0.778392
n_iter 27 : loss (0.170074) + tot_loss (0.209789) + tot_loss_crop (0.184449) + loss_clip_order (0.215820) = final_loss = 0.780132
n_iter 28 : loss (0.159228) + tot_loss (0.194382) + tot_loss_crop (0.181907) + loss_clip_order (0.206148) = final_loss = 0.741664
n_iter 29 : loss (0.161796) + tot_loss (0.207655) + tot_loss_crop (0.183902) + loss_clip_order (0.214276) = final_loss = 0.767628
n_iter 30 : loss (0.172446) + tot_loss (0.205823) + tot_loss_crop (0.184537) + loss_clip_order (0.208631) = final_loss = 0.771437
[Pretraining Epoch 021] Total-Loss 0.21 =  F-Loss 0.21 + Clip-Loss 0.21 (train)
n_iter  0 : loss (0.166306) + tot_loss (0.198348) + tot_loss_crop (0.181938) + loss_clip_order (0.217715) = final_loss = 0.764307
n_iter  1 : loss (0.163650) + tot_loss (0.213277) + tot_loss_crop (0.184153) + loss_clip_order (0.211645) = final_loss = 0.772725
n_iter  2 : loss (0.159151) + tot_loss (0.205499) + tot_loss_crop (0.182304) + loss_clip_order (0.208723) = final_loss = 0.755677
n_iter  3 : loss (0.164350) + tot_loss (0.198378) + tot_loss_crop (0.181305) + loss_clip_order (0.214898) = final_loss = 0.758931
n_iter  4 : loss (0.167293) + tot_loss (0.194673) + tot_loss_crop (0.180255) + loss_clip_order (0.209689) = final_loss = 0.751909
n_iter  5 : loss (0.151890) + tot_loss (0.200510) + tot_loss_crop (0.182165) + loss_clip_order (0.204993) = final_loss = 0.739558
n_iter  6 : loss (0.167688) + tot_loss (0.197455) + tot_loss_crop (0.178945) + loss_clip_order (0.212754) = final_loss = 0.756842
n_iter  7 : loss (0.166393) + tot_loss (0.185845) + tot_loss_crop (0.175625) + loss_clip_order (0.209383) = final_loss = 0.737246
n_iter  8 : loss (0.156618) + tot_loss (0.193638) + tot_loss_crop (0.178208) + loss_clip_order (0.211662) = final_loss = 0.740125
n_iter  9 : loss (0.165501) + tot_loss (0.190023) + tot_loss_crop (0.176304) + loss_clip_order (0.210132) = final_loss = 0.741960
n_iter 10 : loss (0.164071) + tot_loss (0.198362) + tot_loss_crop (0.178648) + loss_clip_order (0.211300) = final_loss = 0.752381
n_iter 11 : loss (0.165806) + tot_loss (0.190592) + tot_loss_crop (0.174977) + loss_clip_order (0.211135) = final_loss = 0.742509
n_iter 12 : loss (0.164341) + tot_loss (0.199497) + tot_loss_crop (0.175773) + loss_clip_order (0.218615) = final_loss = 0.758227
n_iter 13 : loss (0.153629) + tot_loss (0.197691) + tot_loss_crop (0.176186) + loss_clip_order (0.204211) = final_loss = 0.731716
n_iter 14 : loss (0.156858) + tot_loss (0.199062) + tot_loss_crop (0.176124) + loss_clip_order (0.209332) = final_loss = 0.741376
n_iter 15 : loss (0.164798) + tot_loss (0.194921) + tot_loss_crop (0.175781) + loss_clip_order (0.205071) = final_loss = 0.740571
n_iter 16 : loss (0.167610) + tot_loss (0.194926) + tot_loss_crop (0.172873) + loss_clip_order (0.208174) = final_loss = 0.743582
n_iter 17 : loss (0.162204) + tot_loss (0.193110) + tot_loss_crop (0.173459) + loss_clip_order (0.221368) = final_loss = 0.750140
n_iter 18 : loss (0.163381) + tot_loss (0.192902) + tot_loss_crop (0.175054) + loss_clip_order (0.216353) = final_loss = 0.747691
n_iter 19 : loss (0.157010) + tot_loss (0.182752) + tot_loss_crop (0.169296) + loss_clip_order (0.219462) = final_loss = 0.728520
n_iter 20 : loss (0.159404) + tot_loss (0.191191) + tot_loss_crop (0.171007) + loss_clip_order (0.210352) = final_loss = 0.731955
n_iter 21 : loss (0.164035) + tot_loss (0.203846) + tot_loss_crop (0.173291) + loss_clip_order (0.212124) = final_loss = 0.753295
n_iter 22 : loss (0.163285) + tot_loss (0.189440) + tot_loss_crop (0.168842) + loss_clip_order (0.225042) = final_loss = 0.746608
n_iter 23 : loss (0.169907) + tot_loss (0.191201) + tot_loss_crop (0.172285) + loss_clip_order (0.208630) = final_loss = 0.742023
n_iter 24 : loss (0.155367) + tot_loss (0.182478) + tot_loss_crop (0.167540) + loss_clip_order (0.216333) = final_loss = 0.721718
n_iter 25 : loss (0.158270) + tot_loss (0.187554) + tot_loss_crop (0.171368) + loss_clip_order (0.204317) = final_loss = 0.721510
n_iter 26 : loss (0.163875) + tot_loss (0.189691) + tot_loss_crop (0.170235) + loss_clip_order (0.206425) = final_loss = 0.730226
n_iter 27 : loss (0.164736) + tot_loss (0.192491) + tot_loss_crop (0.167564) + loss_clip_order (0.213581) = final_loss = 0.738372
n_iter 28 : loss (0.158291) + tot_loss (0.177824) + tot_loss_crop (0.164775) + loss_clip_order (0.204209) = final_loss = 0.705099
n_iter 29 : loss (0.160610) + tot_loss (0.190528) + tot_loss_crop (0.170981) + loss_clip_order (0.204539) = final_loss = 0.726658
n_iter 30 : loss (0.169097) + tot_loss (0.189674) + tot_loss_crop (0.168525) + loss_clip_order (0.217766) = final_loss = 0.745063
[Pretraining Epoch 022] Total-Loss 0.19 =  F-Loss 0.19 + Clip-Loss 0.22 (train)
n_iter  0 : loss (0.176180) + tot_loss (0.182840) + tot_loss_crop (0.166169) + loss_clip_order (0.218969) = final_loss = 0.744157
n_iter  1 : loss (0.168684) + tot_loss (0.197590) + tot_loss_crop (0.170395) + loss_clip_order (0.211927) = final_loss = 0.748597
n_iter  2 : loss (0.157166) + tot_loss (0.190464) + tot_loss_crop (0.166383) + loss_clip_order (0.206863) = final_loss = 0.720876
n_iter  3 : loss (0.161294) + tot_loss (0.184058) + tot_loss_crop (0.166358) + loss_clip_order (0.207596) = final_loss = 0.719307
n_iter  4 : loss (0.168112) + tot_loss (0.181058) + tot_loss_crop (0.164446) + loss_clip_order (0.212102) = final_loss = 0.725718
n_iter  5 : loss (0.169824) + tot_loss (0.186123) + tot_loss_crop (0.166053) + loss_clip_order (0.214766) = final_loss = 0.736766
n_iter  6 : loss (0.157721) + tot_loss (0.182775) + tot_loss_crop (0.164594) + loss_clip_order (0.211713) = final_loss = 0.716803
n_iter  7 : loss (0.164391) + tot_loss (0.171003) + tot_loss_crop (0.159607) + loss_clip_order (0.215087) = final_loss = 0.710087
n_iter  8 : loss (0.156477) + tot_loss (0.178495) + tot_loss_crop (0.163423) + loss_clip_order (0.210866) = final_loss = 0.709261
n_iter  9 : loss (0.159780) + tot_loss (0.175172) + tot_loss_crop (0.161461) + loss_clip_order (0.206478) = final_loss = 0.702891
n_iter 10 : loss (0.155655) + tot_loss (0.183234) + tot_loss_crop (0.163544) + loss_clip_order (0.203483) = final_loss = 0.705917
n_iter 11 : loss (0.172138) + tot_loss (0.176718) + tot_loss_crop (0.160104) + loss_clip_order (0.208938) = final_loss = 0.717898
n_iter 12 : loss (0.173241) + tot_loss (0.184933) + tot_loss_crop (0.162491) + loss_clip_order (0.207522) = final_loss = 0.728187
n_iter 13 : loss (0.157412) + tot_loss (0.183608) + tot_loss_crop (0.162761) + loss_clip_order (0.196905) = final_loss = 0.700687
n_iter 14 : loss (0.176202) + tot_loss (0.185187) + tot_loss_crop (0.162153) + loss_clip_order (0.206827) = final_loss = 0.730369
n_iter 15 : loss (0.169911) + tot_loss (0.181242) + tot_loss_crop (0.163018) + loss_clip_order (0.200865) = final_loss = 0.715037
n_iter 16 : loss (0.159135) + tot_loss (0.181779) + tot_loss_crop (0.163500) + loss_clip_order (0.203022) = final_loss = 0.707437
n_iter 17 : loss (0.151895) + tot_loss (0.179739) + tot_loss_crop (0.161450) + loss_clip_order (0.212947) = final_loss = 0.706031
n_iter 18 : loss (0.164581) + tot_loss (0.179580) + tot_loss_crop (0.158883) + loss_clip_order (0.213342) = final_loss = 0.716386
n_iter 19 : loss (0.167555) + tot_loss (0.169455) + tot_loss_crop (0.157748) + loss_clip_order (0.214905) = final_loss = 0.709663
n_iter 20 : loss (0.153040) + tot_loss (0.178113) + tot_loss_crop (0.159335) + loss_clip_order (0.205484) = final_loss = 0.695972
n_iter 21 : loss (0.159472) + tot_loss (0.190207) + tot_loss_crop (0.163782) + loss_clip_order (0.199555) = final_loss = 0.713016
n_iter 22 : loss (0.177020) + tot_loss (0.176676) + tot_loss_crop (0.156422) + loss_clip_order (0.213286) = final_loss = 0.723403
n_iter 23 : loss (0.157405) + tot_loss (0.177645) + tot_loss_crop (0.159618) + loss_clip_order (0.202888) = final_loss = 0.697557
n_iter 24 : loss (0.159046) + tot_loss (0.169302) + tot_loss_crop (0.156022) + loss_clip_order (0.205287) = final_loss = 0.689657
n_iter 25 : loss (0.165394) + tot_loss (0.175239) + tot_loss_crop (0.159082) + loss_clip_order (0.202419) = final_loss = 0.702134
n_iter 26 : loss (0.159962) + tot_loss (0.176719) + tot_loss_crop (0.159431) + loss_clip_order (0.206393) = final_loss = 0.702506
n_iter 27 : loss (0.156717) + tot_loss (0.180254) + tot_loss_crop (0.158547) + loss_clip_order (0.202008) = final_loss = 0.697527
n_iter 28 : loss (0.156689) + tot_loss (0.165591) + tot_loss_crop (0.155418) + loss_clip_order (0.199976) = final_loss = 0.677674
n_iter 29 : loss (0.167855) + tot_loss (0.178366) + tot_loss_crop (0.159030) + loss_clip_order (0.199384) = final_loss = 0.704634
n_iter 30 : loss (0.168902) + tot_loss (0.177692) + tot_loss_crop (0.155448) + loss_clip_order (0.210481) = final_loss = 0.712522
[Pretraining Epoch 023] Total-Loss 0.18 =  F-Loss 0.18 + Clip-Loss 0.21 (train)
training epoch 21
use Semi !!!
[Iteration 000] Total-Loss 4.82 = T-Loss 4.08 + B-Loss 0.74 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.67 = T-Loss 3.98 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.63 = T-Loss 3.95 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.58 = T-Loss 3.91 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 021] Total-Loss 4.58 = T-Loss 3.91 + B-Loss 0.68 (train)[0m
[Epoch 021] Total-Loss 4.59 = T-Loss 3.94 + B-Loss 0.65  (val)
training epoch 22
use Semi !!!
[Iteration 000] Total-Loss 3.97 = T-Loss 3.27 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.18 = T-Loss 3.52 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.13 = T-Loss 3.47 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.10 = T-Loss 3.45 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 022] Total-Loss 4.10 = T-Loss 3.45 + B-Loss 0.66 (train)[0m
[Epoch 022] Total-Loss 4.42 = T-Loss 3.78 + B-Loss 0.64  (val)
training epoch 23
use Semi !!!
[Iteration 000] Total-Loss 3.81 = T-Loss 3.13 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.97 = T-Loss 3.32 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.92 = T-Loss 3.27 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.91 = T-Loss 3.26 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 023] Total-Loss 3.91 = T-Loss 3.26 + B-Loss 0.65 (train)[0m
[Epoch 023] Total-Loss 4.27 = T-Loss 3.63 + B-Loss 0.64  (val)
24
n_iter  0 : loss (0.194435) + tot_loss (0.177308) + tot_loss_crop (0.150975) + loss_clip_order (0.613806) = final_loss = 1.136523
n_iter  1 : loss (0.183052) + tot_loss (0.193189) + tot_loss_crop (0.153016) + loss_clip_order (0.287020) = final_loss = 0.816277
n_iter  2 : loss (0.183560) + tot_loss (0.190473) + tot_loss_crop (0.152398) + loss_clip_order (0.416806) = final_loss = 0.943237
n_iter  3 : loss (0.177570) + tot_loss (0.189378) + tot_loss_crop (0.156918) + loss_clip_order (0.451452) = final_loss = 0.975318
n_iter  4 : loss (0.180465) + tot_loss (0.188321) + tot_loss_crop (0.157151) + loss_clip_order (0.465820) = final_loss = 0.991757
n_iter  5 : loss (0.173046) + tot_loss (0.190934) + tot_loss_crop (0.157961) + loss_clip_order (0.360902) = final_loss = 0.882843
n_iter  6 : loss (0.172564) + tot_loss (0.182284) + tot_loss_crop (0.153993) + loss_clip_order (0.278450) = final_loss = 0.787291
n_iter  7 : loss (0.179462) + tot_loss (0.168453) + tot_loss_crop (0.154115) + loss_clip_order (0.241172) = final_loss = 0.743202
n_iter  8 : loss (0.171220) + tot_loss (0.176094) + tot_loss_crop (0.156479) + loss_clip_order (0.245835) = final_loss = 0.749629
n_iter  9 : loss (0.167986) + tot_loss (0.174866) + tot_loss_crop (0.154545) + loss_clip_order (0.231627) = final_loss = 0.729024
n_iter 10 : loss (0.163251) + tot_loss (0.190796) + tot_loss_crop (0.161362) + loss_clip_order (0.250929) = final_loss = 0.766338
n_iter 11 : loss (0.161931) + tot_loss (0.189462) + tot_loss_crop (0.160685) + loss_clip_order (0.263925) = final_loss = 0.776004
n_iter 12 : loss (0.166576) + tot_loss (0.201816) + tot_loss_crop (0.166924) + loss_clip_order (0.241163) = final_loss = 0.776479
n_iter 13 : loss (0.154577) + tot_loss (0.203842) + tot_loss_crop (0.169696) + loss_clip_order (0.228118) = final_loss = 0.756233
n_iter 14 : loss (0.158392) + tot_loss (0.204143) + tot_loss_crop (0.168249) + loss_clip_order (0.223737) = final_loss = 0.754521
n_iter 15 : loss (0.163704) + tot_loss (0.199179) + tot_loss_crop (0.165757) + loss_clip_order (0.226148) = final_loss = 0.754788
n_iter 16 : loss (0.166945) + tot_loss (0.197187) + tot_loss_crop (0.166605) + loss_clip_order (0.204610) = final_loss = 0.735347
n_iter 17 : loss (0.162575) + tot_loss (0.191453) + tot_loss_crop (0.165299) + loss_clip_order (0.203593) = final_loss = 0.722919
n_iter 18 : loss (0.161006) + tot_loss (0.188375) + tot_loss_crop (0.161959) + loss_clip_order (0.200355) = final_loss = 0.711695
n_iter 19 : loss (0.164102) + tot_loss (0.174448) + tot_loss_crop (0.158473) + loss_clip_order (0.197265) = final_loss = 0.694287
n_iter 20 : loss (0.160912) + tot_loss (0.180566) + tot_loss_crop (0.158300) + loss_clip_order (0.214751) = final_loss = 0.714529
n_iter 21 : loss (0.161279) + tot_loss (0.190798) + tot_loss_crop (0.161325) + loss_clip_order (0.208798) = final_loss = 0.722200
n_iter 22 : loss (0.162952) + tot_loss (0.175618) + tot_loss_crop (0.156955) + loss_clip_order (0.220152) = final_loss = 0.715677
n_iter 23 : loss (0.160402) + tot_loss (0.176677) + tot_loss_crop (0.157610) + loss_clip_order (0.215012) = final_loss = 0.709701
n_iter 24 : loss (0.157454) + tot_loss (0.168020) + tot_loss_crop (0.155153) + loss_clip_order (0.210365) = final_loss = 0.690992
n_iter 25 : loss (0.164328) + tot_loss (0.173578) + tot_loss_crop (0.155354) + loss_clip_order (0.211621) = final_loss = 0.704882
n_iter 26 : loss (0.159986) + tot_loss (0.177303) + tot_loss_crop (0.156503) + loss_clip_order (0.226645) = final_loss = 0.720438
n_iter 27 : loss (0.154314) + tot_loss (0.181273) + tot_loss_crop (0.156305) + loss_clip_order (0.192568) = final_loss = 0.684459
n_iter 28 : loss (0.158111) + tot_loss (0.168254) + tot_loss_crop (0.153911) + loss_clip_order (0.192140) = final_loss = 0.672416
n_iter 29 : loss (0.166004) + tot_loss (0.182353) + tot_loss_crop (0.158900) + loss_clip_order (0.201209) = final_loss = 0.708466
n_iter 30 : loss (0.170003) + tot_loss (0.183331) + tot_loss_crop (0.157938) + loss_clip_order (0.192078) = final_loss = 0.703351
[Pretraining Epoch 024] Total-Loss 0.18 =  F-Loss 0.18 + Clip-Loss 0.19 (train)
n_iter  0 : loss (0.161985) + tot_loss (0.175991) + tot_loss_crop (0.156480) + loss_clip_order (0.197817) = final_loss = 0.692274
n_iter  1 : loss (0.157710) + tot_loss (0.190427) + tot_loss_crop (0.158403) + loss_clip_order (0.209104) = final_loss = 0.715644
n_iter  2 : loss (0.159795) + tot_loss (0.182209) + tot_loss_crop (0.153976) + loss_clip_order (0.196960) = final_loss = 0.692941
n_iter  3 : loss (0.166730) + tot_loss (0.174764) + tot_loss_crop (0.152985) + loss_clip_order (0.196706) = final_loss = 0.691185
n_iter  4 : loss (0.156619) + tot_loss (0.171671) + tot_loss_crop (0.152338) + loss_clip_order (0.193904) = final_loss = 0.674532
n_iter  5 : loss (0.161649) + tot_loss (0.175401) + tot_loss_crop (0.153958) + loss_clip_order (0.196346) = final_loss = 0.687354
n_iter  6 : loss (0.165889) + tot_loss (0.170192) + tot_loss_crop (0.150849) + loss_clip_order (0.200337) = final_loss = 0.687267
n_iter  7 : loss (0.165990) + tot_loss (0.156917) + tot_loss_crop (0.146838) + loss_clip_order (0.194881) = final_loss = 0.664626
n_iter  8 : loss (0.162686) + tot_loss (0.164284) + tot_loss_crop (0.148142) + loss_clip_order (0.198473) = final_loss = 0.673585
n_iter  9 : loss (0.164511) + tot_loss (0.160232) + tot_loss_crop (0.146172) + loss_clip_order (0.197043) = final_loss = 0.667959
n_iter 10 : loss (0.170384) + tot_loss (0.167740) + tot_loss_crop (0.147677) + loss_clip_order (0.201376) = final_loss = 0.687177
n_iter 11 : loss (0.167260) + tot_loss (0.160588) + tot_loss_crop (0.144988) + loss_clip_order (0.188462) = final_loss = 0.661298
n_iter 12 : loss (0.161617) + tot_loss (0.168575) + tot_loss_crop (0.146059) + loss_clip_order (0.193171) = final_loss = 0.669421
n_iter 13 : loss (0.156657) + tot_loss (0.167361) + tot_loss_crop (0.146741) + loss_clip_order (0.191658) = final_loss = 0.662417
n_iter 14 : loss (0.165729) + tot_loss (0.168626) + tot_loss_crop (0.145698) + loss_clip_order (0.201114) = final_loss = 0.681167
n_iter 15 : loss (0.157315) + tot_loss (0.165130) + tot_loss_crop (0.145545) + loss_clip_order (0.201656) = final_loss = 0.669646
n_iter 16 : loss (0.161515) + tot_loss (0.166163) + tot_loss_crop (0.144546) + loss_clip_order (0.196900) = final_loss = 0.669124
n_iter 17 : loss (0.161300) + tot_loss (0.164376) + tot_loss_crop (0.143986) + loss_clip_order (0.195532) = final_loss = 0.665194
n_iter 18 : loss (0.154563) + tot_loss (0.164619) + tot_loss_crop (0.143934) + loss_clip_order (0.190074) = final_loss = 0.653190
n_iter 19 : loss (0.162282) + tot_loss (0.153959) + tot_loss_crop (0.138649) + loss_clip_order (0.200087) = final_loss = 0.654977
n_iter 20 : loss (0.166984) + tot_loss (0.162662) + tot_loss_crop (0.142163) + loss_clip_order (0.196388) = final_loss = 0.668197
n_iter 21 : loss (0.159115) + tot_loss (0.174523) + tot_loss_crop (0.142600) + loss_clip_order (0.193605) = final_loss = 0.669844
n_iter 22 : loss (0.163970) + tot_loss (0.159545) + tot_loss_crop (0.140128) + loss_clip_order (0.201311) = final_loss = 0.664953
n_iter 23 : loss (0.166169) + tot_loss (0.161745) + tot_loss_crop (0.140992) + loss_clip_order (0.198224) = final_loss = 0.667130
n_iter 24 : loss (0.160553) + tot_loss (0.151448) + tot_loss_crop (0.137849) + loss_clip_order (0.192538) = final_loss = 0.642388
n_iter 25 : loss (0.167640) + tot_loss (0.157571) + tot_loss_crop (0.141455) + loss_clip_order (0.193437) = final_loss = 0.660103
n_iter 26 : loss (0.156719) + tot_loss (0.159372) + tot_loss_crop (0.138986) + loss_clip_order (0.196921) = final_loss = 0.651998
n_iter 27 : loss (0.165025) + tot_loss (0.162322) + tot_loss_crop (0.140209) + loss_clip_order (0.193411) = final_loss = 0.660968
n_iter 28 : loss (0.165497) + tot_loss (0.148579) + tot_loss_crop (0.135776) + loss_clip_order (0.192346) = final_loss = 0.642199
n_iter 29 : loss (0.164043) + tot_loss (0.161282) + tot_loss_crop (0.139556) + loss_clip_order (0.193215) = final_loss = 0.658096
n_iter 30 : loss (0.159334) + tot_loss (0.160589) + tot_loss_crop (0.136895) + loss_clip_order (0.190100) = final_loss = 0.646919
[Pretraining Epoch 025] Total-Loss 0.16 =  F-Loss 0.16 + Clip-Loss 0.19 (train)
n_iter  0 : loss (0.163796) + tot_loss (0.153411) + tot_loss_crop (0.135360) + loss_clip_order (0.196535) = final_loss = 0.649101
n_iter  1 : loss (0.159587) + tot_loss (0.167714) + tot_loss_crop (0.139126) + loss_clip_order (0.193979) = final_loss = 0.660406
n_iter  2 : loss (0.172756) + tot_loss (0.160950) + tot_loss_crop (0.136427) + loss_clip_order (0.195281) = final_loss = 0.665415
n_iter  3 : loss (0.164564) + tot_loss (0.154347) + tot_loss_crop (0.136796) + loss_clip_order (0.189697) = final_loss = 0.645405
n_iter  4 : loss (0.164387) + tot_loss (0.151630) + tot_loss_crop (0.134038) + loss_clip_order (0.189153) = final_loss = 0.639208
n_iter  5 : loss (0.157393) + tot_loss (0.157143) + tot_loss_crop (0.136506) + loss_clip_order (0.187453) = final_loss = 0.638496
n_iter  6 : loss (0.155206) + tot_loss (0.153293) + tot_loss_crop (0.134158) + loss_clip_order (0.193704) = final_loss = 0.636361
n_iter  7 : loss (0.156989) + tot_loss (0.141832) + tot_loss_crop (0.130815) + loss_clip_order (0.192501) = final_loss = 0.622136
n_iter  8 : loss (0.158241) + tot_loss (0.149760) + tot_loss_crop (0.131514) + loss_clip_order (0.193036) = final_loss = 0.632552
n_iter  9 : loss (0.165151) + tot_loss (0.146082) + tot_loss_crop (0.130109) + loss_clip_order (0.190080) = final_loss = 0.631421
n_iter 10 : loss (0.161021) + tot_loss (0.154027) + tot_loss_crop (0.133523) + loss_clip_order (0.189865) = final_loss = 0.638437
n_iter 11 : loss (0.166656) + tot_loss (0.147893) + tot_loss_crop (0.129384) + loss_clip_order (0.189915) = final_loss = 0.633847
n_iter 12 : loss (0.165945) + tot_loss (0.155837) + tot_loss_crop (0.131573) + loss_clip_order (0.189461) = final_loss = 0.642816
n_iter 13 : loss (0.163621) + tot_loss (0.154484) + tot_loss_crop (0.133046) + loss_clip_order (0.188154) = final_loss = 0.639306
n_iter 14 : loss (0.161135) + tot_loss (0.155538) + tot_loss_crop (0.132549) + loss_clip_order (0.192054) = final_loss = 0.641276
n_iter 15 : loss (0.174575) + tot_loss (0.152505) + tot_loss_crop (0.132076) + loss_clip_order (0.188161) = final_loss = 0.647316
n_iter 16 : loss (0.164901) + tot_loss (0.153096) + tot_loss_crop (0.130764) + loss_clip_order (0.190967) = final_loss = 0.639727
n_iter 17 : loss (0.164311) + tot_loss (0.152054) + tot_loss_crop (0.130043) + loss_clip_order (0.209634) = final_loss = 0.656043
n_iter 18 : loss (0.165985) + tot_loss (0.151754) + tot_loss_crop (0.130830) + loss_clip_order (0.195397) = final_loss = 0.643965
n_iter 19 : loss (0.155994) + tot_loss (0.141980) + tot_loss_crop (0.126617) + loss_clip_order (0.197697) = final_loss = 0.622288
n_iter 20 : loss (0.156110) + tot_loss (0.150342) + tot_loss_crop (0.128797) + loss_clip_order (0.189988) = final_loss = 0.625237
n_iter 21 : loss (0.170861) + tot_loss (0.162520) + tot_loss_crop (0.131822) + loss_clip_order (0.188046) = final_loss = 0.653249
n_iter 22 : loss (0.172827) + tot_loss (0.148239) + tot_loss_crop (0.127347) + loss_clip_order (0.202124) = final_loss = 0.650537
n_iter 23 : loss (0.172195) + tot_loss (0.149483) + tot_loss_crop (0.127597) + loss_clip_order (0.192121) = final_loss = 0.641397
n_iter 24 : loss (0.165973) + tot_loss (0.140806) + tot_loss_crop (0.126185) + loss_clip_order (0.201856) = final_loss = 0.634820
n_iter 25 : loss (0.151079) + tot_loss (0.146941) + tot_loss_crop (0.127768) + loss_clip_order (0.183387) = final_loss = 0.609176
n_iter 26 : loss (0.168289) + tot_loss (0.149448) + tot_loss_crop (0.128029) + loss_clip_order (0.195099) = final_loss = 0.640865
n_iter 27 : loss (0.164916) + tot_loss (0.153300) + tot_loss_crop (0.129113) + loss_clip_order (0.187182) = final_loss = 0.634511
n_iter 28 : loss (0.165223) + tot_loss (0.139473) + tot_loss_crop (0.125287) + loss_clip_order (0.197919) = final_loss = 0.627901
n_iter 29 : loss (0.169728) + tot_loss (0.151373) + tot_loss_crop (0.128582) + loss_clip_order (0.208764) = final_loss = 0.658446
n_iter 30 : loss (0.164039) + tot_loss (0.150303) + tot_loss_crop (0.128682) + loss_clip_order (0.185626) = final_loss = 0.628649
[Pretraining Epoch 026] Total-Loss 0.15 =  F-Loss 0.15 + Clip-Loss 0.19 (train)
training epoch 24
use Semi !!!
[Iteration 000] Total-Loss 5.29 = T-Loss 4.58 + B-Loss 0.72 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.84 = T-Loss 4.15 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.76 = T-Loss 4.09 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.78 = T-Loss 4.10 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 024] Total-Loss 4.78 = T-Loss 4.10 + B-Loss 0.67 (train)[0m
[Epoch 024] Total-Loss 4.81 = T-Loss 4.16 + B-Loss 0.65  (val)
training epoch 25
use Semi !!!
[Iteration 000] Total-Loss 4.28 = T-Loss 3.59 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.37 = T-Loss 3.71 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.27 = T-Loss 3.61 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.24 = T-Loss 3.58 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 025] Total-Loss 4.24 = T-Loss 3.58 + B-Loss 0.66 (train)[0m
[Epoch 025] Total-Loss 4.40 = T-Loss 3.76 + B-Loss 0.64  (val)
training epoch 26
use Semi !!!
[Iteration 000] Total-Loss 3.75 = T-Loss 3.06 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.01 = T-Loss 3.35 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.97 = T-Loss 3.32 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.98 = T-Loss 3.33 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 026] Total-Loss 3.98 = T-Loss 3.33 + B-Loss 0.65 (train)[0m
[Epoch 026] Total-Loss 4.34 = T-Loss 3.71 + B-Loss 0.64  (val)
27
n_iter  0 : loss (0.196264) + tot_loss (0.144155) + tot_loss_crop (0.121399) + loss_clip_order (0.272135) = final_loss = 0.733953
n_iter  1 : loss (0.193576) + tot_loss (0.164129) + tot_loss_crop (0.126835) + loss_clip_order (0.265196) = final_loss = 0.749736
n_iter  2 : loss (0.186729) + tot_loss (0.163466) + tot_loss_crop (0.125890) + loss_clip_order (0.332957) = final_loss = 0.809041
n_iter  3 : loss (0.190735) + tot_loss (0.163282) + tot_loss_crop (0.128920) + loss_clip_order (0.389354) = final_loss = 0.872291
n_iter  4 : loss (0.181850) + tot_loss (0.163908) + tot_loss_crop (0.129985) + loss_clip_order (0.374716) = final_loss = 0.850458
n_iter  5 : loss (0.178380) + tot_loss (0.169864) + tot_loss_crop (0.132609) + loss_clip_order (0.326795) = final_loss = 0.807648
n_iter  6 : loss (0.177022) + tot_loss (0.165594) + tot_loss_crop (0.131719) + loss_clip_order (0.309864) = final_loss = 0.784199
n_iter  7 : loss (0.173176) + tot_loss (0.151253) + tot_loss_crop (0.127791) + loss_clip_order (0.269646) = final_loss = 0.721866
n_iter  8 : loss (0.164978) + tot_loss (0.156552) + tot_loss_crop (0.129383) + loss_clip_order (0.219484) = final_loss = 0.670396
n_iter  9 : loss (0.168169) + tot_loss (0.150087) + tot_loss_crop (0.127962) + loss_clip_order (0.199564) = final_loss = 0.645782
n_iter 10 : loss (0.173394) + tot_loss (0.155539) + tot_loss_crop (0.128786) + loss_clip_order (0.186577) = final_loss = 0.644296
n_iter 11 : loss (0.162838) + tot_loss (0.145454) + tot_loss_crop (0.126950) + loss_clip_order (0.179240) = final_loss = 0.614482
n_iter 12 : loss (0.171078) + tot_loss (0.153735) + tot_loss_crop (0.129278) + loss_clip_order (0.214010) = final_loss = 0.668101
n_iter 13 : loss (0.166765) + tot_loss (0.151402) + tot_loss_crop (0.130583) + loss_clip_order (0.217616) = final_loss = 0.666366
n_iter 14 : loss (0.175368) + tot_loss (0.153203) + tot_loss_crop (0.130677) + loss_clip_order (0.235553) = final_loss = 0.694801
n_iter 15 : loss (0.158817) + tot_loss (0.151422) + tot_loss_crop (0.128602) + loss_clip_order (0.233479) = final_loss = 0.672320
n_iter 16 : loss (0.163314) + tot_loss (0.153082) + tot_loss_crop (0.130650) + loss_clip_order (0.188309) = final_loss = 0.635355
n_iter 17 : loss (0.157663) + tot_loss (0.153331) + tot_loss_crop (0.131387) + loss_clip_order (0.200808) = final_loss = 0.643190
n_iter 18 : loss (0.169402) + tot_loss (0.155149) + tot_loss_crop (0.131208) + loss_clip_order (0.185321) = final_loss = 0.641081
n_iter 19 : loss (0.156225) + tot_loss (0.146629) + tot_loss_crop (0.128391) + loss_clip_order (0.181955) = final_loss = 0.613199
n_iter 20 : loss (0.162086) + tot_loss (0.156692) + tot_loss_crop (0.131008) + loss_clip_order (0.186961) = final_loss = 0.636747
n_iter 21 : loss (0.156157) + tot_loss (0.170915) + tot_loss_crop (0.133867) + loss_clip_order (0.188309) = final_loss = 0.649247
n_iter 22 : loss (0.176752) + tot_loss (0.156337) + tot_loss_crop (0.130260) + loss_clip_order (0.190269) = final_loss = 0.653618
n_iter 23 : loss (0.176438) + tot_loss (0.159253) + tot_loss_crop (0.132163) + loss_clip_order (0.189060) = final_loss = 0.656914
n_iter 24 : loss (0.159359) + tot_loss (0.150412) + tot_loss_crop (0.127686) + loss_clip_order (0.187200) = final_loss = 0.624657
n_iter 25 : loss (0.158545) + tot_loss (0.156414) + tot_loss_crop (0.131073) + loss_clip_order (0.175001) = final_loss = 0.621033
n_iter 26 : loss (0.168213) + tot_loss (0.158394) + tot_loss_crop (0.130859) + loss_clip_order (0.187400) = final_loss = 0.644865
n_iter 27 : loss (0.153182) + tot_loss (0.160769) + tot_loss_crop (0.128772) + loss_clip_order (0.180811) = final_loss = 0.623534
n_iter 28 : loss (0.162523) + tot_loss (0.146113) + tot_loss_crop (0.125445) + loss_clip_order (0.183767) = final_loss = 0.617848
n_iter 29 : loss (0.164011) + tot_loss (0.158381) + tot_loss_crop (0.128770) + loss_clip_order (0.187807) = final_loss = 0.638969
n_iter 30 : loss (0.151512) + tot_loss (0.157340) + tot_loss_crop (0.126307) + loss_clip_order (0.183497) = final_loss = 0.618657
[Pretraining Epoch 027] Total-Loss 0.16 =  F-Loss 0.16 + Clip-Loss 0.18 (train)
n_iter  0 : loss (0.162776) + tot_loss (0.149171) + tot_loss_crop (0.125524) + loss_clip_order (0.191147) = final_loss = 0.628617
n_iter  1 : loss (0.166359) + tot_loss (0.163260) + tot_loss_crop (0.128503) + loss_clip_order (0.190644) = final_loss = 0.648766
n_iter  2 : loss (0.163464) + tot_loss (0.154714) + tot_loss_crop (0.126164) + loss_clip_order (0.181208) = final_loss = 0.625551
n_iter  3 : loss (0.165769) + tot_loss (0.148045) + tot_loss_crop (0.124145) + loss_clip_order (0.180054) = final_loss = 0.618013
n_iter  4 : loss (0.170266) + tot_loss (0.144339) + tot_loss_crop (0.123529) + loss_clip_order (0.181552) = final_loss = 0.619685
n_iter  5 : loss (0.163341) + tot_loss (0.148597) + tot_loss_crop (0.124047) + loss_clip_order (0.182364) = final_loss = 0.618350
n_iter  6 : loss (0.157531) + tot_loss (0.144383) + tot_loss_crop (0.121559) + loss_clip_order (0.184545) = final_loss = 0.608017
n_iter  7 : loss (0.167192) + tot_loss (0.132215) + tot_loss_crop (0.120173) + loss_clip_order (0.182791) = final_loss = 0.602371
n_iter  8 : loss (0.170054) + tot_loss (0.139180) + tot_loss_crop (0.120957) + loss_clip_order (0.190566) = final_loss = 0.620757
n_iter  9 : loss (0.173143) + tot_loss (0.135585) + tot_loss_crop (0.119254) + loss_clip_order (0.179149) = final_loss = 0.607131
n_iter 10 : loss (0.164437) + tot_loss (0.143577) + tot_loss_crop (0.120471) + loss_clip_order (0.182684) = final_loss = 0.611169
n_iter 11 : loss (0.157163) + tot_loss (0.136018) + tot_loss_crop (0.118818) + loss_clip_order (0.173237) = final_loss = 0.585235
n_iter 12 : loss (0.166188) + tot_loss (0.144579) + tot_loss_crop (0.118850) + loss_clip_order (0.180605) = final_loss = 0.610221
n_iter 13 : loss (0.169154) + tot_loss (0.142843) + tot_loss_crop (0.120905) + loss_clip_order (0.178517) = final_loss = 0.611419
n_iter 14 : loss (0.160764) + tot_loss (0.144123) + tot_loss_crop (0.119813) + loss_clip_order (0.187283) = final_loss = 0.611983
n_iter 15 : loss (0.171215) + tot_loss (0.141151) + tot_loss_crop (0.120400) + loss_clip_order (0.190294) = final_loss = 0.623060
n_iter 16 : loss (0.172791) + tot_loss (0.142022) + tot_loss_crop (0.119909) + loss_clip_order (0.173298) = final_loss = 0.608020
n_iter 17 : loss (0.165596) + tot_loss (0.140659) + tot_loss_crop (0.119513) + loss_clip_order (0.186267) = final_loss = 0.612034
n_iter 18 : loss (0.159371) + tot_loss (0.140518) + tot_loss_crop (0.116734) + loss_clip_order (0.182550) = final_loss = 0.599174
n_iter 19 : loss (0.162590) + tot_loss (0.130665) + tot_loss_crop (0.113061) + loss_clip_order (0.183068) = final_loss = 0.589384
n_iter 20 : loss (0.159435) + tot_loss (0.139288) + tot_loss_crop (0.115671) + loss_clip_order (0.177697) = final_loss = 0.592092
n_iter 21 : loss (0.153346) + tot_loss (0.151668) + tot_loss_crop (0.119309) + loss_clip_order (0.175652) = final_loss = 0.599975
n_iter 22 : loss (0.155805) + tot_loss (0.137446) + tot_loss_crop (0.115068) + loss_clip_order (0.184722) = final_loss = 0.593042
n_iter 23 : loss (0.158622) + tot_loss (0.140011) + tot_loss_crop (0.117699) + loss_clip_order (0.172482) = final_loss = 0.588814
n_iter 24 : loss (0.151542) + tot_loss (0.131231) + tot_loss_crop (0.113693) + loss_clip_order (0.181912) = final_loss = 0.578378
n_iter 25 : loss (0.157937) + tot_loss (0.137097) + tot_loss_crop (0.115951) + loss_clip_order (0.180769) = final_loss = 0.591754
n_iter 26 : loss (0.162149) + tot_loss (0.138193) + tot_loss_crop (0.116039) + loss_clip_order (0.182253) = final_loss = 0.598634
n_iter 27 : loss (0.159786) + tot_loss (0.141343) + tot_loss_crop (0.114522) + loss_clip_order (0.177092) = final_loss = 0.592744
n_iter 28 : loss (0.153808) + tot_loss (0.126629) + tot_loss_crop (0.112123) + loss_clip_order (0.173353) = final_loss = 0.565914
n_iter 29 : loss (0.159477) + tot_loss (0.139072) + tot_loss_crop (0.113378) + loss_clip_order (0.185154) = final_loss = 0.597081
n_iter 30 : loss (0.160312) + tot_loss (0.138512) + tot_loss_crop (0.112712) + loss_clip_order (0.181151) = final_loss = 0.592687
[Pretraining Epoch 028] Total-Loss 0.14 =  F-Loss 0.14 + Clip-Loss 0.18 (train)
n_iter  0 : loss (0.159935) + tot_loss (0.130746) + tot_loss_crop (0.111313) + loss_clip_order (0.172059) = final_loss = 0.574054
n_iter  1 : loss (0.158367) + tot_loss (0.145398) + tot_loss_crop (0.116132) + loss_clip_order (0.177678) = final_loss = 0.597574
n_iter  2 : loss (0.157503) + tot_loss (0.138303) + tot_loss_crop (0.113428) + loss_clip_order (0.178744) = final_loss = 0.587977
n_iter  3 : loss (0.162749) + tot_loss (0.132009) + tot_loss_crop (0.112123) + loss_clip_order (0.180099) = final_loss = 0.586981
n_iter  4 : loss (0.164489) + tot_loss (0.129021) + tot_loss_crop (0.108750) + loss_clip_order (0.178747) = final_loss = 0.581007
n_iter  5 : loss (0.166078) + tot_loss (0.134776) + tot_loss_crop (0.112844) + loss_clip_order (0.172801) = final_loss = 0.586499
n_iter  6 : loss (0.153876) + tot_loss (0.131157) + tot_loss_crop (0.110472) + loss_clip_order (0.182103) = final_loss = 0.577608
n_iter  7 : loss (0.155799) + tot_loss (0.120068) + tot_loss_crop (0.107158) + loss_clip_order (0.177498) = final_loss = 0.560523
n_iter  8 : loss (0.157132) + tot_loss (0.127937) + tot_loss_crop (0.109422) + loss_clip_order (0.180413) = final_loss = 0.574904
n_iter  9 : loss (0.157239) + tot_loss (0.124894) + tot_loss_crop (0.108210) + loss_clip_order (0.180013) = final_loss = 0.570356
n_iter 10 : loss (0.162478) + tot_loss (0.132493) + tot_loss_crop (0.108935) + loss_clip_order (0.182406) = final_loss = 0.586312
n_iter 11 : loss (0.179503) + tot_loss (0.126821) + tot_loss_crop (0.106351) + loss_clip_order (0.178993) = final_loss = 0.591669
n_iter 12 : loss (0.168470) + tot_loss (0.134441) + tot_loss_crop (0.110256) + loss_clip_order (0.181312) = final_loss = 0.594479
n_iter 13 : loss (0.169006) + tot_loss (0.133346) + tot_loss_crop (0.108911) + loss_clip_order (0.174774) = final_loss = 0.586037
n_iter 14 : loss (0.161114) + tot_loss (0.134446) + tot_loss_crop (0.108706) + loss_clip_order (0.185380) = final_loss = 0.589645
n_iter 15 : loss (0.163559) + tot_loss (0.131024) + tot_loss_crop (0.108008) + loss_clip_order (0.182582) = final_loss = 0.585173
n_iter 16 : loss (0.162128) + tot_loss (0.131667) + tot_loss_crop (0.108718) + loss_clip_order (0.176057) = final_loss = 0.578570
n_iter 17 : loss (0.159151) + tot_loss (0.130075) + tot_loss_crop (0.108452) + loss_clip_order (0.184274) = final_loss = 0.581953
n_iter 18 : loss (0.155123) + tot_loss (0.130026) + tot_loss_crop (0.108406) + loss_clip_order (0.173966) = final_loss = 0.567522
n_iter 19 : loss (0.163701) + tot_loss (0.120513) + tot_loss_crop (0.102708) + loss_clip_order (0.177442) = final_loss = 0.564364
n_iter 20 : loss (0.165398) + tot_loss (0.129342) + tot_loss_crop (0.105791) + loss_clip_order (0.178890) = final_loss = 0.579421
n_iter 21 : loss (0.172329) + tot_loss (0.141513) + tot_loss_crop (0.109070) + loss_clip_order (0.182617) = final_loss = 0.605529
n_iter 22 : loss (0.162907) + tot_loss (0.127358) + tot_loss_crop (0.106131) + loss_clip_order (0.192404) = final_loss = 0.588800
n_iter 23 : loss (0.156051) + tot_loss (0.129347) + tot_loss_crop (0.106450) + loss_clip_order (0.179027) = final_loss = 0.570876
n_iter 24 : loss (0.172099) + tot_loss (0.121262) + tot_loss_crop (0.102219) + loss_clip_order (0.192335) = final_loss = 0.587914
n_iter 25 : loss (0.163370) + tot_loss (0.126445) + tot_loss_crop (0.105714) + loss_clip_order (0.176286) = final_loss = 0.571815
n_iter 26 : loss (0.168564) + tot_loss (0.127905) + tot_loss_crop (0.104933) + loss_clip_order (0.182278) = final_loss = 0.583680
n_iter 27 : loss (0.154287) + tot_loss (0.130788) + tot_loss_crop (0.104873) + loss_clip_order (0.180291) = final_loss = 0.570239
n_iter 28 : loss (0.161677) + tot_loss (0.117006) + tot_loss_crop (0.101911) + loss_clip_order (0.174059) = final_loss = 0.554653
n_iter 29 : loss (0.165178) + tot_loss (0.129778) + tot_loss_crop (0.105543) + loss_clip_order (0.178006) = final_loss = 0.578505
n_iter 30 : loss (0.162507) + tot_loss (0.129240) + tot_loss_crop (0.105103) + loss_clip_order (0.175666) = final_loss = 0.572516
[Pretraining Epoch 029] Total-Loss 0.13 =  F-Loss 0.13 + Clip-Loss 0.18 (train)
training epoch 27
use Semi !!!
[Iteration 000] Total-Loss 5.08 = T-Loss 4.36 + B-Loss 0.72 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.73 = T-Loss 4.04 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.69 = T-Loss 4.01 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.70 = T-Loss 4.02 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 027] Total-Loss 4.70 = T-Loss 4.02 + B-Loss 0.68 (train)[0m
[Epoch 027] Total-Loss 4.74 = T-Loss 4.09 + B-Loss 0.66  (val)
training epoch 28
use Semi !!!
[Iteration 000] Total-Loss 4.24 = T-Loss 3.54 + B-Loss 0.70 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.35 = T-Loss 3.67 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.29 = T-Loss 3.62 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.27 = T-Loss 3.60 + B-Loss 0.67 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 028] Total-Loss 4.27 = T-Loss 3.60 + B-Loss 0.67 (train)[0m
[Epoch 028] Total-Loss 4.46 = T-Loss 3.82 + B-Loss 0.64  (val)
training epoch 29
use Semi !!!
[Iteration 000] Total-Loss 3.87 = T-Loss 3.18 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 4.07 = T-Loss 3.41 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 4.04 = T-Loss 3.38 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 4.06 = T-Loss 3.40 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 029] Total-Loss 4.06 = T-Loss 3.40 + B-Loss 0.66 (train)[0m
[Epoch 029] Total-Loss 4.40 = T-Loss 3.76 + B-Loss 0.64  (val)
training epoch 30
use Semi !!!
[Iteration 000] Total-Loss 3.76 = T-Loss 3.07 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.98 = T-Loss 3.32 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.95 = T-Loss 3.30 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.97 = T-Loss 3.32 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 030] Total-Loss 3.97 = T-Loss 3.32 + B-Loss 0.66 (train)[0m
[Epoch 030] Total-Loss 4.41 = T-Loss 3.77 + B-Loss 0.64  (val)
training epoch 31
use Semi !!!
[Iteration 000] Total-Loss 3.78 = T-Loss 3.10 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.90 = T-Loss 3.25 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.90 = T-Loss 3.25 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.95 = T-Loss 3.30 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 031] Total-Loss 3.95 = T-Loss 3.30 + B-Loss 0.65 (train)[0m
[Epoch 031] Total-Loss 4.35 = T-Loss 3.71 + B-Loss 0.64  (val)
training epoch 32
use Semi !!!
[Iteration 000] Total-Loss 3.64 = T-Loss 2.95 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.94 = T-Loss 3.28 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.93 = T-Loss 3.27 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.95 = T-Loss 3.30 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 032] Total-Loss 3.95 = T-Loss 3.30 + B-Loss 0.65 (train)[0m
[Epoch 032] Total-Loss 4.39 = T-Loss 3.75 + B-Loss 0.64  (val)
training epoch 33
use Semi !!!
[Iteration 000] Total-Loss 3.64 = T-Loss 2.96 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.89 = T-Loss 3.24 + B-Loss 0.66 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.89 = T-Loss 3.24 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.92 = T-Loss 3.27 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 033] Total-Loss 3.92 = T-Loss 3.27 + B-Loss 0.65 (train)[0m
[Epoch 033] Total-Loss 4.34 = T-Loss 3.70 + B-Loss 0.64  (val)
training epoch 34
use Semi !!!
[Iteration 000] Total-Loss 3.57 = T-Loss 2.88 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.83 = T-Loss 3.18 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.82 = T-Loss 3.17 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.84 = T-Loss 3.19 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 034] Total-Loss 3.84 = T-Loss 3.19 + B-Loss 0.65 (train)[0m
[Epoch 034] Total-Loss 4.26 = T-Loss 3.62 + B-Loss 0.64  (val)
training epoch 35
use Semi !!!
[Iteration 000] Total-Loss 3.49 = T-Loss 2.80 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.76 = T-Loss 3.11 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.75 = T-Loss 3.09 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.76 = T-Loss 3.11 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 035] Total-Loss 3.76 = T-Loss 3.11 + B-Loss 0.65 (train)[0m
[Epoch 035] Total-Loss 4.21 = T-Loss 3.58 + B-Loss 0.64  (val)
training epoch 36
use Semi !!!
[Iteration 000] Total-Loss 3.45 = T-Loss 2.76 + B-Loss 0.69 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.71 = T-Loss 3.06 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.70 = T-Loss 3.05 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.72 = T-Loss 3.07 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 036] Total-Loss 3.72 = T-Loss 3.07 + B-Loss 0.65 (train)[0m
[Epoch 036] Total-Loss 4.20 = T-Loss 3.56 + B-Loss 0.64  (val)
training epoch 37
use Semi !!!
[Iteration 000] Total-Loss 3.44 = T-Loss 2.76 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.69 = T-Loss 3.03 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.68 = T-Loss 3.03 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.71 = T-Loss 3.06 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 037] Total-Loss 3.71 = T-Loss 3.06 + B-Loss 0.65 (train)[0m
[Epoch 037] Total-Loss 4.18 = T-Loss 3.55 + B-Loss 0.64  (val)
training epoch 38
use Semi !!!
[Iteration 000] Total-Loss 3.39 = T-Loss 2.71 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.72 = T-Loss 3.07 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.73 = T-Loss 3.08 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.77 = T-Loss 3.12 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 038] Total-Loss 3.77 = T-Loss 3.12 + B-Loss 0.65 (train)[0m
[Epoch 038] Total-Loss 4.26 = T-Loss 3.62 + B-Loss 0.64  (val)
training epoch 39
use Semi !!!
[Iteration 000] Total-Loss 3.51 = T-Loss 2.82 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.74 = T-Loss 3.09 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.73 = T-Loss 3.08 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.75 = T-Loss 3.11 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 039] Total-Loss 3.75 = T-Loss 3.11 + B-Loss 0.65 (train)[0m
[Epoch 039] Total-Loss 4.16 = T-Loss 3.52 + B-Loss 0.64  (val)
training epoch 40
use Semi !!!
[Iteration 000] Total-Loss 3.41 = T-Loss 2.73 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.67 = T-Loss 3.02 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.65 = T-Loss 3.00 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.67 = T-Loss 3.02 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 040] Total-Loss 3.67 = T-Loss 3.02 + B-Loss 0.65 (train)[0m
[Epoch 040] Total-Loss 4.14 = T-Loss 3.50 + B-Loss 0.64  (val)
training epoch 41
use Semi !!!
[Iteration 000] Total-Loss 3.36 = T-Loss 2.68 + B-Loss 0.68 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 010] Total-Loss 3.59 = T-Loss 2.94 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 020] Total-Loss 3.57 = T-Loss 2.92 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[Iteration 030] Total-Loss 3.59 = T-Loss 2.94 + B-Loss 0.65 + C-Loss 0.00 + C-EMA-Loss 0.00  (train)
[94m[Epoch 041] Total-Loss 3.59 = T-Loss 2.94 + B-Loss 0.65 (train)[0m
[Epoch 041] Total-Loss 4.07 = T-Loss 3.44 + B-Loss 0.64  (val)
Total Time taken for Running 40 epoch is :2121.722 secs

real	35m51.175s
user	51m40.734s
sys	15m5.835s
{'dataset': {'name': 'anet', 'num_classes': 200, 'training': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}, 'testing': {'video_info_path': './data/activitynet_annotations/video_info_new.csv', 'video_info_path_unlabeled': './data/activitynet_annotations/', 'video_anno_path': './data/activitynet_annotations/anet_anno_action.json', 'num_frame': 16, 'output_path': './output/', 'unlabel_percent': 0.9, 'use_semi': True}}, 'model': {'embedding_head': 1, 'feat_dim': 400, 'temporal_scale': 100}, 'pretraining': {'warmup_epoch': 30, 'consecutive_warmup_epochs': 3, 'unlabeled_pretrain': False}, 'training': {'batch_size': 25, 'learning_rate': 0.0004, 'weight_decay': 0.005, 'alternate': True, 'max_epoch': 40, 'consecutive_train_epochs': 3, 'checkpoint_path': './output/', 'random_seed': 1, 'step': 5, 'gamma': 0.8, 'scheduler': False, 'feature_path': '/data/i5O/ActivityNet1.3/train/', 'num_gpu': 1, 'loss_balance': 0.1, 'loss_balance_full': 0.5, 'regular_eval': False}, 'loss': {'lambda_1': 0.5, 'lambda_2': 0.1}, 'testing': {'feature_path': '/data/i5O/ActivityNet1.3/test/', 'cls_thresh': 0.01, 'mask_thresh': [0, 0.2, 0.4, 0.6, 0.8], 'class_thresh': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9], 'top_k_snip': 10, 'top_k': 500, 'nms_thresh': 0.6}}
Loading validation Video Information ...
  0% 0/4728 [00:00<?, ?it/s] 20% 936/4728 [00:00<00:00, 9359.00it/s] 40% 1872/4728 [00:00<00:00, 8602.97it/s] 58% 2737/4728 [00:00<00:00, 7789.84it/s] 75% 3524/4728 [00:00<00:00, 7052.17it/s] 90% 4239/4728 [00:00<00:00, 5267.12it/s]100% 4728/4728 [00:00<00:00, 6123.22it/s]len(test_loader), 3852
Inference start

Inference finished
Start Post-Processing
End Post-Processing

real	4m20.363s
user	8m28.301s
sys	1m23.299s
Traceback (most recent call last):
  File "eval.py", line 29, in <module>
    from evaluation.eval_detection import ANETdetection
  File "/root/models/SPOT/evaluation/eval_detection.py", line 21, in <module>
    pred_data = pd.read_csv("spot_output_semi.csv")
  File "/root/models/venv_SPOT/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 912, in read_csv
    return _read(filepath_or_buffer, kwds)
  File "/root/models/venv_SPOT/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 577, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "/root/models/venv_SPOT/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1407, in __init__
    self._engine = self._make_engine(f, self.engine)
  File "/root/models/venv_SPOT/lib/python3.8/site-packages/pandas/io/parsers/readers.py", line 1661, in _make_engine
    self.handles = get_handle(
  File "/root/models/venv_SPOT/lib/python3.8/site-packages/pandas/io/common.py", line 859, in get_handle
    handle = open(
FileNotFoundError: [Errno 2] No such file or directory: 'spot_output_semi.csv'

real	0m0.710s
user	0m1.372s
sys	0m6.383s
